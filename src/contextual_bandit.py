import numpy as np
import pickle
from pathlib import Path
from typing import List, Optional, Dict
from datetime import datetime
try:
    from .logger import setup_logger
except ImportError:
    # å¤„ç†ç›´æ¥è¿è¡Œæ—¶çš„å¯¼å…¥é—®é¢˜
    import sys
    sys.path.insert(0, str(Path(__file__).parent))
    from logger import setup_logger

logger = setup_logger(__name__)

class ContextualLinUCB:
    """
    æ ‡å‡†Contextual LinUCBå¤šè‡‚è€è™æœº
    
    é¢‘ç‡ä½œä¸ºåŠ¨ä½œ(arms)ï¼Œå·¥ä½œè´Ÿè½½ç‰¹å¾ä½œä¸ºä¸Šä¸‹æ–‡(context)
    æ¯ä¸ªé¢‘ç‡ç»´æŠ¤ç‹¬ç«‹çš„çº¿æ€§æ¨¡å‹ï¼šreward = context^T * theta_freq
    
    è¿™æ˜¯æ ‡å‡†çš„contextual banditï¼Œé¢‘ç‡ä¸ä½œä¸ºç‰¹å¾è¾“å…¥ï¼
    """
    
    def __init__(self, 
                 n_features: int = 7,
                 alpha: float = 1.0, 
                 lambda_reg: float = 1.0,
                 alpha_decay_rate: float = 0.01,
                 min_alpha: float = 0.1,
                 enable_action_pruning: bool = True,
                 pruning_check_interval: int = 100,
                 pruning_threshold: float = 1.0,
                 min_exploration_for_pruning: int = 5,
                 pruning_maturity_threshold: int = 100,
                 cascade_pruning_threshold: int = 600,
                 gpu_max_freq: int = None,  # GPUç¡¬ä»¶æ”¯æŒçš„æœ€å¤§é¢‘ç‡
                 # æç«¯é¢‘ç‡å³æ—¶ä¿®å‰ªå‚æ•°
                 enable_extreme_pruning: bool = True,
                 extreme_pruning_threshold: float = -1.5,
                 extreme_pruning_min_samples: int = 3,
                 extreme_pruning_max_rounds: int = 20,
                 model_dir: str = "data/models", 
                 auto_load: bool = True):
        
        self.n_features = n_features  # ä¸Šä¸‹æ–‡ç‰¹å¾ç»´åº¦ (åªåŒ…å«å·¥ä½œè´Ÿè½½ç‰¹å¾)
        self.alpha = alpha           # UCBæ¢ç´¢å‚æ•°
        self.initial_alpha = alpha   # ä¿å­˜åˆå§‹alphaå€¼
        self.lambda_reg = lambda_reg # æ­£åˆ™åŒ–å‚æ•°
        self.alpha_decay_rate = alpha_decay_rate  # alphaè¡°å‡ç‡
        self.min_alpha = min_alpha   # æœ€å°alphaå€¼
        
        # æ™ºèƒ½åŠ¨ä½œä¿®å‰ªå‚æ•°
        self.enable_action_pruning = enable_action_pruning
        self.pruning_check_interval = pruning_check_interval
        self.pruning_threshold = pruning_threshold
        self.min_exploration_for_pruning = min_exploration_for_pruning
        self.pruning_maturity_threshold = pruning_maturity_threshold
        self.cascade_pruning_threshold = cascade_pruning_threshold  # å›ºå®šé˜ˆå€¼ï¼Œç”¨äºå¤‡ç”¨
        self.gpu_max_freq = gpu_max_freq  # GPUç¡¬ä»¶æ”¯æŒçš„æœ€å¤§é¢‘ç‡
        self.adaptive_cascade_pruning = True  # å¯ç”¨è‡ªé€‚åº”çº§è”ä¿®å‰ª
        
        self.model_dir = Path(model_dir)
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        # åŠ¨ä½œç©ºé—´ç®¡ç†
        self.available_frequencies = []  # å½“å‰å¯ç”¨é¢‘ç‡åˆ—è¡¨ (æ ¸å¿ƒé¢‘ç‡æˆ–ç»„åˆé¢‘ç‡)
        
        # æ˜¾å­˜+æ ¸å¿ƒé¢‘ç‡ç»„åˆä¼˜åŒ–æ”¯æŒï¼ˆå‘åå…¼å®¹ï¼‰
        self.memory_optimization_enabled = False  # æ˜¯å¦å¯ç”¨æ˜¾å­˜é¢‘ç‡ä¼˜åŒ–
        self.available_memory_frequencies = []    # å¯ç”¨æ˜¾å­˜é¢‘ç‡åˆ—è¡¨
        
        # ç²¾ç»†çš„ç»„åˆé¢‘ç‡ç¦ç”¨ç®¡ç†
        self.globally_disabled_memory_frequencies = set()  # å…¨å±€ç¦ç”¨çš„æ˜¾å­˜é¢‘ç‡ï¼ˆè®¾ç½®å¤±è´¥ï¼‰
        self.core_memory_disabled_combinations = {}  # æ ¸å¿ƒé¢‘ç‡ç‰¹å®šçš„ç¦ç”¨æ˜¾å­˜é¢‘ç‡ {core_freq: set(disabled_memory_freqs)}
        self.disabled_core_frequencies = set()  # å› æ˜¾å­˜é¢‘ç‡é—®é¢˜è¢«ç¦ç”¨çš„æ ¸å¿ƒé¢‘ç‡
        
        # æ ¸å¿ƒé¢‘ç‡ä¾èµ–çš„SLOè¾¹ç•Œä¼ æ’­ç®¡ç†
        self.core_specific_memory_slo_boundaries = {}  # æ¯ä¸ªæ ¸å¿ƒé¢‘ç‡çš„æ˜¾å­˜é¢‘ç‡SLOè¾¹ç•Œ {core_freq: min_allowed_memory_freq}
        
        # æ™ºèƒ½ä¿®å‰ªçŠ¶æ€
        self.pruned_frequencies = set()  # è¢«ä¿®å‰ªçš„é¢‘ç‡é›†åˆ
        self.last_pruning_check = 0      # ä¸Šæ¬¡ä¿®å‰ªæ£€æŸ¥çš„è½®æ¬¡
        self.pruning_history = []        # ä¿®å‰ªå†å²è®°å½•
        
        # æç«¯é¢‘ç‡å³æ—¶ä¿®å‰ªå‚æ•°
        self.enable_extreme_pruning = enable_extreme_pruning  # å¯ç”¨æç«¯é¢‘ç‡å³æ—¶ä¿®å‰ª
        self.extreme_pruning_threshold = extreme_pruning_threshold  # æç«¯å·®é¢‘ç‡çš„å¥–åŠ±é˜ˆå€¼
        self.extreme_pruning_min_samples = extreme_pruning_min_samples  # åˆ¤æ–­æç«¯é¢‘ç‡çš„æœ€å°æ ·æœ¬æ•°
        self.extreme_pruning_max_rounds = extreme_pruning_max_rounds  # åœ¨å‰Nè½®å†…è¿›è¡Œæç«¯ä¿®å‰ª
        
        # æ¯ä¸ªé¢‘ç‡(åŠ¨ä½œ)ç»´æŠ¤ç‹¬ç«‹çš„çº¿æ€§æ¨¡å‹
        # arm_models[freq] = {'A': A_matrix, 'b': b_vector, 'theta': theta_vector}
        self.arm_models = {}  
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_rounds = 0
        self.total_reward = 0.0
        self.reward_history = []
        self.action_history = []  # è®°å½•æ¯æ¬¡é€‰æ‹©çš„é¢‘ç‡
        self.context_history = []  # è®°å½•æ¯æ¬¡çš„ä¸Šä¸‹æ–‡
        self.edp_history = []  # è®°å½•æ¯æ¬¡çš„åŸå§‹EDPå€¼
        
        # æ¯ä¸ªé¢‘ç‡çš„é€‰æ‹©æ¬¡æ•°å’Œç´¯ç§¯å¥–åŠ±
        self.arm_counts = {}     # freq -> count
        self.arm_rewards = {}    # freq -> total_reward
        
        # æ”¶æ•›çŠ¶æ€
        self.exploitation_mode = False
        self.is_converged = False
        
        # å­¦ä¹ é˜¶æ®µé¡ºåºéå†æ§åˆ¶
        self.learning_phase_complete = False  # æ˜¯å¦å®Œæˆå­¦ä¹ é˜¶æ®µéå†
        self.learning_frequency_index = 0    # å½“å‰å­¦ä¹ éå†çš„é¢‘ç‡ç´¢å¼•
        
        # æ¨¡å‹å…ƒæ•°æ®
        self.metadata = {
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat(),
            'version': '5.0-contextual-bandit',
            'algorithm': 'contextual_linucb',
            'frequency_as_action': True,  # æ ‡è®°ï¼šé¢‘ç‡ä½œä¸ºåŠ¨ä½œï¼Œä¸æ˜¯ç‰¹å¾
        }
        
        logger.info(f"ğŸ¯ åˆå§‹åŒ–Contextual LinUCB:")
        logger.info(f"   ä¸Šä¸‹æ–‡ç‰¹å¾: {n_features}ç»´ (ä»…å·¥ä½œè´Ÿè½½ç‰¹å¾)")
        logger.info(f"   é¢‘ç‡ä½œä¸ºåŠ¨ä½œ: æ˜¯ (æ¯ä¸ªé¢‘ç‡ç‹¬ç«‹å»ºæ¨¡)")
        logger.info(f"   UCBå‚æ•°Î±: {alpha}")
        logger.info(f"   æ­£åˆ™åŒ–Î»: {lambda_reg}")
        
        # æç«¯ä¿®å‰ªé…ç½®ä¿¡æ¯
        if self.enable_extreme_pruning:
            logger.info(f"ğŸš¨ æç«¯é¢‘ç‡ä¿®å‰ªå·²å¯ç”¨ (é˜ˆå€¼: {self.extreme_pruning_threshold}, å‰{self.extreme_pruning_max_rounds}è½®æ£€æŸ¥)")
        else:
            logger.info("âš ï¸  æç«¯é¢‘ç‡ä¿®å‰ªå·²ç¦ç”¨")
        
        if auto_load:
            self.load_model()
        else:
            logger.info("ğŸ†• è·³è¿‡æ¨¡å‹åŠ è½½ï¼Œä»é›¶å¼€å§‹")
    
    def enable_memory_frequency_optimization(self, memory_frequencies: List[int]):
        """
        å¯ç”¨æ˜¾å­˜+æ ¸å¿ƒé¢‘ç‡ç»„åˆä¼˜åŒ–ï¼ˆå‘åå…¼å®¹ï¼‰
        
        Args:
            memory_frequencies: æ”¯æŒçš„æ˜¾å­˜é¢‘ç‡åˆ—è¡¨
        """
        self.memory_optimization_enabled = True
        self.available_memory_frequencies = memory_frequencies
        
        logger.info(f"ğŸ”§ å¯ç”¨æ˜¾å­˜+æ ¸å¿ƒé¢‘ç‡ç»„åˆä¼˜åŒ–")
        logger.info(f"   æ”¯æŒçš„æ˜¾å­˜é¢‘ç‡: {memory_frequencies}")
        logger.info(f"   åŠ¨ä½œç©ºé—´å°†æ‰©å±•ä¸º (æ ¸å¿ƒé¢‘ç‡, æ˜¾å­˜é¢‘ç‡) ç»„åˆ")
        
        # å¦‚æœå·²æœ‰æ ¸å¿ƒé¢‘ç‡æ•°æ®ï¼Œé‡æ–°æ„å»ºç»„åˆåŠ¨ä½œç©ºé—´
        if self.available_frequencies:
            self._rebuild_action_space()
    
    def _rebuild_action_space(self):
        """é‡å»ºåŠ¨ä½œç©ºé—´ï¼ˆä»æ ¸å¿ƒé¢‘ç‡è½¬æ¢ä¸ºç»„åˆé¢‘ç‡æˆ–åä¹‹ï¼‰"""
        if not self.memory_optimization_enabled:
            # ç¦ç”¨æ˜¾å­˜é¢‘ç‡ä¼˜åŒ–æ—¶ï¼Œç¡®ä¿åŠ¨ä½œç©ºé—´åªåŒ…å«æ ¸å¿ƒé¢‘ç‡
            return
            
        # æ„å»ºæ–°çš„ç»„åˆåŠ¨ä½œç©ºé—´
        old_arm_models = self.arm_models.copy()
        old_arm_counts = self.arm_counts.copy() 
        old_arm_rewards = self.arm_rewards.copy()
        
        # æ¸…ç©ºåŸæœ‰æ¨¡å‹
        self.arm_models = {}
        self.arm_counts = {}
        self.arm_rewards = {}
        
        # è¿ç§»æ ¸å¿ƒé¢‘ç‡æ•°æ®åˆ°ç»„åˆé¢‘ç‡
        for core_freq in self.available_frequencies:
            if core_freq in old_arm_models:
                # ä¸ºæ¯ä¸ªæ˜¾å­˜é¢‘ç‡åˆ›å»ºç»„åˆåŠ¨ä½œ
                for mem_freq in self.available_memory_frequencies:
                    action = (core_freq, mem_freq)
                    # å¤åˆ¶åŸæ ¸å¿ƒé¢‘ç‡çš„æ¨¡å‹å‚æ•°
                    self.arm_models[action] = old_arm_models[core_freq].copy()
                    self.arm_counts[action] = old_arm_counts.get(core_freq, 0)
                    self.arm_rewards[action] = old_arm_rewards.get(core_freq, 0.0)
        
        logger.info(f"ğŸ”„ åŠ¨ä½œç©ºé—´é‡å»ºå®Œæˆï¼š{len(old_arm_models)}ä¸ªæ ¸å¿ƒé¢‘ç‡ â†’ {len(self.arm_models)}ä¸ªç»„åˆåŠ¨ä½œ")
    
    def _init_arm_model(self, action):
        """ä¸ºæ–°åŠ¨ä½œåˆå§‹åŒ–çº¿æ€§æ¨¡å‹ï¼ˆæ”¯æŒæ ¸å¿ƒé¢‘ç‡æˆ–ç»„åˆé¢‘ç‡ï¼‰"""
        if action not in self.arm_models:
            # ä½¿ç”¨ç¨å¤§çš„åˆå§‹æ­£åˆ™åŒ–ç¡®ä¿æ•°å€¼ç¨³å®šæ€§
            initial_reg = max(self.lambda_reg, 5.0)  # è‡³å°‘5.0çš„æ­£åˆ™åŒ–ï¼Œæé«˜æ•°å€¼ç¨³å®šæ€§
            
            self.arm_models[action] = {
                'A': initial_reg * np.eye(self.n_features, dtype=np.float64),  # ä½¿ç”¨doubleç²¾åº¦
                'b': np.zeros(self.n_features, dtype=np.float64),
                'theta': np.zeros(self.n_features, dtype=np.float64)
            }
            self.arm_counts[action] = 0
            self.arm_rewards[action] = 0.0
            
            # åŠ¨ä½œæè¿°ï¼ˆå‘åå…¼å®¹ï¼‰
            if self.memory_optimization_enabled and isinstance(action, tuple):
                action_desc = f"{action[0]}MHzæ ¸å¿ƒ+{action[1]}MHzæ˜¾å­˜"
            else:
                action_desc = f"{action}MHzæ ¸å¿ƒ"
            
            logger.debug(f"ğŸ†• åˆå§‹åŒ–åŠ¨ä½œ {action_desc} çš„çº¿æ€§æ¨¡å‹ (æ­£åˆ™åŒ–={initial_reg})")
    
    def _get_current_alpha(self) -> float:
        """è®¡ç®—å½“å‰çš„alphaå€¼ï¼ˆåº”ç”¨è¡°å‡ï¼‰"""
        if self.total_rounds == 0:
            return self.alpha
        
        # æŒ‡æ•°è¡°å‡ï¼šalpha = initial_alpha * exp(-decay_rate * rounds)
        decayed_alpha = self.initial_alpha * np.exp(-self.alpha_decay_rate * self.total_rounds)
        
        # ç¡®ä¿ä¸ä½äºæœ€å°å€¼
        current_alpha = max(decayed_alpha, self.min_alpha)
        
        return current_alpha
    
    def _get_representative_context(self) -> Optional[np.ndarray]:
        """è·å–ä»£è¡¨æ€§ä¸Šä¸‹æ–‡ï¼ˆç”¨äºä¿®å‰ªæ£€æŸ¥ï¼‰"""
        if not self.context_history:
            return None
        
        # ä½¿ç”¨æœ€è¿‘çš„ä¸Šä¸‹æ–‡å†å²ï¼ˆæœ€å¤š50ä¸ªï¼‰è®¡ç®—å¹³å‡å€¼
        recent_contexts = self.context_history[-50:]
        if len(recent_contexts) == 0:
            return None
        
        # è®¡ç®—å¹³å‡ä¸Šä¸‹æ–‡
        representative_context = np.mean(recent_contexts, axis=0)
        
        logger.debug(f"ğŸ” è®¡ç®—ä»£è¡¨æ€§ä¸Šä¸‹æ–‡: åŸºäºæœ€è¿‘{len(recent_contexts)}ä¸ªä¸Šä¸‹æ–‡")
        
        return representative_context
    
    def _should_perform_pruning_check(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰§è¡Œä¿®å‰ªæ£€æŸ¥"""
        if not self.enable_action_pruning:
            logger.debug(f"ğŸ—‚ï¸ ä¿®å‰ªæ£€æŸ¥: æœªå¯ç”¨ (enable_action_pruning=False)")
            return False
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æˆç†Ÿåº¦é—¨æ§›
        if self.total_rounds < self.pruning_maturity_threshold:
            logger.debug(f"ğŸ—‚ï¸ ä¿®å‰ªæ£€æŸ¥: æœªè¾¾æˆç†Ÿåº¦ ({self.total_rounds} < {self.pruning_maturity_threshold})")
            return False
        
        # æ£€æŸ¥æ˜¯å¦åˆ°äº†ä¿®å‰ªæ£€æŸ¥é—´éš”
        rounds_since_last_check = self.total_rounds - self.last_pruning_check
        if rounds_since_last_check < self.pruning_check_interval:
            logger.debug(f"ğŸ—‚ï¸ ä¿®å‰ªæ£€æŸ¥: é—´éš”ä¸è¶³ ({rounds_since_last_check} < {self.pruning_check_interval})")
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„é¢‘ç‡ï¼ˆè‡³å°‘ä¿ç•™2ä¸ªï¼‰
        # æ³¨æ„ï¼šavailable_frequencies å·²ç»é€šè¿‡ç»Ÿä¸€è¿‡æ»¤æ–¹æ³•å¤„ç†ï¼Œä¸åŒ…å«å·²ä¿®å‰ªé¢‘ç‡
        available_count = len(self.available_frequencies)
        if available_count <= 2:
            logger.debug(f"ğŸ—‚ï¸ ä¿®å‰ªæ£€æŸ¥: å¯ç”¨é¢‘ç‡å¤ªå°‘ ({available_count} <= 2)")
            return False
        
        logger.info(f"ğŸ—‚ï¸ ä¿®å‰ªæ£€æŸ¥: æ»¡è¶³æ¡ä»¶ (è½®æ¬¡{self.total_rounds}, è·ä¸Šæ¬¡{rounds_since_last_check}è½®, å¯ç”¨{available_count}ä¸ª)")
        return True
    
    def _get_adaptive_cascade_threshold(self) -> int:
        """è®¡ç®—è‡ªé€‚åº”çš„çº§è”ä¿®å‰ªé˜ˆå€¼"""
        if not self.adaptive_cascade_pruning or self.gpu_max_freq is None:
            return self.cascade_pruning_threshold
        
        # è‡ªé€‚åº”é˜ˆå€¼ï¼šGPUç¡¬ä»¶æœ€å¤§é¢‘ç‡çš„ä¸€åŠ
        adaptive_threshold = self.gpu_max_freq // 2
        
        logger.debug(f"ğŸ”„ è‡ªé€‚åº”çº§è”ä¿®å‰ªé˜ˆå€¼: {adaptive_threshold}MHz (GPUæœ€å¤§é¢‘ç‡{self.gpu_max_freq}MHzçš„ä¸€åŠ)")
        
        return adaptive_threshold
    
    def _perform_cascade_pruning(self, trigger_freq: int) -> list:
        """æ‰§è¡Œçº§è”ä¿®å‰ªé€»è¾‘ï¼Œè¿”å›è¢«çº§è”ä¿®å‰ªçš„é¢‘ç‡åˆ—è¡¨"""
        cascade_pruned = []
        cascade_threshold = self._get_adaptive_cascade_threshold()
        
        if trigger_freq < cascade_threshold:
            # æ‰¾åˆ°éœ€è¦çº§è”ä¿®å‰ªçš„é¢‘ç‡
            # æ³¨æ„ï¼šavailable_frequencies åº”è¯¥å·²ç»ä¸åŒ…å«å·²ä¿®å‰ªé¢‘ç‡
            available_for_evaluation = self.available_frequencies.copy()
            
            # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿ä¸åŒ…å«å·²ä¿®å‰ªé¢‘ç‡
            if self.pruned_frequencies:
                available_for_evaluation = [f for f in available_for_evaluation if f not in self.pruned_frequencies]
            
            for potential_freq in available_for_evaluation:
                if potential_freq <= trigger_freq and potential_freq != trigger_freq:
                    self.pruned_frequencies.add(potential_freq)
                    cascade_pruned.append(potential_freq)
                    
                    # è®¡ç®—çº§è”ä¿®å‰ªé¢‘ç‡çš„EDPä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    avg_edp = None
                    edp_samples = 0
                    if hasattr(self, 'edp_history') and self.edp_history:
                        freq_edp_values = []
                        for action, edp in zip(self.action_history, self.edp_history):
                            # å¤„ç†ç»„åˆé¢‘ç‡æƒ…å†µï¼Œåªæ¯”è¾ƒæ ¸å¿ƒé¢‘ç‡
                            action_freq = action[0] if isinstance(action, tuple) else action
                            if action_freq == potential_freq and edp > 0:
                                freq_edp_values.append(edp)
                        if freq_edp_values:
                            avg_edp = np.mean(freq_edp_values)
                            edp_samples = len(freq_edp_values)
                    
                    # ä¸ºçº§è”ä¿®å‰ªçš„é¢‘ç‡æ·»åŠ ä¿®å‰ªè®°å½•
                    cascade_record = {
                        'round': self.total_rounds,
                        'frequency': potential_freq,
                        'historical_avg_reward': self.arm_rewards.get(potential_freq, 0.0) / max(self.arm_counts.get(potential_freq, 1), 1),
                        'historical_avg_edp': avg_edp,
                        'edp_samples': edp_samples,
                        'exploration_count': self.arm_counts.get(potential_freq, 0),
                        'threshold': cascade_threshold,
                        'reason': f'çº§è”ä¿®å‰ª: {trigger_freq}MHz<{cascade_threshold}è¢«ä¿®å‰ªï¼Œè¿å¸¦ä¿®å‰ªæ‰€æœ‰â‰¤{trigger_freq}MHzé¢‘ç‡',
                        'pruning_type': 'cascade',
                        'cascade_trigger': trigger_freq
                    }
                    self.pruning_history.append(cascade_record)
        
        return cascade_pruned

    def _check_extreme_frequency_pruning(self, freq: int):
        """æ£€æŸ¥å¹¶æ‰§è¡Œæç«¯é¢‘ç‡å³æ—¶ä¿®å‰ª"""
        # åªåœ¨è¯¥é¢‘ç‡æœªè¢«ä¿®å‰ªæ—¶æ‰æ£€æŸ¥
        if freq in self.pruned_frequencies:
            return
        
        # æ£€æŸ¥è¯¥é¢‘ç‡æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ ·æœ¬
        count = self.arm_counts[freq]
        if count < self.extreme_pruning_min_samples:
            return
        
        # è®¡ç®—è¯¥é¢‘ç‡çš„å¹³å‡å¥–åŠ±
        avg_reward = self.arm_rewards[freq] / count
        
        # å¦‚æœå¹³å‡å¥–åŠ±æç«¯ç³Ÿç³•ï¼Œç«‹å³ä¿®å‰ª
        if avg_reward <= self.extreme_pruning_threshold:
            logger.warning(f"âš¡ æç«¯é¢‘ç‡å³æ—¶ä¿®å‰ª: {freq}MHz (å¹³å‡å¥–åŠ±: {avg_reward:.3f} <= {self.extreme_pruning_threshold})")
            
            # æ‰§è¡Œä¿®å‰ª
            self.pruned_frequencies.add(freq)
            
            # è®°å½•ä¸»è¦ä¿®å‰ªå†å²
            pruning_record = {
                'round': self.total_rounds,
                'frequency': freq,
                'historical_avg_reward': avg_reward,
                'exploration_count': count,
                'threshold': self.extreme_pruning_threshold,
                'reason': f'æç«¯é¢‘ç‡å³æ—¶ä¿®å‰ª: å¹³å‡å¥–åŠ±{avg_reward:.3f}æç«¯ç³Ÿç³•',
                'pruning_type': 'extreme_immediate'
            }
            self.pruning_history.append(pruning_record)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦çº§è”ä¿®å‰ª
            cascade_pruned = self._perform_cascade_pruning(freq)
            
            if cascade_pruned:
                logger.warning(f"ğŸ“‰ çº§è”ä¿®å‰ª: åŒæ—¶ç§»é™¤ {sorted(cascade_pruned)} MHz (â‰¤{freq}MHz)")
            
            # æ›´æ–°å¯ç”¨é¢‘ç‡åˆ—è¡¨
            self.available_frequencies = [f for f in self.available_frequencies 
                                        if f not in self.pruned_frequencies]
            
            logger.info(f"ğŸš« å³æ—¶ä¿®å‰ªå®Œæˆ: å‰©ä½™ {len(self.available_frequencies)} ä¸ªå¯ç”¨é¢‘ç‡")
    
    def _perform_action_pruning(self):
        """æ‰§è¡Œæ™ºèƒ½åŠ¨ä½œä¿®å‰ª - åŸºäºEDPç»Ÿè®¡å­¦åŠ¨æ€é˜ˆå€¼ (è‡ªé€‚åº”çš„æ°¸æ’æ ‡å°º)"""
        if not self._should_perform_pruning_check():
            return
        
        # æ›´æ–°ä¸Šæ¬¡ä¿®å‰ªæ£€æŸ¥æ—¶é—´
        self.last_pruning_check = self.total_rounds
        
        # æ³¨æ„ï¼šavailable_frequencies åº”è¯¥å·²ç»é€šè¿‡ç»Ÿä¸€è¿‡æ»¤ï¼Œä¸åŒ…å«å·²ä¿®å‰ªé¢‘ç‡
        # ä½†ä¸ºäº†å®‰å…¨èµ·è§ï¼Œè¿™é‡Œä»ç„¶è¿›è¡Œæ£€æŸ¥
        available_for_evaluation = self.available_frequencies.copy()
        
        # å®‰å…¨æ£€æŸ¥ï¼šç§»é™¤å¯èƒ½æ„å¤–åŒ…å«çš„å·²ä¿®å‰ªé¢‘ç‡
        if self.pruned_frequencies:
            before_count = len(available_for_evaluation)
            available_for_evaluation = [f for f in available_for_evaluation if f not in self.pruned_frequencies]
            if len(available_for_evaluation) != before_count:
                logger.warning(f"âš ï¸ available_frequenciesåŒ…å«å·²ä¿®å‰ªé¢‘ç‡ï¼Œå·²æ¸…ç† ({before_count} -> {len(available_for_evaluation)})")
        
        if len(available_for_evaluation) <= 2:
            logger.debug("ğŸ“Š å¯ç”¨é¢‘ç‡å¤ªå°‘ï¼Œè·³è¿‡ä¿®å‰ª")
            return
        
        # æ£€æŸ¥æ˜¯å¦æœ‰EDPå†å²æ•°æ®
        if not hasattr(self, 'edp_history') or not self.edp_history:
            logger.debug("ğŸ“Š æ— EDPå†å²æ•°æ®ï¼Œè·³è¿‡åŸºäºEDPçš„ä¿®å‰ª")
            return
        
        # è®¡ç®—æ‰€æœ‰é¢‘ç‡çš„å†å²å¹³å‡EDP
        historical_edp_data = {}
        for freq in available_for_evaluation:
            exploration_count = self.arm_counts.get(freq, 0)
            if exploration_count >= self.min_exploration_for_pruning:
                # æ”¶é›†è¯¥é¢‘ç‡çš„æ‰€æœ‰EDPè®°å½•
                freq_edp_values = []
                for action, edp in zip(self.action_history, self.edp_history):
                    # å¤„ç†ç»„åˆé¢‘ç‡æƒ…å†µï¼Œåªæ¯”è¾ƒæ ¸å¿ƒé¢‘ç‡
                    action_freq = action[0] if isinstance(action, tuple) else action
                    if action_freq == freq and edp > 0:  # åªè€ƒè™‘æœ‰æ•ˆçš„EDPå€¼
                        freq_edp_values.append(edp)
                
                if len(freq_edp_values) >= self.min_exploration_for_pruning:
                    avg_edp = np.mean(freq_edp_values)
                    historical_edp_data[freq] = {
                        'avg_edp': avg_edp,
                        'exploration_count': len(freq_edp_values),
                        'edp_values': freq_edp_values
                    }
        
        if len(historical_edp_data) < 2:
            logger.debug(f"ğŸ“Š æœ‰å……åˆ†EDPå†å²çš„é¢‘ç‡å¤ªå°‘({len(historical_edp_data)}ä¸ª)ï¼Œè·³è¿‡ä¿®å‰ª")
            return
        
        # æ‰¾åˆ°EDPè¡¨ç°æœ€å¥½çš„é¢‘ç‡ (EDPè¶Šå°è¶Šå¥½)
        best_freq = min(historical_edp_data.keys(), key=lambda f: historical_edp_data[f]['avg_edp'])
        best_avg_edp = historical_edp_data[best_freq]['avg_edp']
        
        # è®¡ç®—åŸºäºæ ‡å‡†å·®çš„åŠ¨æ€EDPé˜ˆå€¼
        all_avg_edp_values = [data['avg_edp'] for data in historical_edp_data.values()]
        edp_std = np.std(all_avg_edp_values) if len(all_avg_edp_values) > 1 else 0.1
        
        # åŠ¨æ€é˜ˆå€¼ï¼šé…ç½®çš„å€æ•° * EDPæ ‡å‡†å·®
        # ä½¿ç”¨ç°æœ‰çš„ pruning_threshold é…ç½®ä½œä¸ºæ ‡å‡†å·®å€æ•°
        edp_threshold = self.pruning_threshold * max(edp_std, 0.05)  # æœ€å°é˜ˆå€¼0.05JÂ·s
        
        logger.debug(f"ğŸ“Š EDPç»Ÿè®¡: å¹³å‡å€¼èŒƒå›´{min(all_avg_edp_values):.3f}-{max(all_avg_edp_values):.3f}JÂ·s, "
                    f"æ ‡å‡†å·®{edp_std:.3f}JÂ·s, åŠ¨æ€é˜ˆå€¼{edp_threshold:.3f}JÂ·s")
        
        # æ‰§è¡ŒåŸºäºEDPçš„ä¿®å‰ªé€»è¾‘
        newly_pruned = []
        
        for freq, data in historical_edp_data.items():
            if freq == best_freq:
                continue  # ä¸ä¿®å‰ªEDPè¡¨ç°æœ€ä¼˜çš„é¢‘ç‡
            
            # æ£€æŸ¥ä¿®å‰ªæ¡ä»¶
            edp_gap = data['avg_edp'] - best_avg_edp  # EDPå·®è·ï¼ˆæ­£å€¼è¡¨ç¤ºæ›´å·®ï¼‰
            exploration_count = data['exploration_count']
            
            # ä¿®å‰ªæ¡ä»¶ï¼š
            # 1. å†å²å¹³å‡EDPè¿œé«˜äºæœ€ä¼˜ï¼ˆèƒ½æ•ˆå·®ï¼‰
            # 2. å·²ç»è¢«å……åˆ†æ¢ç´¢
            # 3. ä¸æ˜¯æœ€åå‰©ä½™çš„å‡ ä¸ªé¢‘ç‡
            if (edp_gap > edp_threshold and 
                exploration_count >= self.min_exploration_for_pruning and
                len(available_for_evaluation) - len(newly_pruned) > 2):  # è‡³å°‘ä¿ç•™2ä¸ªé¢‘ç‡
                
                self.pruned_frequencies.add(freq)
                newly_pruned.append(freq)
                
                # è®°å½•EDPä¿®å‰ªå†å²
                pruning_record = {
                    'round': self.total_rounds,
                    'frequency': freq,
                    'historical_avg_edp': data['avg_edp'],
                    'best_historical_edp': best_avg_edp,
                    'best_frequency': best_freq,
                    'edp_gap': edp_gap,
                    'exploration_count': exploration_count,
                    'edp_threshold': edp_threshold,
                    'edp_std': edp_std,
                    'edp_samples': len(data['edp_values']),
                    'std_multiplier': self.pruning_threshold,
                    'reason': f'å†å²å¹³å‡EDPæ¯”æœ€ä¼˜é«˜{edp_gap:.3f}JÂ·s > {edp_threshold:.3f}JÂ·s({self.pruning_threshold:.1f}Ã—æ ‡å‡†å·®)',
                    'permanently_banned': True,
                    'pruning_method': 'EDP_dynamic_threshold'
                }
                self.pruning_history.append(pruning_record)
        
        # æ‰§è¡Œçº§è”ä¿®å‰ªï¼ˆä¸ºæ‰€æœ‰æ–°ä¿®å‰ªçš„é¢‘ç‡ï¼‰
        all_cascade_pruned = []
        for freq in newly_pruned:
            cascade_pruned = self._perform_cascade_pruning(freq)
            all_cascade_pruned.extend(cascade_pruned)
        
        # è¾“å‡ºä¿®å‰ªç»“æœ
        if newly_pruned or all_cascade_pruned:
            total_pruned = len(newly_pruned) + len(all_cascade_pruned)
            logger.info(f"ğŸ—‚ï¸ [EDPæ™ºèƒ½ä¿®å‰ª] è½®æ¬¡{self.total_rounds}: ä¿®å‰ª{total_pruned}ä¸ªé¢‘ç‡")
            logger.info(f"   EDPæœ€ä¼˜é¢‘ç‡: {best_freq}MHz (å¹³å‡EDP: {best_avg_edp:.3f}JÂ·s)")
            logger.info(f"   åŠ¨æ€ä¿®å‰ªé˜ˆå€¼: {edp_threshold:.3f}JÂ·s ({self.pruning_threshold:.1f}Ã—æ ‡å‡†å·®{edp_std:.3f})")
            
            # æ˜¾ç¤ºåŸºäºEDPä¸»åŠ¨ä¿®å‰ªçš„é¢‘ç‡
            for freq in newly_pruned:
                record = next(r for r in self.pruning_history if r['frequency'] == freq and r['round'] == self.total_rounds and 'cascade_trigger' not in r)
                logger.info(f"   ğŸ¯ EDPä¿®å‰ª: {freq}MHz (å¹³å‡EDP: {record['historical_avg_edp']:.3f}JÂ·s, "
                          f"å·®è·: +{record['edp_gap']:.3f}JÂ·s, æ ·æœ¬: {record['edp_samples']}ä¸ª)")
            
            # æ˜¾ç¤ºçº§è”ä¿®å‰ªçš„é¢‘ç‡
            if all_cascade_pruned:
                cascade_threshold = self._get_adaptive_cascade_threshold()
                logger.info(f"   ğŸ”— çº§è”ä¿®å‰ª(<{cascade_threshold}MHzè§¦å‘): {sorted(all_cascade_pruned)}MHz")
                for freq in sorted(all_cascade_pruned):
                    cascade_record = next(r for r in self.pruning_history if r['frequency'] == freq and r['round'] == self.total_rounds and 'cascade_trigger' in r)
                    # è·å–çº§è”ä¿®å‰ªé¢‘ç‡çš„EDPä¿¡æ¯
                    if freq in historical_edp_data:
                        edp_info = f"å¹³å‡EDP: {historical_edp_data[freq]['avg_edp']:.3f}JÂ·s"
                    else:
                        edp_info = f"æ¢ç´¢: {cascade_record['exploration_count']}æ¬¡"
                    logger.info(f"      â†³ {freq}MHz ({edp_info})")
            
            # æ³¨æ„: available_frequencies çš„åŒæ­¥ç”±å¤–éƒ¨è°ƒç”¨æ–¹è´Ÿè´£
            # è¿™é‡Œåªè´Ÿè´£ç»´æŠ¤ pruned_frequencies çŠ¶æ€
            active_count = len([f for f in self.available_frequencies if f not in self.pruned_frequencies])
            logger.info(f"   å‰©ä½™æ´»è·ƒé¢‘ç‡: {active_count}ä¸ª (éœ€å¤–éƒ¨åŒæ­¥available_frequencies)")
        else:
            logger.debug(f"ğŸ“Š EDPä¿®å‰ªæ£€æŸ¥å®Œæˆï¼Œæ— é¢‘ç‡éœ€è¦ä¿®å‰ª (EDPæœ€ä¼˜: {best_freq}MHz, å¹³å‡EDP: {best_avg_edp:.3f}JÂ·s, "
                        f"åŠ¨æ€é˜ˆå€¼: {edp_threshold:.3f}JÂ·s)")
    
    def _update_theta(self, action):
        """æ›´æ–°åŠ¨ä½œçš„å‚æ•°å‘é‡ theta = A^-1 * bï¼ˆæ”¯æŒæ ¸å¿ƒé¢‘ç‡æˆ–ç»„åˆé¢‘ç‡ï¼‰"""
        model = self.arm_models[action]
        try:
            # ä½¿ç”¨æ›´ç¨³å®šçš„æ±‚è§£æ–¹æ³•
            model['theta'] = np.linalg.solve(model['A'], model['b']).astype(np.float32)
        except np.linalg.LinAlgError:
            # å¦‚æœçŸ©é˜µå¥‡å¼‚ï¼Œæ·»åŠ æ›´å¤§çš„æ­£åˆ™åŒ–
            # åŠ¨ä½œæè¿°ï¼ˆå‘åå…¼å®¹ï¼‰
            if self.memory_optimization_enabled and isinstance(action, tuple):
                action_desc = f"{action[0]}MHzæ ¸å¿ƒ+{action[1]}MHzæ˜¾å­˜"
            else:
                action_desc = f"{action}MHzæ ¸å¿ƒ"
            
            logger.warning(f"åŠ¨ä½œ {action_desc} çš„AçŸ©é˜µå¥‡å¼‚ï¼Œå¢åŠ æ­£åˆ™åŒ–")
            model['A'] += 0.1 * np.eye(self.n_features)
            model['theta'] = np.linalg.solve(model['A'], model['b']).astype(np.float32)
    
    def update_action_space(self, frequencies: List[int]):
        """æ›´æ–°å¯ç”¨é¢‘ç‡åˆ—è¡¨ - è¿‡æ»¤æ‰è¢«ç¦ç”¨çš„é¢‘ç‡"""
        if not frequencies:
            logger.warning("âš ï¸ æ”¶åˆ°ç©ºçš„é¢‘ç‡åˆ—è¡¨ï¼Œä¿æŒå½“å‰åŠ¨ä½œç©ºé—´ä¸å˜")
            return
        
        # è¿‡æ»¤æ‰è¢«ç¦ç”¨çš„æ ¸å¿ƒé¢‘ç‡
        filtered_frequencies = [freq for freq in frequencies if freq not in self.disabled_core_frequencies]
        
        if not filtered_frequencies:
            logger.warning("âš ï¸ è¿‡æ»¤åæ²¡æœ‰å¯ç”¨é¢‘ç‡ï¼Œä¿æŒå½“å‰åŠ¨ä½œç©ºé—´ä¸å˜")
            return
        
        if len(filtered_frequencies) != len(frequencies):
            logger.info(f"ğŸš« è¿‡æ»¤ç¦ç”¨é¢‘ç‡: {len(frequencies)} -> {len(filtered_frequencies)} ä¸ªé¢‘ç‡")
            logger.debug(f"   ç¦ç”¨çš„é¢‘ç‡: {sorted(set(frequencies) - set(filtered_frequencies))}")
        
        old_freqs = set(self.available_frequencies)
        new_freqs = set(filtered_frequencies)
        
        # ä¸ºæ–°é¢‘ç‡åˆå§‹åŒ–æ¨¡å‹
        added_freqs = new_freqs - old_freqs
        for freq in added_freqs:
            self._init_arm_model(freq)
            logger.debug(f"â• æ·»åŠ æ–°é¢‘ç‡: {freq}MHz")
        
        # ç§»é™¤çš„é¢‘ç‡ï¼ˆå¯èƒ½æ˜¯è¢«è°ƒç”¨æ–¹è¿‡æ»¤æ‰çš„ï¼‰
        removed_freqs = old_freqs - new_freqs
        if removed_freqs:
            logger.debug(f"â– ç§»é™¤é¢‘ç‡: {sorted(removed_freqs)}")
        
        # æ›´æ–°é¢‘ç‡åˆ—è¡¨
        sorted_frequencies = sorted(filtered_frequencies)
        logger.info(f"ğŸ¯ åŠ¨ä½œç©ºé—´æ›´æ–°: {sorted_frequencies} (å…±{len(filtered_frequencies)}ä¸ªé¢‘ç‡)")
        
        self.available_frequencies = filtered_frequencies.copy()
        logger.debug(f"ğŸ”„ é¢‘ç‡ç©ºé—´çŠ¶æ€: å¯ç”¨{len(filtered_frequencies)}ä¸ª, å·²ä¿®å‰ª{len(self.pruned_frequencies)}ä¸ª")
    
    def add_actual_frequency(self, actual_freq: int):
        """
        åŠ¨æ€æ·»åŠ å®é™…ä½¿ç”¨çš„é¢‘ç‡åˆ°åŠ¨ä½œç©ºé—´
        å½“ç›®æ ‡é¢‘ç‡è®¾ç½®å¤±è´¥æ—¶ï¼Œæ·»åŠ å®é™…é‡‡ç”¨çš„é¢‘ç‡ä»¥æ‰©å±•åŠ¨ä½œç©ºé—´
        
        Args:
            actual_freq: å®é™…è®¾ç½®æˆåŠŸçš„é¢‘ç‡ï¼ˆMHzï¼‰
        """
        if actual_freq in self.available_frequencies:
            logger.debug(f"ğŸ”„ é¢‘ç‡ {actual_freq}MHz å·²å­˜åœ¨äºåŠ¨ä½œç©ºé—´ä¸­")
            return
        
        if actual_freq in self.disabled_core_frequencies:
            logger.warning(f"âš ï¸ é¢‘ç‡ {actual_freq}MHz å·²è¢«ç¦ç”¨ï¼Œä¸èƒ½æ·»åŠ åˆ°åŠ¨ä½œç©ºé—´")
            return
        
        if actual_freq in self.pruned_frequencies:
            logger.warning(f"âš ï¸ é¢‘ç‡ {actual_freq}MHz å·²è¢«ä¿®å‰ªï¼Œä¸èƒ½æ·»åŠ åˆ°åŠ¨ä½œç©ºé—´")
            return
        
        # æ·»åŠ åˆ°å¯ç”¨é¢‘ç‡åˆ—è¡¨
        self.available_frequencies.append(actual_freq)
        self.available_frequencies.sort()  # ä¿æŒæ’åº
        
        # åˆå§‹åŒ–æ–°é¢‘ç‡çš„æ¨¡å‹
        self._init_arm_model(actual_freq)
        
        logger.info(f"âœ… åŠ¨æ€æ·»åŠ å®é™…é¢‘ç‡ {actual_freq}MHz åˆ°åŠ¨ä½œç©ºé—´ (æ€»è®¡{len(self.available_frequencies)}ä¸ªé¢‘ç‡)")
        logger.debug(f"ğŸ”„ æ›´æ–°åçš„åŠ¨ä½œç©ºé—´: {sorted(self.available_frequencies)}")
    
    def select_action(self, context: np.ndarray, available_frequencies: List[int]):
        """
        ä½¿ç”¨LinUCBç®—æ³•é€‰æ‹©æœ€ä¼˜åŠ¨ä½œ - æ”¯æŒæ ¸å¿ƒé¢‘ç‡æˆ–ç»„åˆé¢‘ç‡ä¼˜åŒ–
        
        Args:
            context: å·¥ä½œè´Ÿè½½ä¸Šä¸‹æ–‡ç‰¹å¾ (n_featuresç»´)
            available_frequencies: å½“å‰å¯ç”¨æ ¸å¿ƒé¢‘ç‡åˆ—è¡¨
        
        Returns:
            selected_action: é€‰æ‹©çš„åŠ¨ä½œ (é¢‘ç‡MHz æˆ– (æ ¸å¿ƒé¢‘ç‡MHz, æ˜¾å­˜é¢‘ç‡MHz) å…ƒç»„)
        """
        if not available_frequencies:
            raise ValueError("å¯ç”¨é¢‘ç‡åˆ—è¡¨ä¸ºç©º")
        
        # æ„å»ºåŠ¨ä½œç©ºé—´ - ä½¿ç”¨æ–°çš„æœ‰æ•ˆåŠ¨ä½œè¿‡æ»¤é€»è¾‘
        if self.memory_optimization_enabled:
            # ç»„åˆé¢‘ç‡æ¨¡å¼ï¼šæ„å»ºæœ‰æ•ˆçš„ (æ ¸å¿ƒé¢‘ç‡, æ˜¾å­˜é¢‘ç‡) ç»„åˆ
            available_actions = []
            for core_freq in available_frequencies:
                if core_freq in self.disabled_core_frequencies:
                    continue  # è·³è¿‡è¢«ç¦ç”¨çš„æ ¸å¿ƒé¢‘ç‡
                    
                for mem_freq in self.available_memory_frequencies:
                    action = (core_freq, mem_freq)
                    if self.is_action_allowed(action):
                        available_actions.append(action)
        else:
            # æ ¸å¿ƒé¢‘ç‡æ¨¡å¼ï¼šåªä½¿ç”¨æœªè¢«ç¦ç”¨çš„æ ¸å¿ƒé¢‘ç‡
            available_actions = [freq for freq in available_frequencies 
                               if freq not in self.disabled_core_frequencies]
        
        if not available_actions:
            logger.error("âŒ æ‰€æœ‰åŠ¨ä½œéƒ½è¢«ç¦ç”¨äº†ï¼")
            # åº”æ€¥æƒ…å†µï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ ¸å¿ƒé¢‘ç‡
            if available_frequencies:
                if self.memory_optimization_enabled and self.available_memory_frequencies:
                    emergency_action = (available_frequencies[0], self.available_memory_frequencies[0])
                else:
                    emergency_action = available_frequencies[0]
                logger.warning(f"ğŸš¨ ä½¿ç”¨åº”æ€¥åŠ¨ä½œ: {emergency_action}")
                available_actions = [emergency_action]
            else:
                raise ValueError("æ²¡æœ‰ä»»ä½•å¯ç”¨çš„åŠ¨ä½œï¼")
        
        # ç¡®ä¿æ‰€æœ‰åŠ¨ä½œéƒ½æœ‰æ¨¡å‹
        for action in available_actions:
            self._init_arm_model(action)
        
        # å­¦ä¹ é˜¶æ®µï¼šä»å¤§åˆ°å°é¡ºåºéå†æ‰€æœ‰åŠ¨ä½œ
        if not self.learning_phase_complete:
            # åˆå§‹åŒ–å­¦ä¹ åŠ¨ä½œåˆ—è¡¨ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡æ—¶è®¾ç½®ï¼‰
            if not hasattr(self, '_learning_action_list'):
                if self.memory_optimization_enabled:
                    # ç»„åˆé¢‘ç‡æ¨¡å¼ï¼šæŒ‰æ ¸å¿ƒé¢‘ç‡ä»é«˜åˆ°ä½ï¼Œæ¯ä¸ªæ ¸å¿ƒé¢‘ç‡æ­é…æ‰€æœ‰æ˜¾å­˜é¢‘ç‡
                    self._learning_action_list = []
                    for core_freq in sorted(available_frequencies, reverse=True):
                        for mem_freq in sorted(self.available_memory_frequencies, reverse=True):
                            self._learning_action_list.append((core_freq, mem_freq))
                else:
                    # æ ¸å¿ƒé¢‘ç‡æ¨¡å¼ï¼šæŒ‰é¢‘ç‡ä»é«˜åˆ°ä½
                    self._learning_action_list = sorted(available_frequencies, reverse=True)
                
                logger.info(f"ğŸ“š åˆå§‹åŒ–å­¦ä¹ é˜¶æ®µåŠ¨ä½œåˆ—è¡¨: {len(self._learning_action_list)}ä¸ªåŠ¨ä½œ")
                
            # é‡å‘½åç´¢å¼•å˜é‡ä»¥åæ˜ æ–°çš„åŠ¨ä½œæ¦‚å¿µ
            if not hasattr(self, 'learning_action_index'):
                self.learning_action_index = getattr(self, 'learning_frequency_index', 0)
            
            # è·³è¿‡å·²ç»å¤±è´¥çš„åŠ¨ä½œï¼Œç»§ç»­ä¸‹ä¸€ä¸ªå¯ç”¨åŠ¨ä½œ
            while self.learning_action_index < len(self._learning_action_list):
                candidate_action = self._learning_action_list[self.learning_action_index]
                
                # æ£€æŸ¥å€™é€‰åŠ¨ä½œæ˜¯å¦ä»ç„¶å¯ç”¨
                if candidate_action in available_actions:
                    self.learning_action_index += 1
                    
                    # åŠ¨ä½œæè¿°ï¼ˆå‘åå…¼å®¹ï¼‰
                    if self.memory_optimization_enabled and isinstance(candidate_action, tuple):
                        action_desc = f"{candidate_action[0]}MHzæ ¸å¿ƒ+{candidate_action[1]}MHzæ˜¾å­˜"
                    else:
                        action_desc = f"{candidate_action}MHzæ ¸å¿ƒ"
                    
                    logger.info(f"ğŸ“š [å­¦ä¹ é˜¶æ®µéå†] é€‰æ‹©åŠ¨ä½œ {action_desc} ({self.learning_action_index}/{len(self._learning_action_list)}) - ä»é«˜åˆ°ä½")
                    return candidate_action
                else:
                    # è·³è¿‡å¤±è´¥æˆ–ä¸å¯ç”¨çš„åŠ¨ä½œ
                    self.learning_action_index += 1
                    
                    # åŠ¨ä½œæè¿°ï¼ˆå‘åå…¼å®¹ï¼‰
                    if self.memory_optimization_enabled and isinstance(candidate_action, tuple):
                        action_desc = f"{candidate_action[0]}MHzæ ¸å¿ƒ+{candidate_action[1]}MHzæ˜¾å­˜"
                    else:
                        action_desc = f"{candidate_action}MHzæ ¸å¿ƒ"
                    
                    logger.info(f"â­ï¸ [å­¦ä¹ é˜¶æ®µéå†] è·³è¿‡ä¸å¯ç”¨åŠ¨ä½œ {action_desc} ({self.learning_action_index}/{len(self._learning_action_list)})")
                    continue
            
            # å®Œæˆå­¦ä¹ é˜¶æ®µéå†
            self.learning_phase_complete = True
            logger.info(f"âœ… å­¦ä¹ é˜¶æ®µéå†å®Œæˆï¼Œå¼€å§‹LinUCBç®—æ³•é€‰æ‹©")
        
        # æ­£å¸¸LinUCBé€‰æ‹©é€»è¾‘
        current_alpha = self._get_current_alpha()
        fallback_confidence = current_alpha * 10.0
        
        # è®¡ç®—æ¯ä¸ªåŠ¨ä½œçš„UCBå€¼
        ucb_values = {}
        predictions = {}
        confidence_widths = {}
        
        for action in available_actions:
            model = self.arm_models[action]
            
            # é¢„æµ‹å¥–åŠ±: theta^T * context
            predicted_reward = np.dot(model['theta'], context)
            
            # è®¡ç®—ç½®ä¿¡åŒºé—´å®½åº¦: alpha * sqrt(context^T * A^-1 * context)
            try:
                A_inv_context = np.linalg.solve(model['A'], context)
                quadratic_form = np.dot(context, A_inv_context)
                
                # æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§
                if quadratic_form < 0:
                    if abs(quadratic_form) < 1e-10:
                        quadratic_form = 1e-10
                        
                        # åŠ¨ä½œæè¿°ï¼ˆå‘åå…¼å®¹ï¼‰
                        if self.memory_optimization_enabled and isinstance(action, tuple):
                            action_desc = f"{action[0]}MHzæ ¸å¿ƒ+{action[1]}MHzæ˜¾å­˜"
                        else:
                            action_desc = f"{action}MHzæ ¸å¿ƒ"
                        logger.debug(f"åŠ¨ä½œ {action_desc} äºŒæ¬¡å‹æ•°å€¼è¯¯å·®ä¿®æ­£")
                    else:
                        # åŠ¨ä½œæè¿°ï¼ˆå‘åå…¼å®¹ï¼‰
                        if self.memory_optimization_enabled and isinstance(action, tuple):
                            action_desc = f"{action[0]}MHzæ ¸å¿ƒ+{action[1]}MHzæ˜¾å­˜"
                        else:
                            action_desc = f"{action}MHzæ ¸å¿ƒ"
                        logger.warning(f"åŠ¨ä½œ {action_desc} AçŸ©é˜µä¸ç¨³å®šï¼ŒäºŒæ¬¡å‹={quadratic_form:.3e}")
                        confidence_width = fallback_confidence
                        quadratic_form = None
                elif np.isnan(quadratic_form) or np.isinf(quadratic_form):
                    # åŠ¨ä½œæè¿°ï¼ˆå‘åå…¼å®¹ï¼‰
                    if self.memory_optimization_enabled and isinstance(action, tuple):
                        action_desc = f"{action[0]}MHzæ ¸å¿ƒ+{action[1]}MHzæ˜¾å­˜"
                    else:
                        action_desc = f"{action}MHzæ ¸å¿ƒ"
                    logger.warning(f"åŠ¨ä½œ {action_desc} äºŒæ¬¡å‹è®¡ç®—å¼‚å¸¸: {quadratic_form}")
                    confidence_width = fallback_confidence
                    quadratic_form = None
                
                if quadratic_form is not None:
                    confidence_width = current_alpha * np.sqrt(quadratic_form)
                    
            except np.linalg.LinAlgError as e:
                confidence_width = fallback_confidence
                # åŠ¨ä½œæè¿°ï¼ˆå‘åå…¼å®¹ï¼‰
                if self.memory_optimization_enabled and isinstance(action, tuple):
                    action_desc = f"{action[0]}MHzæ ¸å¿ƒ+{action[1]}MHzæ˜¾å­˜"
                else:
                    action_desc = f"{action}MHzæ ¸å¿ƒ"
                logger.warning(f"åŠ¨ä½œ {action_desc} AçŸ©é˜µæ±‚è§£å¤±è´¥ ({e})")
            
            # UCBå€¼ = é¢„æµ‹å¥–åŠ± + ç½®ä¿¡åŒºé—´
            ucb_value = predicted_reward + confidence_width
            
            ucb_values[action] = ucb_value
            predictions[action] = predicted_reward
            confidence_widths[action] = confidence_width
            
            # åŠ¨ä½œæè¿°ï¼ˆå‘åå…¼å®¹ï¼‰
            if self.memory_optimization_enabled and isinstance(action, tuple):
                action_desc = f"{action[0]}MHzæ ¸å¿ƒ+{action[1]}MHzæ˜¾å­˜"
            else:
                action_desc = f"{action}MHzæ ¸å¿ƒ"
            
            logger.debug(f"  åŠ¨ä½œ{action_desc}: é¢„æµ‹={predicted_reward:.3f}, "
                        f"ç½®ä¿¡åŒºé—´={confidence_width:.3f}, UCB={ucb_value:.3f}")
        
        # é€‰æ‹©UCBå€¼æœ€å¤§çš„åŠ¨ä½œ
        selected_action = max(ucb_values.keys(), key=lambda a: ucb_values[a])
        
        # åŠ¨ä½œæè¿°ï¼ˆå‘åå…¼å®¹ï¼‰
        if self.memory_optimization_enabled and isinstance(selected_action, tuple):
            action_desc = f"{selected_action[0]}MHzæ ¸å¿ƒ+{selected_action[1]}MHzæ˜¾å­˜"
        else:
            action_desc = f"{selected_action}MHzæ ¸å¿ƒ"
        
        logger.info(f"ğŸ¯ [Contextual LinUCB] é€‰æ‹©åŠ¨ä½œ {action_desc}, "
                   f"é¢„æµ‹å¥–åŠ±={predictions[selected_action]:.3f}, "
                   f"ç½®ä¿¡åŒºé—´={confidence_widths[selected_action]:.3f}, "
                   f"UCB={ucb_values[selected_action]:.3f}, "
                   f"é€‰æ‹©æ¬¡æ•°={self.arm_counts[selected_action] + 1}, "
                   f"å½“å‰Î±={current_alpha:.3f}")
        
        return selected_action
    
    def update(self, context: np.ndarray, action, reward: float, edp_value: Optional[float] = None):
        """
        æ›´æ–°æ¨¡å‹å‚æ•°ï¼ˆæ”¯æŒæ ¸å¿ƒé¢‘ç‡æˆ–ç»„åˆé¢‘ç‡åŠ¨ä½œï¼‰
        
        Args:
            context: ä¸Šä¸‹æ–‡ç‰¹å¾
            action: é€‰æ‹©çš„åŠ¨ä½œ (é¢‘ç‡MHz æˆ– (æ ¸å¿ƒé¢‘ç‡MHz, æ˜¾å­˜é¢‘ç‡MHz) å…ƒç»„)
            reward: è§‚å¯Ÿåˆ°çš„å¥–åŠ±
            edp_value: åŸå§‹EDPå€¼ (å¯é€‰ï¼Œç”¨äºæ€§èƒ½é€€åŒ–æ£€æµ‹)
        """
        # ç¡®ä¿åŠ¨ä½œæœ‰æ¨¡å‹
        self._init_arm_model(action)
        
        # æ›´æ–°è¯¥åŠ¨ä½œçš„çº¿æ€§æ¨¡å‹
        model = self.arm_models[action]
        
        # æ›´æ–° A = A + context * context^T
        outer_product = np.outer(context, context)
        model['A'] += outer_product
        
        
        # æ›´æ–° b = b + reward * context  
        model['b'] += reward * context
        
        # é‡æ–°è®¡ç®— theta = A^-1 * b
        self._update_theta(action)
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.total_rounds += 1
        self.total_reward += reward
        self.reward_history.append(reward)
        self.action_history.append(action)
        self.context_history.append(context.copy())
        # ğŸ”§ ä¿®å¤å†å²æ•°ç»„é•¿åº¦ä¸åŒ¹é…é—®é¢˜ï¼šç¡®ä¿edp_historyä¸action_historyé•¿åº¦ä¸€è‡´
        if edp_value is not None:
            self.edp_history.append(edp_value)
        else:
            # å¦‚æœæ²¡æœ‰EDPå€¼ï¼Œä½¿ç”¨é»˜è®¤å€¼å ä½ï¼Œç¡®ä¿æ•°ç»„é•¿åº¦ä¸€è‡´
            self.edp_history.append(0.0)  # ä½¿ç”¨0.0ä½œä¸ºé»˜è®¤EDPå ä½å€¼
            logger.debug(f"âš ï¸ è½®æ¬¡{self.total_rounds}: EDPå€¼ä¸ºNoneï¼Œä½¿ç”¨0.0å ä½")
        self.arm_rewards[action] += reward
        self.arm_counts[action] += 1  # å¢åŠ è¯¥åŠ¨ä½œçš„é€‰æ‹©æ¬¡æ•°
        
        # æ›´æ–°å…ƒæ•°æ®
        self.metadata['updated_at'] = datetime.now().isoformat()
        self.metadata['total_rounds'] = self.total_rounds
        self.metadata['avg_reward'] = self.total_reward / max(self.total_rounds, 1)
        
        # åŠ¨ä½œæè¿°ï¼ˆå‘åå…¼å®¹ï¼‰
        if self.memory_optimization_enabled and isinstance(action, tuple):
            action_desc = f"{action[0]}MHzæ ¸å¿ƒ+{action[1]}MHzæ˜¾å­˜"
        else:
            action_desc = f"{action}MHzæ ¸å¿ƒ"
        
        logger.debug(f"ğŸ“ˆ æ›´æ–°åŠ¨ä½œ {action_desc} æ¨¡å‹, å¥–åŠ±={reward:.3f}, "
                    f"ç´¯ç§¯å¥–åŠ±={self.arm_rewards[action]:.3f}")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿›è¡Œæç«¯é¢‘ç‡å³æ—¶ä¿®å‰ª
        if (self.enable_extreme_pruning and 
            self.total_rounds <= self.extreme_pruning_max_rounds):
            self._check_extreme_frequency_pruning(action)
    
    def get_model_stats(self) -> dict:
        """è·å–æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯"""
        # è®¡ç®—æ¯ä¸ªé¢‘ç‡çš„å¹³å‡å¥–åŠ±
        avg_rewards = {}
        for freq in self.arm_models.keys():
            if self.arm_counts[freq] > 0:
                avg_rewards[freq] = self.arm_rewards[freq] / self.arm_counts[freq]
            else:
                avg_rewards[freq] = 0.0
        
        # æœ€è¿‘å¥–åŠ±
        recent_rewards = self.reward_history[-50:] if self.reward_history else []
        
        current_alpha = self._get_current_alpha()
        stats = {
            'total_rounds': self.total_rounds,
            'avg_reward': self.total_reward / max(self.total_rounds, 1),
            'recent_avg_reward': np.mean(recent_rewards) if recent_rewards else 0.0,
            'n_arms': len(self.arm_models),
            'arm_counts': dict(self.arm_counts),
            'arm_avg_rewards': avg_rewards,
            'exploration_strategy': 'LinUCB',
            'algorithm': 'contextual_bandit',
            'current_alpha': current_alpha,
            'initial_alpha': self.initial_alpha,
            'alpha_decay_rate': self.alpha_decay_rate,
            'min_alpha': self.min_alpha,
            'converged': self.is_converged,
            'metadata': self.metadata.copy(),
            # æ™ºèƒ½ä¿®å‰ªç»Ÿè®¡
            'action_pruning_enabled': self.enable_action_pruning,
            'pruned_frequencies_count': len(self.pruned_frequencies),
            'pruned_frequencies': sorted(list(self.pruned_frequencies)),
            'pruning_operations_count': len(self.pruning_history),
            'active_frequencies_count': len([f for f in self.available_frequencies if f not in self.pruned_frequencies]),
            # çº§è”ä¿®å‰ªç»Ÿè®¡
            'cascade_pruning_count': len([r for r in self.pruning_history if 'cascade_trigger' in r]),
            'direct_pruning_count': len([r for r in self.pruning_history if 'cascade_trigger' not in r])
        }
        
        return stats
    
    def save_model(self, filename: str = None):
        """ä¿å­˜æ¨¡å‹"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"contextual_linucb_model_{timestamp}.pkl"
        
        filepath = self.model_dir / filename
        
        # å‡†å¤‡ä¿å­˜æ•°æ®
        model_data = {
            'arm_models': self.arm_models,
            'available_frequencies': self.available_frequencies,
            'total_rounds': self.total_rounds,
            'total_reward': self.total_reward,
            'reward_history': self.reward_history,
            'action_history': self.action_history,
            'context_history': self.context_history,
            'edp_history': self.edp_history,
            'arm_counts': self.arm_counts,
            'arm_rewards': self.arm_rewards,
            'exploitation_mode': self.exploitation_mode,
            'is_converged': self.is_converged,
            'metadata': self.metadata,
            # è¶…å‚æ•°
            'n_features': self.n_features,
            'alpha': self.alpha,
            'lambda_reg': self.lambda_reg,
            # æ™ºèƒ½ä¿®å‰ªçŠ¶æ€
            'pruned_frequencies': list(self.pruned_frequencies),
            'last_pruning_check': self.last_pruning_check,
            'pruning_history': self.pruning_history,
            # ä¿®å‰ªé…ç½®å‚æ•°
            'enable_action_pruning': self.enable_action_pruning,
            'pruning_check_interval': self.pruning_check_interval,
            'pruning_threshold': self.pruning_threshold,
            'min_exploration_for_pruning': self.min_exploration_for_pruning,
            'pruning_maturity_threshold': self.pruning_maturity_threshold,
            # å­¦ä¹ é˜¶æ®µçŠ¶æ€
            'learning_phase_complete': self.learning_phase_complete,
            'learning_frequency_index': self.learning_frequency_index,
            '_learning_frequency_list': getattr(self, '_learning_frequency_list', None)
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
        
        # æ¸…ç†æ—§æ¨¡å‹æ–‡ä»¶ï¼Œåªä¿ç•™1ä¸ªæœ€æ–°çš„
        self._cleanup_old_models(current_file=filepath.name)
        
        # åˆ›å»ºæœ€æ–°æ¨¡å‹é“¾æ¥
        latest_path = self.model_dir / "latest_contextual_model.pkl"
        if latest_path.exists() or latest_path.is_symlink():
            latest_path.unlink()
        latest_path.symlink_to(filepath.name)
        
        logger.info(f"ğŸ’¾ Contextual LinUCBæ¨¡å‹å·²ä¿å­˜: {filepath}")
    
    def _cleanup_old_models(self, current_file: str):
        """æ¸…ç†æ—§æ¨¡å‹æ–‡ä»¶ï¼Œåªä¿ç•™1ä¸ªæœ€æ–°çš„"""
        try:
            # æŸ¥æ‰¾æ‰€æœ‰contextual_linucb_modelæ–‡ä»¶
            model_files = list(self.model_dir.glob("contextual_linucb_model_*.pkl"))
            
            if len(model_files) <= 1:
                return  # æ²¡æœ‰æ—§æ–‡ä»¶éœ€è¦æ¸…ç†
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
            model_files.sort(key=lambda p: p.stat().st_mtime, reverse=True)
            
            # åˆ é™¤é™¤å½“å‰æ–‡ä»¶å¤–çš„æ‰€æœ‰æ–‡ä»¶
            deleted_count = 0
            for model_file in model_files:
                if model_file.name != current_file:
                    try:
                        model_file.unlink()
                        deleted_count += 1
                        logger.debug(f"ğŸ—‘ï¸ åˆ é™¤æ—§æ¨¡å‹æ–‡ä»¶: {model_file.name}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ åˆ é™¤æ—§æ¨¡å‹æ–‡ä»¶å¤±è´¥ {model_file.name}: {e}")
            
            if deleted_count > 0:
                logger.info(f"ğŸ§¹ æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªæ—§æ¨¡å‹æ–‡ä»¶")
                
        except Exception as e:
            logger.warning(f"âš ï¸ æ¨¡å‹æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}")
    
    def load_model(self, filename: str = None):
        """åŠ è½½æ¨¡å‹"""
        if filename is None:
            # å°è¯•åŠ è½½æœ€æ–°æ¨¡å‹
            latest_path = self.model_dir / "latest_contextual_model.pkl"
            if latest_path.exists():
                filepath = latest_path
            else:
                # æŸ¥æ‰¾æœ€æ–°çš„æ¨¡å‹æ–‡ä»¶
                model_files = list(self.model_dir.glob("contextual_linucb_model_*.pkl"))
                if not model_files:
                    logger.info("ğŸ“ æœªæ‰¾åˆ°å·²æœ‰æ¨¡å‹æ–‡ä»¶ï¼Œä»é›¶å¼€å§‹")
                    return
                filepath = max(model_files, key=lambda p: p.stat().st_mtime)
        else:
            filepath = self.model_dir / filename
        
        if not filepath.exists():
            logger.warning(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            return
        
        try:
            with open(filepath, 'rb') as f:
                model_data = pickle.load(f)
            
            # éªŒè¯æ¨¡å‹å…¼å®¹æ€§
            if model_data.get('n_features') != self.n_features:
                logger.warning("âš ï¸ æ¨¡å‹ç‰¹å¾ç»´åº¦ä¸å…¼å®¹ï¼Œä»é›¶å¼€å§‹")
                return
            
            # åŠ è½½æ•°æ®
            self.arm_models = model_data.get('arm_models', {})
            self.available_frequencies = model_data.get('available_frequencies', [])
            self.total_rounds = model_data.get('total_rounds', 0)
            self.total_reward = model_data.get('total_reward', 0.0)
            self.reward_history = model_data.get('reward_history', [])
            self.action_history = model_data.get('action_history', [])
            self.context_history = model_data.get('context_history', [])
            self.edp_history = model_data.get('edp_history', [])
            self.arm_counts = model_data.get('arm_counts', {})
            self.arm_rewards = model_data.get('arm_rewards', {})
            self.exploitation_mode = model_data.get('exploitation_mode', False)
            self.is_converged = model_data.get('is_converged', False)
            self.metadata = model_data.get('metadata', self.metadata)
            # åŠ è½½ä¿®å‰ªçŠ¶æ€ï¼ˆå‘åå…¼å®¹ï¼‰
            self.pruned_frequencies = set(model_data.get('pruned_frequencies', []))
            self.last_pruning_check = model_data.get('last_pruning_check', 0)
            self.pruning_history = model_data.get('pruning_history', [])
            # åŠ è½½å­¦ä¹ é˜¶æ®µçŠ¶æ€ï¼ˆå‘åå…¼å®¹ï¼‰
            self.learning_phase_complete = model_data.get('learning_phase_complete', False)
            self.learning_frequency_index = model_data.get('learning_frequency_index', 0)
            saved_learning_list = model_data.get('_learning_frequency_list', None)
            if saved_learning_list is not None:
                self._learning_frequency_list = saved_learning_list
            
            logger.info(f"âœ… Contextual LinUCBæ¨¡å‹å·²åŠ è½½: {filepath}")
            logger.info(f"   è½®æ¬¡: {self.total_rounds}, å¹³å‡å¥–åŠ±: {self.total_reward/max(self.total_rounds,1):.3f}")
            logger.info(f"   é¢‘ç‡æ•°é‡: {len(self.arm_models)}")
            if self.enable_action_pruning and self.pruned_frequencies:
                logger.info(f"   å·²ä¿®å‰ªé¢‘ç‡: {len(self.pruned_frequencies)}ä¸ª {sorted(list(self.pruned_frequencies))}")
                logger.info(f"   ä¿®å‰ªå†å²: {len(self.pruning_history)}æ¬¡ä¿®å‰ªæ“ä½œ")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            logger.info("ğŸ†• å°†ä»é›¶å¼€å§‹")
    
    # å…¼å®¹æ€§æ¥å£ (ä¸åŸLinUCBä¿æŒä¸€è‡´)
    @property 
    def round_count(self) -> int:
        return self.total_rounds
    
    @property
    def phase(self) -> str:
        return "EXPLOITATION" if self.exploitation_mode else "LEARNING"
    
    @property
    def converged(self) -> bool:
        return self.is_converged
    
    @property
    def n_actions(self) -> int:
        return len(self.available_frequencies)
    
    def set_exploitation_mode(self, mode: bool):
        """è®¾ç½®åˆ©ç”¨æ¨¡å¼"""
        self.exploitation_mode = mode
        logger.info(f"ğŸ”„ åˆ‡æ¢åˆ°{'åˆ©ç”¨' if mode else 'å­¦ä¹ '}æ¨¡å¼")
    
    def select_action_exploitation(self, context: np.ndarray, 
                                  available_frequencies: List[int]) -> int:
        """åˆ©ç”¨æ¨¡å¼é€‰æ‹© (è´ªå¿ƒé€‰æ‹©æœ€ä½³é¢„æµ‹)"""
        if not available_frequencies:
            raise ValueError("å¯ç”¨é¢‘ç‡åˆ—è¡¨ä¸ºç©º")
        
        best_freq = None
        best_prediction = float('-inf')
        
        for freq in available_frequencies:
            self._init_arm_model(freq)
            model = self.arm_models[freq]
            prediction = np.dot(model['theta'], context)
            
            if prediction > best_prediction:
                best_prediction = prediction
                best_freq = freq
        
        logger.info(f"ğŸ¯ [åˆ©ç”¨æ¨¡å¼] é€‰æ‹©é¢‘ç‡ {best_freq}MHz, é¢„æµ‹å¥–åŠ±={best_prediction:.3f}")
        return best_freq
    
    def predict_reward(self, context: np.ndarray, frequency: int) -> float:
        """
        é¢„æµ‹æŒ‡å®šé¢‘ç‡åœ¨ç»™å®šä¸Šä¸‹æ–‡ä¸‹çš„æœŸæœ›å¥–åŠ±ï¼ˆä¸å«æ¢ç´¢å™ªå£°ï¼‰
        
        Args:
            context: ä¸Šä¸‹æ–‡ç‰¹å¾å‘é‡
            frequency: ç›®æ ‡é¢‘ç‡
            
        Returns:
            float: é¢„æµ‹çš„æœŸæœ›å¥–åŠ±
        """
        # ç¡®ä¿é¢‘ç‡æ¨¡å‹å·²åˆå§‹åŒ–
        self._init_arm_model(frequency)
        
        if frequency not in self.arm_models:
            logger.warning(f"é¢‘ç‡ {frequency}MHz åˆå§‹åŒ–å¤±è´¥ï¼Œè¿”å›0")
            return 0.0
        
        model = self.arm_models[frequency]
        
        try:
            # è®¡ç®—æœŸæœ›å¥–åŠ± E[r] = context^T * theta
            expected_reward = np.dot(context, model['theta'])
            logger.debug(f"é¢„æµ‹é¢‘ç‡ {frequency}MHz æœŸæœ›å¥–åŠ±: {expected_reward:.4f}")
            return float(expected_reward)
            
        except Exception as e:
            logger.warning(f"é¢„æµ‹é¢‘ç‡ {frequency}MHz å¥–åŠ±å¤±è´¥: {e}")
            return 0.0
    
    def get_ucb_values(self, context: np.ndarray) -> Dict[int, float]:
        """è·å–æ‰€æœ‰é¢‘ç‡çš„UCBå€¼ï¼ˆä½¿ç”¨è¡°å‡åçš„alphaï¼‰"""
        ucb_values = {}
        
        # ä½¿ç”¨è¡°å‡åçš„alphaå€¼
        current_alpha = self._get_current_alpha()
        
        for freq in self.available_frequencies:
            self._init_arm_model(freq)
            model = self.arm_models[freq]
            
            predicted_reward = np.dot(model['theta'], context)
            
            try:
                A_inv = np.linalg.inv(model['A'])
                confidence_width = current_alpha * np.sqrt(
                    np.dot(context, np.dot(A_inv, context))
                )
            except np.linalg.LinAlgError:
                confidence_width = current_alpha * 10.0
            
            ucb_values[freq] = predicted_reward + confidence_width
        
        return ucb_values
    
    def get_confidence_intervals(self, context: np.ndarray) -> Dict[int, dict]:
        """è·å–ç½®ä¿¡åŒºé—´"""
        intervals = {}
        
        for freq in self.available_frequencies:
            self._init_arm_model(freq)
            model = self.arm_models[freq]
            
            mean = np.dot(model['theta'], context)
            
            try:
                A_inv = np.linalg.inv(model['A'])
                current_alpha = self._get_current_alpha()
                width = current_alpha * np.sqrt(np.dot(context, np.dot(A_inv, context)))
            except np.linalg.LinAlgError:
                current_alpha = self._get_current_alpha()
                width = current_alpha * 10.0
            
            intervals[freq] = {
                'mean': mean,
                'lower': mean - width,
                'upper': mean + width,
                'width': 2 * width
            }
        
        return intervals
    
    def update_memory_frequencies(self, new_memory_frequencies: List[int]):
        """
        æ›´æ–°å¯ç”¨æ˜¾å­˜é¢‘ç‡åˆ—è¡¨ï¼Œå¹¶é‡æ–°ç”Ÿæˆå­¦ä¹ åŠ¨ä½œåˆ—è¡¨
        
        Args:
            new_memory_frequencies: æ–°çš„å¯ç”¨æ˜¾å­˜é¢‘ç‡åˆ—è¡¨
        """
        if not self.memory_optimization_enabled:
            logger.debug("ğŸ“ æ˜¾å­˜é¢‘ç‡ä¼˜åŒ–æœªå¯ç”¨ï¼Œè·³è¿‡æ˜¾å­˜é¢‘ç‡æ›´æ–°")
            return
        
        old_count = len(self.available_memory_frequencies)
        self.available_memory_frequencies = new_memory_frequencies.copy()
        new_count = len(self.available_memory_frequencies)
        
        logger.info(f"ğŸ”„ æ›´æ–°æ˜¾å­˜é¢‘ç‡åˆ—è¡¨: {old_count} -> {new_count} ä¸ªé¢‘ç‡")
        logger.debug(f"   æ–°æ˜¾å­˜é¢‘ç‡: {sorted(new_memory_frequencies)}")
        
        # é‡æ–°ç”Ÿæˆå­¦ä¹ åŠ¨ä½œåˆ—è¡¨ï¼ˆå¦‚æœåœ¨å­¦ä¹ é˜¶æ®µï¼‰
        if hasattr(self, '_learning_frequency_list') and not self.learning_phase_complete:
            self._regenerate_learning_action_list()
            logger.info("ğŸ“š å·²é‡æ–°ç”Ÿæˆå­¦ä¹ åŠ¨ä½œåˆ—è¡¨ä»¥åæ˜ æ˜¾å­˜é¢‘ç‡å˜åŒ–")
    
    def _regenerate_learning_action_list(self):
        """
        é‡æ–°ç”Ÿæˆå­¦ä¹ åŠ¨ä½œåˆ—è¡¨ï¼Œè€ƒè™‘å½“å‰å¯ç”¨çš„æ ¸å¿ƒé¢‘ç‡å’Œæ˜¾å­˜é¢‘ç‡ï¼Œä»¥åŠæ‰€æœ‰ç¦ç”¨è§„åˆ™
        """
        if self.memory_optimization_enabled and self.available_memory_frequencies:
            # ç»„åˆé¢‘ç‡æ¨¡å¼ï¼šç”Ÿæˆæ‰€æœ‰æœ‰æ•ˆçš„ (æ ¸å¿ƒé¢‘ç‡, æ˜¾å­˜é¢‘ç‡) ç»„åˆ
            self._learning_frequency_list = []
            for core_freq in self.available_frequencies:
                if core_freq in self.disabled_core_frequencies:
                    continue
                    
                for mem_freq in self.available_memory_frequencies:
                    action = (core_freq, mem_freq)
                    if self.is_action_allowed(action):
                        self._learning_frequency_list.append(action)
            
            logger.debug(f"ğŸ”„ é‡æ–°ç”Ÿæˆç»„åˆé¢‘ç‡å­¦ä¹ åˆ—è¡¨: {len(self._learning_frequency_list)} ä¸ªæœ‰æ•ˆç»„åˆ")
            logger.debug(f"   æ ¸å¿ƒé¢‘ç‡: {len(self.available_frequencies)} ä¸ª")
            logger.debug(f"   æ˜¾å­˜é¢‘ç‡: {len(self.available_memory_frequencies)} ä¸ª")
            logger.debug(f"   ç¦ç”¨æ ¸å¿ƒé¢‘ç‡: {len(self.disabled_core_frequencies)} ä¸ª")
            logger.debug(f"   å…¨å±€ç¦ç”¨æ˜¾å­˜é¢‘ç‡: {len(self.globally_disabled_memory_frequencies)} ä¸ª")
        else:
            # ä»…æ ¸å¿ƒé¢‘ç‡æ¨¡å¼
            self._learning_frequency_list = [freq for freq in self.available_frequencies 
                                           if freq not in self.disabled_core_frequencies]
            logger.debug(f"ğŸ”„ é‡æ–°ç”Ÿæˆæ ¸å¿ƒé¢‘ç‡å­¦ä¹ åˆ—è¡¨: {len(self._learning_frequency_list)} ä¸ªæœ‰æ•ˆé¢‘ç‡")
        
        # é‡ç½®å­¦ä¹ ç´¢å¼•åˆ°åˆç†ä½ç½®
        if self.learning_frequency_index >= len(self._learning_frequency_list):
            self.learning_frequency_index = 0
            logger.debug("ğŸ“ å­¦ä¹ ç´¢å¼•é‡ç½®ä¸º0ï¼ˆè¶…å‡ºæ–°åˆ—è¡¨èŒƒå›´ï¼‰")
    
    def disable_memory_frequency_globally(self, memory_freq: int, reason: str = "è®¾ç½®å¤±è´¥"):
        """
        å…¨å±€ç¦ç”¨æ˜¾å­˜é¢‘ç‡ - æ‰€æœ‰æ ¸å¿ƒé¢‘ç‡éƒ½ä¸å†ä½¿ç”¨è¿™ä¸ªæ˜¾å­˜é¢‘ç‡
        
        Args:
            memory_freq: è¦ç¦ç”¨çš„æ˜¾å­˜é¢‘ç‡
            reason: ç¦ç”¨åŸå› 
        """
        if not self.memory_optimization_enabled:
            return
        
        self.globally_disabled_memory_frequencies.add(memory_freq)
        
        # ä»å¯ç”¨æ˜¾å­˜é¢‘ç‡åˆ—è¡¨ä¸­ç§»é™¤
        if memory_freq in self.available_memory_frequencies:
            self.available_memory_frequencies.remove(memory_freq)
        
        logger.warning(f"ğŸš« å…¨å±€ç¦ç”¨æ˜¾å­˜é¢‘ç‡ {memory_freq}MHz ({reason})")
        logger.info(f"   å‰©ä½™å¯ç”¨æ˜¾å­˜é¢‘ç‡: {sorted(self.available_memory_frequencies)}")
        
        # é‡æ–°ç”Ÿæˆå­¦ä¹ åŠ¨ä½œåˆ—è¡¨
        if hasattr(self, '_learning_frequency_list') and not self.learning_phase_complete:
            self._regenerate_learning_action_list()
    
    def disable_core_memory_combination(self, core_freq: int, memory_freq: int, include_lower: bool = True):
        """
        ç¦ç”¨ç‰¹å®šæ ¸å¿ƒé¢‘ç‡ä¸‹çš„æ˜¾å­˜é¢‘ç‡ç»„åˆ
        
        Args:
            core_freq: æ ¸å¿ƒé¢‘ç‡
            memory_freq: è¦ç¦ç”¨çš„æ˜¾å­˜é¢‘ç‡è¾¹ç•Œ
            include_lower: æ˜¯å¦åŒ…å«æ›´ä½çš„æ˜¾å­˜é¢‘ç‡
        """
        if not self.memory_optimization_enabled:
            return
        
        if core_freq not in self.core_memory_disabled_combinations:
            self.core_memory_disabled_combinations[core_freq] = set()
        
        # ç¦ç”¨æŒ‡å®šçš„æ˜¾å­˜é¢‘ç‡
        disabled_freqs = {memory_freq}
        
        # å¦‚æœåŒ…å«æ›´ä½é¢‘ç‡ï¼Œä¹Ÿç¦ç”¨æ‰€æœ‰æ›´ä½çš„æ˜¾å­˜é¢‘ç‡
        if include_lower:
            for mem_freq in self.available_memory_frequencies:
                if mem_freq <= memory_freq:
                    disabled_freqs.add(mem_freq)
        
        self.core_memory_disabled_combinations[core_freq].update(disabled_freqs)
        
        logger.warning(f"ğŸš« ç¦ç”¨æ ¸å¿ƒé¢‘ç‡ {core_freq}MHz ä¸‹çš„æ˜¾å­˜é¢‘ç‡ç»„åˆ: {sorted(disabled_freqs)}")
        
        # é‡æ–°ç”Ÿæˆå­¦ä¹ åŠ¨ä½œåˆ—è¡¨
        if hasattr(self, '_learning_frequency_list') and not self.learning_phase_complete:
            self._regenerate_learning_action_list()
    
    def disable_core_frequency_for_memory_issues(self, core_freq: int, reason: str):
        """
        å› æ˜¾å­˜é¢‘ç‡é—®é¢˜ç¦ç”¨æ ¸å¿ƒé¢‘ç‡
        
        Args:
            core_freq: è¦ç¦ç”¨çš„æ ¸å¿ƒé¢‘ç‡
            reason: ç¦ç”¨åŸå› 
        """
        self.disabled_core_frequencies.add(core_freq)
        
        # ä»å¯ç”¨æ ¸å¿ƒé¢‘ç‡åˆ—è¡¨ä¸­ç§»é™¤
        if core_freq in self.available_frequencies:
            self.available_frequencies.remove(core_freq)
        
        logger.warning(f"ğŸš« ç¦ç”¨æ ¸å¿ƒé¢‘ç‡ {core_freq}MHz ({reason})")
        logger.info(f"   å‰©ä½™å¯ç”¨æ ¸å¿ƒé¢‘ç‡: {len(self.available_frequencies)} ä¸ª")
        
        # é‡æ–°ç”Ÿæˆå­¦ä¹ åŠ¨ä½œåˆ—è¡¨
        if hasattr(self, '_learning_frequency_list') and not self.learning_phase_complete:
            self._regenerate_learning_action_list()
    
    def disable_core_frequencies_below_threshold(self, threshold_freq: int, reason: str):
        """
        ç¦ç”¨é˜ˆå€¼é¢‘ç‡åŠä»¥ä¸‹çš„æ‰€æœ‰æ ¸å¿ƒé¢‘ç‡
        
        Args:
            threshold_freq: é˜ˆå€¼é¢‘ç‡
            reason: ç¦ç”¨åŸå› 
        """
        disabled_freqs = []
        for freq in self.available_frequencies.copy():
            if freq <= threshold_freq:
                self.disabled_core_frequencies.add(freq)
                self.available_frequencies.remove(freq)
                disabled_freqs.append(freq)
        
        logger.warning(f"ğŸš« ç¦ç”¨æ ¸å¿ƒé¢‘ç‡ â‰¤{threshold_freq}MHz: {sorted(disabled_freqs)} ({reason})")
        logger.info(f"   å‰©ä½™å¯ç”¨æ ¸å¿ƒé¢‘ç‡: {len(self.available_frequencies)} ä¸ª")
        
        # é‡æ–°ç”Ÿæˆå­¦ä¹ åŠ¨ä½œåˆ—è¡¨
        if hasattr(self, '_learning_frequency_list') and not self.learning_phase_complete:
            self._regenerate_learning_action_list()
    
    def propagate_memory_slo_boundary(self, violating_core_freq: int, violating_memory_freq: int):
        """
        ä¼ æ’­æ˜¾å­˜é¢‘ç‡SLOè¾¹ç•Œåˆ°æ›´å°çš„æ ¸å¿ƒé¢‘ç‡
        
        å½“å¤§æ ¸å¿ƒé¢‘ç‡+å°æ˜¾å­˜é¢‘ç‡ç»„åˆè¿è§„æ—¶ï¼Œä¼ æ’­çº¦æŸåˆ°æ›´å°çš„æ ¸å¿ƒé¢‘ç‡ï¼š
        - æ‰€æœ‰å°äºç­‰äºviolating_core_freqçš„æ ¸å¿ƒé¢‘ç‡éƒ½ä¸èƒ½ä½¿ç”¨å°äºç­‰äºviolating_memory_freqçš„æ˜¾å­˜é¢‘ç‡
        - å¤§äºviolating_core_freqçš„æ ¸å¿ƒé¢‘ç‡ä¸å—å½±å“
        
        Args:
            violating_core_freq: è¿è§„çš„æ ¸å¿ƒé¢‘ç‡
            violating_memory_freq: è¿è§„çš„æ˜¾å­˜é¢‘ç‡
        """
        if not self.memory_optimization_enabled:
            return
            
        # è®¡ç®—éœ€è¦è®¾ç½®è¾¹ç•Œçš„æ ¸å¿ƒé¢‘ç‡ï¼ˆå°äºç­‰äºè¿è§„æ ¸å¿ƒé¢‘ç‡ï¼‰
        affected_core_freqs = [freq for freq in self.available_frequencies 
                              if freq <= violating_core_freq]
        
        # å¯¹æ¯ä¸ªå—å½±å“çš„æ ¸å¿ƒé¢‘ç‡è®¾ç½®æˆ–æ›´æ–°SLOè¾¹ç•Œ
        for core_freq in affected_core_freqs:
            # è·å–å½“å‰è¾¹ç•Œ
            current_boundary = self.core_specific_memory_slo_boundaries.get(core_freq, 0)
            
            # è®¾ç½®æ›´ä¸¥æ ¼çš„è¾¹ç•Œï¼ˆæ›´é«˜çš„æœ€å°æ˜¾å­˜é¢‘ç‡ï¼‰
            new_boundary = max(current_boundary, violating_memory_freq + 1)
            
            # åªæœ‰åœ¨è¾¹ç•Œç¡®å®æ”¹å˜æ—¶æ‰è®¾ç½®
            if new_boundary > current_boundary:
                self.core_specific_memory_slo_boundaries[core_freq] = new_boundary
                
                # ç¦ç”¨è¯¥æ ¸å¿ƒé¢‘ç‡ä¸‹æ‰€æœ‰å°äºç­‰äºviolating_memory_freqçš„æ˜¾å­˜é¢‘ç‡
                self.disable_core_memory_combination(core_freq, violating_memory_freq, include_lower=True)
        
        logger.warning(f"ğŸ”„ SLOè¾¹ç•Œä¼ æ’­: {violating_core_freq}MHz+{violating_memory_freq}MHzè¿è§„")
        logger.info(f"   å½±å“æ ¸å¿ƒé¢‘ç‡: {sorted(affected_core_freqs)} (è®¾ç½®æ˜¾å­˜é¢‘ç‡è¾¹ç•Œ >{violating_memory_freq}MHz)")
        logger.info(f"   ä¸å½±å“æ ¸å¿ƒé¢‘ç‡: {sorted([f for f in self.available_frequencies if f > violating_core_freq])}")
        
        # é‡æ–°ç”Ÿæˆå­¦ä¹ åŠ¨ä½œåˆ—è¡¨
        if hasattr(self, '_learning_frequency_list') and not self.learning_phase_complete:
            self._regenerate_learning_action_list()
    
    def is_action_allowed(self, action) -> bool:
        """
        æ£€æŸ¥åŠ¨ä½œæ˜¯å¦è¢«å…è®¸ï¼ˆæœªè¢«ç¦ç”¨ï¼‰
        
        Args:
            action: åŠ¨ä½œ (æ ¸å¿ƒé¢‘ç‡ æˆ– (æ ¸å¿ƒé¢‘ç‡, æ˜¾å­˜é¢‘ç‡) å…ƒç»„)
            
        Returns:
            bool: æ˜¯å¦å…è®¸æ­¤åŠ¨ä½œ
        """
        if not self.memory_optimization_enabled:
            # ä»…æ ¸å¿ƒé¢‘ç‡æ¨¡å¼
            return action not in self.disabled_core_frequencies
        
        if isinstance(action, tuple):
            core_freq, memory_freq = action
            
            # æ£€æŸ¥æ ¸å¿ƒé¢‘ç‡æ˜¯å¦è¢«ç¦ç”¨
            if core_freq in self.disabled_core_frequencies:
                return False
            
            # æ£€æŸ¥æ˜¾å­˜é¢‘ç‡æ˜¯å¦è¢«å…¨å±€ç¦ç”¨
            if memory_freq in self.globally_disabled_memory_frequencies:
                return False
            
            # æ£€æŸ¥ç‰¹å®šæ ¸å¿ƒé¢‘ç‡ä¸‹çš„æ˜¾å­˜é¢‘ç‡ç»„åˆæ˜¯å¦è¢«ç¦ç”¨
            if (core_freq in self.core_memory_disabled_combinations and 
                memory_freq in self.core_memory_disabled_combinations[core_freq]):
                return False
            
            # æ£€æŸ¥æ ¸å¿ƒé¢‘ç‡ç‰¹å®šçš„SLOè¾¹ç•Œ
            if core_freq in self.core_specific_memory_slo_boundaries:
                min_allowed_memory_freq = self.core_specific_memory_slo_boundaries[core_freq]
                if memory_freq < min_allowed_memory_freq:
                    return False
            
            return True
        else:
            # å•ä¸€æ ¸å¿ƒé¢‘ç‡åŠ¨ä½œ
            return action not in self.disabled_core_frequencies
    
    def get_valid_actions(self) -> List:
        """
        è·å–æ‰€æœ‰æœ‰æ•ˆï¼ˆæœªè¢«ç¦ç”¨ï¼‰çš„åŠ¨ä½œåˆ—è¡¨
        
        Returns:
            List: æœ‰æ•ˆåŠ¨ä½œåˆ—è¡¨
        """
        if not self.memory_optimization_enabled:
            # ä»…æ ¸å¿ƒé¢‘ç‡æ¨¡å¼
            return [freq for freq in self.available_frequencies 
                   if freq not in self.disabled_core_frequencies]
        
        valid_actions = []
        for core_freq in self.available_frequencies:
            if core_freq in self.disabled_core_frequencies:
                continue
                
            for memory_freq in self.available_memory_frequencies:
                action = (core_freq, memory_freq)
                if self.is_action_allowed(action):
                    valid_actions.append(action)
        
        return valid_actions