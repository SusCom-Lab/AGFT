import time
import yaml
import signal
import sys
import argparse
import numpy as np
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Optional
from collections import Counter
import pynvml

from .logger import setup_logger
from .metrics_collector import MetricsCollector
from .gpu_controller import GPUController
from .feature_extractor import FeatureExtractor
from .contextual_bandit import ContextualLinUCB
from .reward_calculator import EDPRewardCalculator
from .experiment_recorder import ExperimentRecorder, create_round_data_dict


def get_gpu_model_for_logging(gpu_id: int = 0) -> str:
    """è·å–GPUå‹å·ç”¨äºæ—¥å¿—ç›®å½•åˆ†ç±»"""
    try:
        pynvml.nvmlInit()
        nvml_handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_id)
        gpu_name = pynvml.nvmlDeviceGetName(nvml_handle)
        if isinstance(gpu_name, bytes):
            gpu_name = gpu_name.decode('utf-8')
        
        # æ¸…ç†GPUåç§°ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œç”¨äºç›®å½•å
        cleaned_name = gpu_name.replace("NVIDIA ", "").replace("GeForce ", "")
        cleaned_name = cleaned_name.replace(" ", "_").replace("-", "_")
        # ç§»é™¤å¸¸è§çš„åç¼€ä¿¡æ¯
        for suffix in ["_SXM2", "_32GB", "_16GB", "_8GB", "_PCIE", "_SMX2"]:
            if suffix in cleaned_name:
                cleaned_name = cleaned_name.split(suffix)[0]
                break
        
        return cleaned_name[:20]  # é™åˆ¶é•¿åº¦é¿å…è·¯å¾„è¿‡é•¿
        
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è·å–GPUå‹å·ä¿¡æ¯: {e}")
        return "Unknown_GPU"


def create_gpu_classified_log_dir(config_path: str = "config/config.yaml") -> tuple[Path, str]:
    """æ ¹æ®é…ç½®æ–‡ä»¶ä¸­çš„GPU IDåˆ›å»ºåˆ†ç±»çš„æ—¥å¿—ç›®å½•"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        gpu_id = config.get('gpu', {}).get('device_id', 0)
    except Exception:
        gpu_id = 0
    
    gpu_model = get_gpu_model_for_logging(gpu_id)
    log_dir = Path("logs") / gpu_model
    log_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = f"vllm_gpu_autoscaler_{timestamp}.log"
    
    return log_dir / log_file, gpu_model


class VLLMGPUAutoscaler:
    """vLLM GPUè‡ªåŠ¨è°ƒé¢‘å™¨ - çº¯Contextual LinUCBç‰ˆæœ¬"""
    
    def __init__(self, config_path: str = "config/config.yaml", reset_model: bool = False):
        """åˆå§‹åŒ–è‡ªåŠ¨è°ƒé¢‘å™¨"""
        self.config_path = config_path
        self.reset_model = reset_model
        self.running = False
        
        # åŠ è½½é…ç½®
        self.config = self._load_config()
        
        # æ£€æŸ¥æ•°æ®æ”¶é›†æ¨¡å¼
        self.data_collection_mode = self.config.get('control', {}).get('data_collection_mode', False)
        
        # è®¾ç½®æ—¥å¿—
        log_file_path, gpu_model = create_gpu_classified_log_dir(config_path)
        logging_config = self.config.get('logging', {})
        
        # è·å–æ—¥å¿—çº§åˆ«
        console_level_str = logging_config.get('console_level', 'INFO').upper()
        file_level_str = logging_config.get('file_level', 'DEBUG').upper()
        
        # è½¬æ¢ä¸ºloggingçº§åˆ«
        import logging
        level_map = {
            'DEBUG': logging.DEBUG,
            'INFO': logging.INFO,
            'WARNING': logging.WARNING,
            'ERROR': logging.ERROR,
            'CRITICAL': logging.CRITICAL
        }
        console_level = level_map.get(console_level_str, logging.INFO)
        file_level = level_map.get(file_level_str, logging.DEBUG)
        
        self.logger = setup_logger("VLLMAutoscaler", str(log_file_path), 
                                  console_level=console_level, file_level=file_level)
        
        self.logger.info("=" * 80)
        self.logger.info("ğŸš€ vLLM GPUè‡ªåŠ¨è°ƒé¢‘å™¨å¯åŠ¨")
        self.logger.info(f"ğŸ“ é…ç½®æ–‡ä»¶: {config_path}")
        self.logger.info(f"ğŸ”§ GPUå‹å·: {gpu_model}")
        self.logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file_path}")
        self.logger.info(f"ğŸ“Š æ—¥å¿—çº§åˆ«: æ§åˆ¶å°={console_level_str}, æ–‡ä»¶={file_level_str}")
        self.logger.info(f"ğŸ” è¯¦ç»†è½®æ¬¡è®°å½•: {'å¯ç”¨' if logging_config.get('detailed_round_logging', True) else 'ç¦ç”¨'}")
        self.logger.info(f"ğŸ“Š è¿è¡Œæ¨¡å¼: {'æ•°æ®æ”¶é›†æ¨¡å¼ (ä¸è°ƒé¢‘)' if self.data_collection_mode else 'æ­£å¸¸å­¦ä¹ æ¨¡å¼'}")
        self.logger.info("=" * 80)
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self._init_components()
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        self.logger.info("âœ… vLLM GPUè‡ªåŠ¨è°ƒé¢‘å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            sys.exit(1)
    
    def _init_components(self):
        """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""
        # åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†å™¨
        prometheus_url = self.config['vllm']['prometheus_url']
        metrics_config = self.config.get('metrics', {})
        # åªä¼ é€’MetricsCollectoréœ€è¦çš„å‚æ•°
        metrics_collector_args = {
            'ema_alpha': metrics_config.get('ema_alpha', 0.4),
            'sampling_duration': metrics_config.get('sampling_duration', 0.8),
            'sampling_interval': metrics_config.get('sampling_interval', 0.01)
        }
        self.metrics_collector = MetricsCollector(prometheus_url, **metrics_collector_args)
        
        # åˆå§‹åŒ–GPUæ§åˆ¶å™¨
        gpu_config = self.config.get('gpu', {})
        # æ˜ å°„å‚æ•°åç§°ä»¥åŒ¹é…GPUControlleræœŸæœ›çš„å‚æ•°
        gpu_controller_args = {}
        if 'device_id' in gpu_config:
            gpu_controller_args['gpu_id'] = gpu_config['device_id']
        if 'frequency_step' in gpu_config:
            gpu_controller_args['step'] = gpu_config['frequency_step']
        if 'min_frequency' in gpu_config:
            gpu_controller_args['min_freq'] = gpu_config['min_frequency']
        # ç›´æ¥æ˜ å°„çš„å‚æ•° (ç§»é™¤max_action_counté™åˆ¶)
        for key in ['auto_step', 'enable_memory_frequency_control', 
                   'memory_auto_detect', 'memory_frequencies']:
            if key in gpu_config:
                gpu_controller_args[key] = gpu_config[key]
        # ä»controlé…ç½®ä¸­è·å–ignore_sloå‚æ•°å’Œæˆç†Ÿåº¦é˜ˆå€¼
        control_config = self.config.get('control', {})
        if 'ignore_slo' in control_config:
            gpu_controller_args['ignore_slo'] = control_config['ignore_slo']
        if 'adaptive_update_interval' in control_config:
            gpu_controller_args['adaptive_update_interval'] = control_config['adaptive_update_interval']
        if 'learner_maturity_threshold' in control_config:
            gpu_controller_args['learner_maturity_threshold'] = control_config['learner_maturity_threshold']
        if 'refinement_start_threshold' in control_config:
            gpu_controller_args['refinement_start_threshold'] = control_config['refinement_start_threshold']
        # ä»adaptive_samplingé…ç½®ä¸­è·å–reward_thresholdå‚æ•°
        adaptive_config = self.config.get('adaptive_sampling', {})
        if 'reward_threshold' in adaptive_config:
            gpu_controller_args['reward_threshold'] = adaptive_config['reward_threshold']
        
        # æ·»åŠ å®é™…é¢‘ç‡å›è°ƒå‡½æ•°
        gpu_controller_args['actual_frequency_callback'] = self._on_actual_frequency_available
        
        self.gpu_controller = GPUController(**gpu_controller_args)
        
        # åˆå§‹åŒ–ç‰¹å¾æå–å™¨
        self.feature_extractor = FeatureExtractor()
        
        # åˆå§‹åŒ–å¥–åŠ±è®¡ç®—å™¨
        control_config = self.config.get('control', {})
        # è·å–metricsé…ç½®ç”¨äºbaseline
        metrics_config = self.config.get('metrics', {})
        sampling_duration = metrics_config.get('sampling_duration', 0.8)
        
        self.reward_calculator = EDPRewardCalculator(
            ttft_limit=control_config.get('ttft_limit', 2.0),
            tpot_limit=control_config.get('tpot_limit', 0.25),
            ignore_slo=control_config.get('ignore_slo', True),
            sampling_duration=sampling_duration,
            baseline_measurements=metrics_config.get('baseline_measurements', 3)
        )
        
        # åŸºçº¿çŠ¶æ€ç”±reward_calculatorç®¡ç†
        
        # åˆå§‹åŒ–Contextual LinUCBæ¨¡å‹ (ä¸å†æ”¯æŒç¥ç»ç½‘ç»œ)
        linucb_config = self.config.get('linucb', {})
        self.model = ContextualLinUCB(
            n_features=7,  # ä»…å·¥ä½œè´Ÿè½½ç‰¹å¾ï¼Œä¸åŒ…å«é¢‘ç‡
            alpha=linucb_config.get('initial_alpha', 0.1),  # å¤§å¹…é™ä½alphaå‡å°‘è¿‡åº¦æ¢ç´¢
            lambda_reg=linucb_config.get('lambda_reg', 5.0),  # ä¿æŒæ­£åˆ™åŒ–æé«˜æ•°å€¼ç¨³å®šæ€§
            alpha_decay_rate=linucb_config.get('alpha_decay_rate', 0.01),  # alphaè¡°å‡ç‡
            min_alpha=linucb_config.get('min_alpha', 0.1),  # æœ€å°alphaå€¼
            # æ™ºèƒ½åŠ¨ä½œä¿®å‰ªå‚æ•°
            enable_action_pruning=linucb_config.get('enable_action_pruning', True),
            pruning_check_interval=linucb_config.get('pruning_check_interval', 100),
            pruning_threshold=linucb_config.get('pruning_threshold', 1.0),
            min_exploration_for_pruning=linucb_config.get('min_exploration_for_pruning', 5),
            pruning_maturity_threshold=linucb_config.get('pruning_maturity_threshold', 100),
            cascade_pruning_threshold=linucb_config.get('cascade_pruning_threshold', 600),
            gpu_max_freq=self.gpu_controller.max_freq,  # ä¼ å…¥GPUç¡¬ä»¶æœ€å¤§é¢‘ç‡
            # æç«¯é¢‘ç‡å³æ—¶ä¿®å‰ªå‚æ•°
            enable_extreme_pruning=linucb_config.get('enable_extreme_pruning', True),
            extreme_pruning_threshold=linucb_config.get('extreme_pruning_threshold', -1.5),
            extreme_pruning_min_samples=linucb_config.get('extreme_pruning_min_samples', 3),
            extreme_pruning_max_rounds=linucb_config.get('extreme_pruning_max_rounds', 20),
            auto_load=not self.reset_model
        )
        
        # å¯ç”¨æ˜¾å­˜+æ ¸å¿ƒé¢‘ç‡ç»„åˆä¼˜åŒ–ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if (self.gpu_controller.enable_memory_frequency_control and 
            self.gpu_controller.memory_frequency_supported and 
            hasattr(self.gpu_controller, 'memory_frequencies')):
            
            memory_freqs = self.gpu_controller.memory_frequencies
            self.model.enable_memory_frequency_optimization(memory_freqs)
            
            # è®¾ç½®LinUCBæ¨¡å‹å›è°ƒï¼Œç”¨äºç²¾ç»†çš„é¢‘ç‡ç¦ç”¨ç®¡ç†
            self.gpu_controller.set_linucb_callback(self.model)
            
            self.logger.info(f"ğŸ”§ æ˜¾å­˜+æ ¸å¿ƒé¢‘ç‡ç»„åˆä¼˜åŒ–å·²å¯ç”¨")
            self.logger.info(f"   æ˜¾å­˜é¢‘ç‡: {memory_freqs}")
            total_combinations = len(self.gpu_controller.frequencies) * len(memory_freqs)
            self.logger.info(f"   æ€»åŠ¨ä½œç©ºé—´: {total_combinations} ä¸ªç»„åˆ")
            self.logger.info(f"   ç²¾ç»†ç¦ç”¨ç®¡ç†: å·²å¯ç”¨")
        else:
            self.logger.info(f"ğŸ”§ ä»…æ ¸å¿ƒé¢‘ç‡ä¼˜åŒ–æ¨¡å¼")
        
        # æ§åˆ¶å‚æ•°
        self.convergence_window = control_config.get('convergence_window', 100)
        self.performance_degradation_threshold = control_config.get('performance_degradation_threshold', 1.2)
        self.convergence_top_k = control_config.get('convergence_top_k', 3)
        self.convergence_threshold = control_config.get('convergence_threshold', 0.70)
        
        # ä¼‘æ¯æ¨¡å¼çŠ¶æ€
        self.idle_mode = False              # å½“å‰æ˜¯å¦å¤„äºä¼‘æ¯æ¨¡å¼
        self.idle_confirmation_count = 0    # è¿ç»­ç©ºé—²æ£€æµ‹è®¡æ•°
        self.last_idle_reset = False        # æ˜¯å¦å·²ç»æ‰§è¡Œè¿‡é¢‘ç‡é‡ç½®
        
        self.logger.info("ğŸ”§ ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–å®Œæˆ:")
        self.logger.info(f"   ç®—æ³•: Contextual LinUCB (é¢‘ç‡ä½œä¸ºåŠ¨ä½œ)")
        self.logger.info(f"   ç‰¹å¾ç»´åº¦: 7ç»´ (ä»…å·¥ä½œè´Ÿè½½ç‰¹å¾)")
        self.logger.info(f"   æ”¶æ•›çª—å£: {self.convergence_window}è½®")
        self.logger.info(f"   æ”¶æ•›ç­–ç•¥: å‰{self.convergence_top_k}ä¸ªåŠ¨ä½œè”åˆå æ¯” >= {self.convergence_threshold:.0%}")
        
        # æ˜¾ç¤ºå½“å‰æ¨¡å‹çŠ¶æ€
        initial_mode = "åˆ©ç”¨(å·²æ”¶æ•›)" if self.model.exploitation_mode else "å­¦ä¹ (æ¢ç´¢ä¸­)"
        self.logger.info(f"   åˆå§‹æ¨¡å¼: {initial_mode}")
        if hasattr(self.model, 'total_rounds') and self.model.total_rounds > 0:
            self.logger.info(f"   å·²è®­ç»ƒè½®æ¬¡: {self.model.total_rounds}")
            self.logger.info(f"   å·²çŸ¥é¢‘ç‡: {len(self.model.available_frequencies)}ä¸ª")
        
        # åˆå§‹åŒ–å®éªŒæ•°æ®è®°å½•å™¨
        self.experiment_recorder = ExperimentRecorder()
        self.experiment_recorder.save_config_snapshot(self.config_path)
        
        # è·å–GPUå‹å·ä¿¡æ¯å¹¶ä¿å­˜åˆ°å®éªŒè®°å½•å™¨
        gpu_model = get_gpu_model_for_logging(gpu_config.get('device_id', 0))
        self.experiment_recorder.set_gpu_model(gpu_model)
    
    def _on_actual_frequency_available(self, actual_freq: int):
        """
        å®é™…é¢‘ç‡å¯ç”¨å›è°ƒå‡½æ•°
        å½“GPUé¢‘ç‡è®¾ç½®å¤±è´¥ä½†æœ‰å®é™…é¢‘ç‡å¯ç”¨æ—¶ï¼Œå°†å…¶æ·»åŠ åˆ°åŠ¨ä½œç©ºé—´
        
        Args:
            actual_freq: å®é™…è®¾ç½®æˆåŠŸçš„é¢‘ç‡ï¼ˆMHzï¼‰
        """
        try:
            # æ£€æŸ¥é…ç½®æ˜¯å¦å¯ç”¨äº†è‡ªé€‚åº”æ¢å¤
            control_config = self.config.get('control', {})
            if not control_config.get('auto_add_actual_frequency', True):
                self.logger.debug(f"ğŸ”„ è‡ªåŠ¨æ·»åŠ å®é™…é¢‘ç‡åŠŸèƒ½å·²ç¦ç”¨ï¼Œå¿½ç•¥ {actual_freq}MHz")
                return
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹å­˜åœ¨
            if not hasattr(self, 'model') or self.model is None:
                self.logger.warning(f"âš ï¸ æ¨¡å‹ä¸å­˜åœ¨ï¼Œæ— æ³•æ·»åŠ å®é™…é¢‘ç‡ {actual_freq}MHz")
                return
            
            # æ£€æŸ¥åŠ¨ä½œç©ºé—´å¤§å°ï¼Œåªæœ‰å½“ç©ºé—´å¾ˆå°æ—¶æ‰æ·»åŠ 
            min_action_size = control_config.get('min_action_space_size', 1)
            current_action_count = len(self.model.available_frequencies)
            
            if current_action_count > min_action_size:
                self.logger.debug(f"ğŸ”„ åŠ¨ä½œç©ºé—´è¶³å¤Ÿå¤§({current_action_count}>{min_action_size})ï¼Œä¸æ·»åŠ å®é™…é¢‘ç‡ {actual_freq}MHz")
                return
            
            # æ·»åŠ å®é™…é¢‘ç‡åˆ°æ¨¡å‹çš„åŠ¨ä½œç©ºé—´
            self.model.add_actual_frequency(actual_freq)
            
            self.logger.info(f"ğŸš€ åŠ¨ä½œç©ºé—´è‡ªé€‚åº”æ¢å¤: æˆåŠŸæ·»åŠ å®é™…é¢‘ç‡ {actual_freq}MHz")
            
        except Exception as e:
            self.logger.error(f"âŒ æ·»åŠ å®é™…é¢‘ç‡å¤±è´¥: {e}")
            import traceback
            self.logger.debug(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    def _signal_handler(self, signum, _frame):
        """ä¿¡å·å¤„ç†å™¨"""
        self.logger.info(f"ğŸ›‘ æ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
        self.running = False
        
        # ç»“æŸå®éªŒå¹¶ä¿å­˜æ•°æ®
        if hasattr(self, 'experiment_recorder'):
            self.experiment_recorder.finalize_experiment()
    
    def _get_current_state(self) -> tuple[np.ndarray, list, dict]:
        """è·å–å½“å‰ç³»ç»ŸçŠ¶æ€"""
        # æ”¶é›†æŒ‡æ ‡ï¼ˆåŒ…å«èƒ½è€—æ•°æ®ï¼‰
        metrics = self.metrics_collector.collect_metrics(
            energy_reader=self.gpu_controller.read_energy_j
        )
        if not metrics:
            raise RuntimeError("æ— æ³•æ”¶é›†vLLMæŒ‡æ ‡")
        
        # æå–ç‰¹å¾ (ä»…å·¥ä½œè´Ÿè½½ç‰¹å¾ï¼Œä¸åŒ…å«é¢‘ç‡)
        features = self.feature_extractor.extract_features(metrics)
        if features is None or len(features) != 7:
            raise RuntimeError(f"ç‰¹å¾æå–å¤±è´¥ï¼ŒæœŸæœ›7ç»´ï¼Œå®é™…{len(features) if features is not None else 0}ç»´")
        
        # è·å–å¯ç”¨é¢‘ç‡ï¼ˆæ’é™¤ä¿®å‰ªå’Œå¤±è´¥çš„é¢‘ç‡ï¼‰
        available_frequencies = self.gpu_controller.get_available_frequencies(self.model)
        if not available_frequencies:
            self.logger.warning("âš ï¸ æ— å¯ç”¨GPUé¢‘ç‡ï¼Œé‡ç½®GPUé¢‘ç‡åˆ°é»˜è®¤çŠ¶æ€")
            # é‡ç½®GPUé¢‘ç‡åˆ°é»˜è®¤çŠ¶æ€ï¼Œä¸å†é”é¢‘
            if self.gpu_controller.reset_gpu_clocks():
                self.logger.info("âœ… GPUé¢‘ç‡å·²é‡ç½®ï¼Œç³»ç»Ÿç»§ç»­è¿è¡Œï¼ˆä¸é”é¢‘æ¨¡å¼ï¼‰")
                # è¿”å›ä¸€ä¸ªç©ºçš„é¢‘ç‡åˆ—è¡¨ï¼Œè¡¨ç¤ºä¸è¿›è¡Œé¢‘ç‡å†³ç­–
                return features, [], metrics
            else:
                raise RuntimeError("GPUé¢‘ç‡é‡ç½®å¤±è´¥ï¼Œæ— æ³•ç»§ç»­è¿è¡Œ")
        
        return features, available_frequencies, metrics
    
    def _make_decision(self, features: np.ndarray, available_frequencies: list) -> int:
        """åšå‡ºé¢‘ç‡å†³ç­–"""
        # å¦‚æœæ²¡æœ‰å¯ç”¨é¢‘ç‡ï¼Œè¿”å›Noneè¡¨ç¤ºä¸è¿›è¡Œé¢‘ç‡å†³ç­–
        if not available_frequencies:
            self.logger.debug("ğŸ“Š æ— å¯ç”¨é¢‘ç‡ï¼Œè·³è¿‡é¢‘ç‡å†³ç­–ï¼ˆä¿æŒé‡ç½®çŠ¶æ€ï¼‰")
            return None
            
        # æ›´æ–°æ¨¡å‹çš„åŠ¨ä½œç©ºé—´
        self.model.update_action_space(available_frequencies)
        
        # é€‰æ‹©é¢‘ç‡ (é¢‘ç‡ä½œä¸ºåŠ¨ä½œï¼Œä¸ä½œä¸ºç‰¹å¾)
        if self.model.exploitation_mode:
            selected_freq = self.model.select_action_exploitation(features, available_frequencies)
        else:
            selected_freq = self.model.select_action(features, available_frequencies)
        
        return selected_freq
    
    def _execute_action_and_measure(self, action, is_baseline: bool = False) -> tuple[float, dict, Optional[float]]:
        """æ‰§è¡ŒåŠ¨ä½œå¹¶æµ‹é‡å¥–åŠ±ï¼ˆæ”¯æŒæ ¸å¿ƒé¢‘ç‡æˆ–ç»„åˆé¢‘ç‡ï¼‰"""
        # å¦‚æœactionä¸ºNoneï¼Œè¡¨ç¤ºç³»ç»Ÿå¤„äºé‡ç½®çŠ¶æ€ï¼Œä¸è®¾ç½®é¢‘ç‡
        if action is None:
            self.logger.debug("ğŸ“Š é¢‘ç‡å·²é‡ç½®ï¼Œè·³è¿‡é¢‘ç‡è®¾ç½®ï¼Œç›´æ¥æµ‹é‡æ€§èƒ½")
            # ç­‰å¾…å†³ç­–é—´éš”
            time.sleep(0.3)
            
            # æ”¶é›†æ‰§è¡Œåçš„æŒ‡æ ‡
            post_metrics = self.metrics_collector.collect_metrics(
                energy_reader=self.gpu_controller.read_energy_j
            )
            if not post_metrics:
                self.logger.warning("âš ï¸ post_metricsä¸ºç©ºï¼Œè·³è¿‡è‡ªé€‚åº”é‡‡æ ·å™¨æ›´æ–°")
                return 0.0, {}, None
                
            # è®¡ç®—å¥–åŠ±ï¼ˆä½¿ç”¨å½“å‰çš„å®é™…é¢‘ç‡ï¼‰
            current_freq = self.gpu_controller._get_current_frequency()
            self.logger.info(f"ğŸ“Š é‡ç½®æ¨¡å¼ä¸‹å½“å‰GPUé¢‘ç‡: {current_freq}MHz")
            
            # è·å–èƒ½è€—å¢é‡
            energy_delta = post_metrics.get('energy_delta_j', 0.0)
            reward = self.reward_calculator.calculate_reward(post_metrics, energy_delta)
            return reward, post_metrics, None
            
        # è®¾ç½®GPUé¢‘ç‡ï¼ˆç»„åˆé¢‘ç‡æˆ–æ ¸å¿ƒé¢‘ç‡ï¼‰
        if self.model.memory_optimization_enabled and isinstance(action, tuple):
            # ç»„åˆé¢‘ç‡æ¨¡å¼ï¼šè®¾ç½®æ ¸å¿ƒé¢‘ç‡å’Œæ˜¾å­˜é¢‘ç‡
            core_freq, memory_freq = action
            success = self.gpu_controller.set_frequency(core_freq)
            if success and hasattr(self.gpu_controller, 'set_memory_frequency'):
                success = success and self.gpu_controller.set_memory_frequency(memory_freq)
            
            if not success:
                action_desc = f"{core_freq}MHzæ ¸å¿ƒ+{memory_freq}MHzæ˜¾å­˜"
                self.logger.error(f"âŒ è®¾ç½®ç»„åˆé¢‘ç‡ {action_desc} å¤±è´¥")
                return -1.0, {}, None  # æƒ©ç½šå¤±è´¥çš„é¢‘ç‡è®¾ç½®
        else:
            # æ ¸å¿ƒé¢‘ç‡æ¨¡å¼ï¼šåªè®¾ç½®æ ¸å¿ƒé¢‘ç‡
            if not self.gpu_controller.set_frequency(action):
                self.logger.error(f"âŒ è®¾ç½®GPUæ ¸å¿ƒé¢‘ç‡ {action}MHz å¤±è´¥")
                return -1.0, {}, None  # æƒ©ç½šå¤±è´¥çš„é¢‘ç‡è®¾ç½®
        
        # ç­‰å¾…å†³ç­–é—´éš”
        time.sleep(0.3)
        
        # æ”¶é›†æ‰§è¡Œåçš„æŒ‡æ ‡ï¼ˆåŒ…å«èƒ½è€—æ•°æ®ï¼‰
        post_metrics = self.metrics_collector.collect_metrics(
            energy_reader=self.gpu_controller.read_energy_j
        )
        if not post_metrics:
            self.logger.warning("âš ï¸ æ— æ³•æ”¶é›†æ‰§è¡ŒåæŒ‡æ ‡")
            return -0.5, {}, None
        
        # ä»æŒ‡æ ‡ä¸­è·å–èƒ½è€—å¢é‡ï¼ˆç„¦è€³ï¼‰
        energy_delta = post_metrics.get('energy_delta_j', 0.0)
        
        # è®¡ç®—å¥–åŠ±å’ŒEDPå€¼
        # ä»vLLMæŒ‡æ ‡ä¸­æå–è®¡æ•°å™¨å¢é‡
        counter_deltas = {}
        ttft_sum_key = "vllm:time_to_first_token_seconds_sum_delta"
        ttft_count_key = "vllm:time_to_first_token_seconds_count_delta"
        tpot_sum_key = "vllm:time_per_output_token_seconds_sum_delta"
        tpot_count_key = "vllm:time_per_output_token_seconds_count_delta"
        
        for key in [ttft_sum_key, ttft_count_key, tpot_sum_key, tpot_count_key]:
            if key in post_metrics:
                counter_deltas[key] = post_metrics[key]
        
        # è°ƒç”¨calculateæ–¹æ³•è·å–è¯¦ç»†ä¿¡æ¯
        reward, info = self.reward_calculator.calculate(
            counter_deltas=counter_deltas,
            energy_consumed_j=energy_delta,
            is_baseline_collection=is_baseline
        )
        
        # æå–EDPå€¼
        edp_value = info.get('edp_raw', None)
        
        return reward, post_metrics, edp_value
    
    def _collect_baseline_metrics(self) -> tuple[float, dict, Optional[float]]:
        """ä¸“é—¨ç”¨äºåŸºçº¿æ”¶é›†çš„æŒ‡æ ‡æ”¶é›†æ–¹æ³• - ä¸æ”¹å˜GPUé¢‘ç‡ï¼Œä½†æ£€æŸ¥ä»»åŠ¡çŠ¶æ€"""
        try:
            # ç­‰å¾…ç³»ç»Ÿç¨³å®š
            time.sleep(0.3)
            
            # æ”¶é›†æŒ‡æ ‡ï¼ˆåŒ…å«èƒ½è€—æ•°æ®ï¼‰
            post_metrics = self.metrics_collector.collect_metrics(
                energy_reader=self.gpu_controller.read_energy_j
            )
            if not post_metrics:
                self.logger.warning("âš ï¸ åŸºçº¿æ”¶é›†æ—¶æ— æ³•æ”¶é›†æŒ‡æ ‡")
                return 0.0, {}, None
            
            # åŸºçº¿æ”¶é›†æœŸé—´æ£€æŸ¥ä»»åŠ¡çŠ¶æ€ - å¦‚æœæ²¡æœ‰ä»»åŠ¡ï¼Œè·³è¿‡è¿™æ¬¡æ”¶é›†
            running_requests = post_metrics.get('vllm:num_requests_running', 0)
            has_queue = post_metrics.get('vllm:num_requests_waiting', 0) > 0
            
            if running_requests == 0 and not has_queue:
                self.logger.info("â¸ï¸ åŸºçº¿æ”¶é›†æœŸé—´æ£€æµ‹åˆ°æ— ä»»åŠ¡ï¼Œè·³è¿‡æ­¤æ¬¡æ”¶é›†")
                return 0.0, {}, None
            
            # è®¡ç®—å¥–åŠ±ï¼ˆåŸºçº¿æ”¶é›†æ¨¡å¼ï¼‰
            reward, info = self.reward_calculator.calculate(
                counter_deltas=post_metrics,
                energy_consumed_j=post_metrics.get('energy_delta_j', 0.0),
                is_baseline_collection=True
            )
            
            # æå–EDPå€¼ç”¨äºè®°å½•
            edp_value = info.get('edp_raw', None)
            
            return reward, post_metrics, edp_value
            
        except Exception as e:
            self.logger.error(f"âŒ åŸºçº¿æŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")
            return 0.0, {}, None
    
    def _check_convergence(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¶æ•› - åŸºäºå‰å‡ ä¸ªæœ€ä¼˜åŠ¨ä½œçš„è”åˆç¨³å®šæ€§"""
        if self.model.total_rounds < self.convergence_window:
            return False
        
        # è·å–æœ€è¿‘çš„åŠ¨ä½œå†å²
        recent_actions = self.model.action_history[-self.convergence_window:]
        if len(recent_actions) < self.convergence_window:
            return False
        
        # ç»Ÿè®¡æ¯ä¸ªåŠ¨ä½œçš„é€‰æ‹©æ¬¡æ•°
        action_counts = Counter(recent_actions)
        
        # ä»é…ç½®ä¸­è·å–æ”¶æ•›å‚æ•°
        control_config = self.config.get('control', {})
        top_k = control_config.get('convergence_top_k', 3)  # è€ƒè™‘å‰kä¸ªæœ€ä¼˜åŠ¨ä½œ
        convergence_threshold = control_config.get('convergence_threshold', 0.70)  # æ”¶æ•›é˜ˆå€¼
        
        # è·å–è¢«é€‰æ‹©æ¬¡æ•°æœ€å¤šçš„å‰kä¸ªåŠ¨ä½œ
        most_common_actions = action_counts.most_common(top_k)
        
        if not most_common_actions:
            return False
        
        # è®¡ç®—å‰kä¸ªåŠ¨ä½œçš„æ€»å æ¯”
        top_k_total_count = sum(count for _, count in most_common_actions)
        top_k_combined_ratio = top_k_total_count / len(recent_actions)
        is_converged = top_k_combined_ratio >= convergence_threshold
        
        # è®°å½•æ”¶æ•›çŠ¶æ€å˜åŒ–
        if is_converged and not self.model.exploitation_mode:
            # æ„å»ºæ”¶æ•›ä¿¡æ¯å­—ç¬¦ä¸²
            top_actions_info = ", ".join([f"{action}MHz({count}æ¬¡,{count/len(recent_actions):.1%})" 
                                        for action, count in most_common_actions])
            
            self.logger.info(f"ğŸ¯ æ¨¡å‹æ”¶æ•›æ£€æµ‹: å‰{len(most_common_actions)}ä¸ªä¼˜åŠ¿åŠ¨ä½œè”åˆå æ¯”{top_k_combined_ratio:.1%} >= {convergence_threshold:.0%}")
            self.logger.info(f"ğŸ“Š ç¨³å®šçŠ¶æ€é›†: {top_actions_info}")
            self.logger.info(f"ğŸ”„ ä»å­¦ä¹ æ¨¡å¼åˆ‡æ¢åˆ°åˆ©ç”¨æ¨¡å¼")
            self.model.set_exploitation_mode(True)
            self.model.is_converged = True
            self.model.save_model("final_contextual_model.pkl")
            
            # è®°å½•æ”¶æ•›æ—¶çš„ç»Ÿè®¡ä¿¡æ¯
            self.logger.info(f"ğŸ“Š æ”¶æ•›ç»Ÿè®¡: æ€»è½®æ¬¡={self.model.total_rounds}, åŠ¨ä½œç©ºé—´={len(self.model.available_frequencies)}ä¸ªé¢‘ç‡")
            
        elif not is_converged and self.model.exploitation_mode:
            # å¦‚æœä¹‹å‰æ”¶æ•›ä½†ç°åœ¨ä¸ç¨³å®šäº†ï¼Œå¯èƒ½éœ€è¦é‡æ–°å­¦ä¹ 
            self.logger.warning(f"âš ï¸ æ”¶æ•›çŠ¶æ€ä¸ç¨³å®š: å‰{top_k}ä¸ªåŠ¨ä½œè”åˆå æ¯”é™è‡³{top_k_combined_ratio:.1%} < {convergence_threshold:.0%}")
        
        return is_converged
    
    def _check_performance_degradation(self) -> bool:
        """æ£€æŸ¥æ€§èƒ½æ˜¯å¦é€€åŒ– - åŸºäºåŸå§‹EDPå€¼"""
        if self.model.total_rounds < 100:
            return False
        
        # ä½¿ç”¨EDPå†å²è€Œä¸æ˜¯å¥–åŠ±å†å²
        edp_history = self.model.edp_history
        if len(edp_history) < 100:
            return False
        
        recent_50_edp = edp_history[-50:]
        previous_50_edp = edp_history[-100:-50]
        
        if not previous_50_edp or not recent_50_edp:
            return False
        
        recent_avg_edp = np.mean(recent_50_edp)
        previous_avg_edp = np.mean(previous_50_edp)
        
        # EDPè¶Šå°è¶Šå¥½ï¼Œæ‰€ä»¥å¦‚æœæœ€è¿‘çš„å¹³å‡EDPæ¯”ä¹‹å‰çš„é«˜å‡ºé…ç½®é˜ˆå€¼ï¼Œå°±è®¤ä¸ºæ€§èƒ½é€€åŒ–
        if previous_avg_edp > 0:
            edp_ratio = recent_avg_edp / previous_avg_edp
            # ä¿®æ­£é˜ˆå€¼é€»è¾‘ï¼šåªæœ‰å½“EDPæ¶åŒ–è¶…è¿‡é…ç½®çš„ç™¾åˆ†æ¯”æ—¶æ‰è§¦å‘
            degradation_threshold = 1.0 + self.performance_degradation_threshold  # 0.65 -> 1.65
            if edp_ratio > degradation_threshold:
                self.logger.warning(f"âš ï¸ æ€§èƒ½é€€åŒ–æ£€æµ‹: æœ€è¿‘50è½®EDPå¹³å‡å€¼({recent_avg_edp:.4f}) "
                                  f"æ¯”å‰50è½®({previous_avg_edp:.4f})æ¶åŒ–äº†{(edp_ratio-1)*100:.1f}% > {self.performance_degradation_threshold*100:.0f}%")
                self.logger.warning(f"ğŸ”„ æ€§èƒ½é€€åŒ–è§¦å‘æ¡ä»¶: EDPæ¶åŒ–æ¯”ä¾‹ {edp_ratio:.3f} > é˜ˆå€¼ {degradation_threshold:.3f}")
                return True
            else:
                # è®°å½•è½»å¾®æ¶åŒ–ä½†æœªè§¦å‘çš„æƒ…å†µ
                if edp_ratio > 1.05:  # æ¶åŒ–è¶…è¿‡5%æ—¶è®°å½•infoçº§åˆ«æ—¥å¿—
                    self.logger.info(f"ğŸ“Š è½»å¾®æ€§èƒ½å˜åŒ–: EDPæ¶åŒ–{(edp_ratio-1)*100:.1f}% (æœªè¾¾åˆ°{self.performance_degradation_threshold*100:.0f}%è§¦å‘é˜ˆå€¼)")
        
        return False
    
    def _check_idle_mode(self, metrics: dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è¿›å…¥/é€€å‡ºä¼‘æ¯æ¨¡å¼ - åŸºäºæ­£åœ¨è¿è¡Œçš„è¯·æ±‚æ•°"""
        # è·å–æ­£åœ¨è¿è¡Œçš„è¯·æ±‚æ•°
        running_requests = metrics.get('vllm:num_requests_running', 0)
        
        # ç©ºé—²æ£€æµ‹ï¼šæ²¡æœ‰æ­£åœ¨è¿è¡Œçš„è¯·æ±‚
        is_currently_idle = (running_requests == 0)
        
        if is_currently_idle:
            self.idle_confirmation_count += 1
            
            # è¿ç»­3æ¬¡æ£€æµ‹åˆ°ç©ºé—²æ‰è¿›å…¥ä¼‘æ¯æ¨¡å¼ï¼ˆé¿å…çŸ­æš‚ç©ºé—²çš„è¯¯åˆ¤ï¼‰
            if not self.idle_mode and self.idle_confirmation_count >= 3:
                self.idle_mode = True
                self.last_idle_reset = False  # é‡ç½®é¢‘ç‡é‡ç½®æ ‡å¿—
                self.logger.info("ğŸ˜´ æ£€æµ‹åˆ°æŒç»­ç©ºé—²ï¼ˆæ— è¿è¡Œä»»åŠ¡ï¼‰ï¼Œè¿›å…¥ä¼‘æ¯æ¨¡å¼")
                return True
        else:
            # æœ‰è¿è¡Œä»»åŠ¡æ—¶é‡ç½®è®¡æ•°å¹¶é€€å‡ºä¼‘æ¯æ¨¡å¼
            if self.idle_mode:
                self.idle_mode = False
                self.idle_confirmation_count = 0
                self.logger.info(f"ğŸƒ æ£€æµ‹åˆ°è¿è¡Œä»»åŠ¡({running_requests}ä¸ª)ï¼Œé€€å‡ºä¼‘æ¯æ¨¡å¼ï¼Œæ¢å¤å­¦ä¹ ")
            else:
                self.idle_confirmation_count = 0
        
        return self.idle_mode
    
    def _handle_idle_mode(self):
        """å¤„ç†ä¼‘æ¯æ¨¡å¼ï¼šé‡ç½®é¢‘ç‡åˆ°å®‰å…¨å€¼ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰"""
        if self.idle_mode and not self.last_idle_reset:
            # é‡ç½®GPUé¢‘ç‡åˆ°å®‰å…¨çš„ç©ºé—²é¢‘ç‡ï¼ˆ210MHzï¼‰
            idle_frequency = 210  # MHzï¼Œå®‰å…¨çš„ç©ºé—²é¢‘ç‡
            if self.gpu_controller.set_frequency(idle_frequency):
                self.logger.info(f"ğŸ”§ ä¼‘æ¯æ¨¡å¼ï¼šGPUé¢‘ç‡å·²é‡ç½®ä¸º {idle_frequency}MHz")
                self.last_idle_reset = True
            else:
                self.logger.warning(f"âš ï¸ ä¼‘æ¯æ¨¡å¼ï¼šGPUé¢‘ç‡é‡ç½®å¤±è´¥")
    
    def _handle_data_collection_mode(self, features: np.ndarray, pre_metrics: dict, post_metrics: dict):
        """å¤„ç†æ•°æ®æ”¶é›†æ¨¡å¼ï¼šä»…æ”¶é›†æ•°æ®ä¸è°ƒé¢‘ï¼Œä½†æ”¶é›†å®Œæ•´çš„èƒ½é‡å’ŒEDPæ•°æ®"""
        # è·å–å½“å‰GPUé¢‘ç‡
        current_freq = self.gpu_controller.current_freq
        
        # è®°å½•æ•°æ®æ”¶é›†è½®æ¬¡
        data_round = getattr(self, '_data_collection_round', 0) + 1
        setattr(self, '_data_collection_round', data_round)
        
        self.logger.info(f"ğŸ“Š æ•°æ®æ”¶é›†æ¨¡å¼ - è½®æ¬¡ {data_round}: GPUé¢‘ç‡ {current_freq}MHz (æ— è°ƒé¢‘)")
        
        # è®¡ç®—EDPæ•°æ®ï¼ˆä¸å­¦ä¹ æ¨¡å¼ç›¸åŒçš„è®¡ç®—æ–¹å¼ï¼‰
        edp_value = 0.0
        energy_j = 0.0
        
        try:
            # è®¡ç®—èƒ½é‡æ¶ˆè€—ï¼ˆç›´æ¥ä½¿ç”¨ç„¦è€³ï¼‰
            energy_j = post_metrics.get('energy_delta_j', 0.0) or 0.0
            
            # è®¡ç®—å»¶è¿ŸæŒ‡æ ‡
            ttft_avg = 0.0
            tpot_avg = 0.0
            
            if post_metrics.get('vllm:time_to_first_token_seconds_count_delta', 0) > 0:
                ttft_avg = (post_metrics.get('vllm:time_to_first_token_seconds_sum_delta', 0.0) / 
                           post_metrics.get('vllm:time_to_first_token_seconds_count_delta', 1))
            
            if post_metrics.get('vllm:time_per_output_token_seconds_count_delta', 0) > 0:
                tpot_avg = (post_metrics.get('vllm:time_per_output_token_seconds_sum_delta', 0.0) / 
                           post_metrics.get('vllm:time_per_output_token_seconds_count_delta', 1))
            
            # è®¡ç®—EDP (Energy-Delay Product)
            if energy_j > 0 and (ttft_avg > 0 or tpot_avg > 0):
                total_latency = ttft_avg + tpot_avg
                edp_value = energy_j * total_latency
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ æ•°æ®æ”¶é›†æ¨¡å¼è®¡ç®—EDPå¤±è´¥: {e}")
        
        # è®°å½•å®Œæ•´æ•°æ®åˆ°å®éªŒæ–‡ä»¶
        if hasattr(self, 'experiment_recorder'):
            try:
                # ä½¿ç”¨ä¸å­¦ä¹ æ¨¡å¼ç›¸åŒçš„æ•°æ®è®°å½•æ–¹å¼
                self._record_experiment_data(
                    round_num=data_round,
                    features=features,
                    selected_action=current_freq,
                    reward=0.0,  # æ•°æ®æ”¶é›†æ¨¡å¼æ— å¥–åŠ±
                    edp_value=edp_value,
                    pre_metrics=pre_metrics,
                    post_metrics=post_metrics
                )
            except Exception as e:
                self.logger.error(f"âŒ æ•°æ®æ”¶é›†æ¨¡å¼è®°å½•å®éªŒæ•°æ®å¤±è´¥: {e}")
        
        print(f"ğŸ“Š æ•°æ®æ”¶é›†è½®æ¬¡: {data_round} (é¢‘ç‡: {current_freq}MHz, EDP: {edp_value:.6f}JÂ·s, èƒ½é‡: {energy_j:.6f}J)")
    
    def _log_round_details(self, round_num: int, features: np.ndarray, action, 
                          reward: float, edp_value: Optional[float], 
                          _pre_metrics: dict, post_metrics: dict):
        """è®°å½•æ¯ä¸€è½®çš„è¯¦ç»†ä¿¡æ¯åˆ°æ—¥å¿—æ–‡ä»¶"""
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—
        logging_config = self.config.get('logging', {})
        if not logging_config.get('detailed_round_logging', True):
            return
        
        # æå–å…³é”®æŒ‡æ ‡
        energy_delta = post_metrics.get('energy_delta_j', 0.0)
        
        # vLLMæŒ‡æ ‡
        ttft_count = post_metrics.get('vllm:time_to_first_token_seconds_count_delta', 0)
        ttft_sum = post_metrics.get('vllm:time_to_first_token_seconds_sum_delta', 0.0)
        tpot_count = post_metrics.get('vllm:time_per_output_token_seconds_count_delta', 0)
        tpot_sum = post_metrics.get('vllm:time_per_output_token_seconds_sum_delta', 0.0)
        
        # è®¡ç®—å¹³å‡å€¼
        avg_ttft = ttft_sum / ttft_count if ttft_count > 0 else 0.0
        avg_tpot = tpot_sum / tpot_count if tpot_count > 0 else 0.0
        
        # GPUä½¿ç”¨ç‡å’Œå†…å­˜ç­‰å…¶ä»–æŒ‡æ ‡
        gpu_util = post_metrics.get('gpu_utilization', 0.0)
        gpu_memory = post_metrics.get('gpu_memory_used', 0.0)
        queue_size = post_metrics.get('vllm:num_requests_waiting', 0)
        
        # æ¨¡å‹çŠ¶æ€
        model_stats = self.model.get_model_stats()
        
        # è·å–åŠ¨ä½œé€‰æ‹©ç»Ÿè®¡ï¼ˆå‘åå…¼å®¹ï¼‰
        available_freqs = self.gpu_controller.get_available_frequencies(self.model)
        action_selection_count = getattr(self.model, 'arm_counts', {}).get(action, 0)
        
        # åŠ¨ä½œæè¿°ï¼ˆå‘åå…¼å®¹ï¼‰
        if self.model.memory_optimization_enabled and isinstance(action, tuple):
            action_desc = f"{action[0]}MHzæ ¸å¿ƒ+{action[1]}MHzæ˜¾å­˜"
            freq_for_compat = action[0]  # ç”¨äºå…¼å®¹æ€§çš„æ ¸å¿ƒé¢‘ç‡
        else:
            action_desc = f"{action}MHzæ ¸å¿ƒ"
            freq_for_compat = action
        
        # è·å–æ­£ç¡®çš„ç‰¹å¾åç§°
        feature_names = self.feature_extractor.feature_names
        
        # è®°å½•å®Œæ•´ä¿¡æ¯
        self.logger.info(
            f"ğŸ” è½®æ¬¡ {round_num} è¯¦ç»†è®°å½•:\n"
            f"ğŸ“Š å†³ç­–ä¿¡æ¯:\n"
            f"   é€‰æ‹©åŠ¨ä½œ: {action_desc} (é€‰æ‹©æ¬¡æ•°: {action_selection_count})\n"
            f"   å¯ç”¨é¢‘ç‡: {len(available_freqs)}ä¸ª [{min(available_freqs)}-{max(available_freqs)}MHz]\n"
            f"   æ¨¡å¼: {'åˆ©ç”¨' if self.model.exploitation_mode else 'å­¦ä¹ '}\n"
            f"ğŸ¯ ç‰¹å¾å‘é‡ (7ç»´):\n"
            f"   [0]{feature_names[0]}: {features[0]:.3f}\n"
            f"   [1]{feature_names[1]}: {features[1]:.3f}\n"
            f"   [2]{feature_names[2]}: {features[2]:.3f}\n"
            f"   [3]{feature_names[3]}: {features[3]:.3f}\n"
            f"   [4]{feature_names[4]}: {features[4]:.3f}\n"
            f"   [5]{feature_names[5]}: {features[5]:.3f}\n"
            f"   [6]{feature_names[6]}: {features[6]:.3f}\n"
            f"âš¡ æ€§èƒ½æŒ‡æ ‡:\n"
            f"   TTFT: {avg_ttft:.4f}s (è®¡æ•°: {ttft_count})\n"
            f"   TPOT: {avg_tpot:.4f}s (è®¡æ•°: {tpot_count})\n"
            f"   èƒ½è€—å¢é‡: {energy_delta:.2f}mJ ({energy_delta/1000:.5f}J)\n"
            f"   EDPå€¼: {f'{edp_value:.6f}' if edp_value is not None else 'N/A'}\n"
            f"ğŸ’° å¥–åŠ±ä¿¡æ¯:\n"
            f"   å½“å‰å¥–åŠ±: {reward:+.4f}\n"
            f"   å¹³å‡å¥–åŠ±: {model_stats.get('avg_reward', 0.0):.4f}\n"
            f"   æœ€è¿‘å¹³å‡: {model_stats.get('recent_avg_reward', 0.0):.4f}\n"
            f"ğŸ–¥ï¸ ç³»ç»ŸçŠ¶æ€:\n"
            f"   GPUåˆ©ç”¨ç‡: {gpu_util:.1f}%\n"
            f"   GPUå†…å­˜: {gpu_memory:.1f}MB\n"
            f"   ç­‰å¾…é˜Ÿåˆ—: {queue_size}ä¸ªè¯·æ±‚\n"
            f"ğŸ“ˆ æ¨¡å‹ç»Ÿè®¡:\n"
            f"   æ€»è½®æ¬¡: {model_stats.get('total_rounds', 0)}\n"
            f"   åŠ¨ä½œç©ºé—´: {model_stats.get('n_arms', 0)}ä¸ªé¢‘ç‡\n"
            f"   æ¢ç´¢/åˆ©ç”¨: {'æ”¶æ•›' if model_stats.get('converged', False) else 'å­¦ä¹ ä¸­'}\n"
            f"{'='*80}"
        )
        
        # åŒæ—¶è®°å½•JSONæ ¼å¼çš„ç»“æ„åŒ–æ•°æ®ï¼Œä¾¿äºåç»­åˆ†æ
        round_data = {
            'timestamp': datetime.now().isoformat(),
            'round': round_num,
            'decision': {
                'selected_action': action_desc,
                'selected_frequency_compat': freq_for_compat,  # å‘åå…¼å®¹
                'selection_count': action_selection_count,
                'available_frequencies': available_freqs,
                'mode': 'exploitation' if self.model.exploitation_mode else 'exploration'
            },
            'features': {
                feature_names[0]: float(features[0]),
                feature_names[1]: float(features[1]),
                feature_names[2]: float(features[2]),
                feature_names[3]: float(features[3]),
                feature_names[4]: float(features[4]),
                feature_names[5]: float(features[5]),
                feature_names[6]: float(features[6])
            },
            'performance': {
                'avg_ttft': avg_ttft,
                'avg_tpot': avg_tpot,
                'ttft_count': ttft_count,
                'tpot_count': tpot_count,
                'energy_delta_j': energy_delta,
                'energy_delta_mj': energy_delta * 1000,
                'edp_value': edp_value
            },
            'reward': {
                'current': reward,
                'average': model_stats.get('avg_reward', 0.0),
                'recent_average': model_stats.get('recent_avg_reward', 0.0)
            },
            'system': {
                'gpu_utilization': gpu_util,
                'gpu_memory_mb': gpu_memory,
                'queue_size': queue_size
            },
            'model': {
                'total_rounds': model_stats.get('total_rounds', 0),
                'n_arms': model_stats.get('n_arms', 0),
                'converged': model_stats.get('converged', False),
                'exploitation_mode': self.model.exploitation_mode
            }
        }
        
        # è®°å½•JSONæ ¼å¼æ•°æ®
        self.logger.info(f"ğŸ“‹ JSONæ•°æ®: {json.dumps(round_data, ensure_ascii=False)}")
    
    def _record_experiment_data(self, round_num: int, features: np.ndarray, selected_action, 
                              reward: float, edp_value: float, pre_metrics: dict, post_metrics: dict):
        """è®°å½•å®éªŒæ•°æ®åˆ°æ–‡ä»¶"""
        try:
            # è·å–å¿…è¦çš„æ•°æ®
            feature_names = self.feature_extractor.feature_names
            
            # å¤„ç†åŠ¨ä½œä¿¡æ¯ï¼ˆæ”¯æŒç»„åˆé¢‘ç‡ï¼‰
            if isinstance(selected_action, tuple):
                gpu_frequency = selected_action[0]  # åªè®°å½•æ ¸å¿ƒé¢‘ç‡
            else:
                gpu_frequency = selected_action
            
            # è®¡ç®—å»¶è¿ŸæŒ‡æ ‡ï¼ˆä½¿ç”¨deltaç‰ˆæœ¬ï¼‰
            ttft_sum_key = 'vllm:time_to_first_token_seconds_sum_delta'
            ttft_count_key = 'vllm:time_to_first_token_seconds_count_delta'
            tpot_sum_key = 'vllm:time_per_output_token_seconds_sum_delta'
            tpot_count_key = 'vllm:time_per_output_token_seconds_count_delta'
            e2e_sum_key = 'vllm:e2e_request_latency_seconds_sum_delta'
            e2e_count_key = 'vllm:e2e_request_latency_seconds_count_delta'
            
            # è®¡ç®—å¹³å‡å»¶è¿Ÿ
            ttft_avg = 0.0
            tpot_avg = 0.0
            e2e_avg = 0.0
            
            if (ttft_sum_key in post_metrics and ttft_count_key in post_metrics and 
                post_metrics[ttft_count_key] and post_metrics[ttft_count_key] > 0):
                ttft_avg = post_metrics[ttft_sum_key] / post_metrics[ttft_count_key]
            
            if (tpot_sum_key in post_metrics and tpot_count_key in post_metrics and 
                post_metrics[tpot_count_key] and post_metrics[tpot_count_key] > 0):
                tpot_avg = post_metrics[tpot_sum_key] / post_metrics[tpot_count_key]
                
            if (e2e_sum_key in post_metrics and e2e_count_key in post_metrics and 
                post_metrics[e2e_count_key] and post_metrics[e2e_count_key] > 0):
                e2e_avg = post_metrics[e2e_sum_key] / post_metrics[e2e_count_key]
            
            # è®¡ç®—ååé‡ï¼ˆä½¿ç”¨deltaç‰ˆæœ¬æˆ–è®¡ç®—å·®å€¼ï¼‰
            # ä¼˜å…ˆä½¿ç”¨deltaç‰ˆæœ¬ï¼Œç¡®ä¿ä¸æ˜¯None
            prompt_delta = post_metrics.get('vllm:prompt_tokens_total_delta', 0) or 0
            generation_delta = post_metrics.get('vllm:generation_tokens_total_delta', 0) or 0
            
            # å¦‚æœæ²¡æœ‰deltaç‰ˆæœ¬ï¼Œæ‰‹åŠ¨è®¡ç®—
            if prompt_delta == 0 and generation_delta == 0:
                prompt_tokens_current = post_metrics.get('vllm:prompt_tokens_total', 0) or 0
                generation_tokens_current = post_metrics.get('vllm:generation_tokens_total', 0) or 0
                prompt_tokens_previous = pre_metrics.get('vllm:prompt_tokens_total', 0) or 0
                generation_tokens_previous = pre_metrics.get('vllm:generation_tokens_total', 0) or 0
                
                prompt_delta = prompt_tokens_current - prompt_tokens_previous
                generation_delta = generation_tokens_current - generation_tokens_previous
            
            # è®¡ç®—é‡‡æ ·æœŸé—´çš„æ—¶é—´å·®ï¼ˆä½¿ç”¨é…ç½®çš„é‡‡æ ·çª—å£ï¼‰
            metrics_config = self.config.get('metrics', {})
            sampling_duration = metrics_config.get('sampling_duration', 1.5) or 1.5  # ç¡®ä¿ä¸æ˜¯None
            
            total_delta = prompt_delta + generation_delta
            
            prefill_throughput = prompt_delta / sampling_duration if sampling_duration and sampling_duration > 0 else 0
            decode_throughput = generation_delta / sampling_duration if sampling_duration and sampling_duration > 0 else 0
            total_throughput = total_delta / sampling_duration if sampling_duration and sampling_duration > 0 else 0
            
            # è·å–èƒ½è€—ï¼ˆå·²ç»æ˜¯ç„¦è€³ï¼‰
            energy_j = post_metrics.get('energy_delta_j', 0.0) or 0.0
            
            # è®¡ç®—EDPä¿¡æ¯
            edp_raw = energy_j * tpot_avg if tpot_avg and tpot_avg > 0 else 0  # ä½¿ç”¨TPOTè€Œä¸æ˜¯E2E
            edp_normalized = reward  # rewardå°±æ˜¯å½’ä¸€åŒ–çš„EDP
            edp_baseline = getattr(self.reward_calculator, 'baseline_edp', 0) or 0
            
            # è·å–ç³»ç»ŸçŠ¶æ€ï¼ˆç¡®ä¿Noneå®‰å…¨ï¼‰
            running_requests = post_metrics.get('vllm:num_requests_running', 0) or 0
            waiting_requests = post_metrics.get('vllm:num_requests_waiting', 0) or 0
            active_requests = running_requests + waiting_requests
            cache_usage = (post_metrics.get('vllm:gpu_cache_usage_perc', 0) or 0) * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            
            current_success = post_metrics.get('vllm:request_success_total', 0) or 0
            previous_success = pre_metrics.get('vllm:request_success_total', 0) or 0
            completed_requests = current_success - previous_success
            
            # è·å–å­¦ä¹ ç®—æ³•çŠ¶æ€
            if self.data_collection_mode:
                learning_phase = 'DATA_COLLECTION'
                alpha_value = 0.0
            else:
                learning_phase = 'EXPLOITATION' if self.model.exploitation_mode else 'EXPLORATION'
                alpha_value = getattr(self.model, 'alpha', 0)
            
            # è·å–UCBç½®ä¿¡åº¦ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            ucb_confidence = 0.0
            if not self.data_collection_mode and hasattr(self.model, '_last_ucb_values') and self.model._last_ucb_values:
                action_key = selected_action if not isinstance(selected_action, tuple) else selected_action[0]
                ucb_confidence = self.model._last_ucb_values.get(action_key, 0.0)
            
            # è·å–åŠ¨ä½œé€‰æ‹©æ–¹æ³•
            if self.data_collection_mode:
                action_method = 'DATA_COLLECTION'
            else:
                action_method = 'GREEDY' if self.model.exploitation_mode else 'UCB'
            
            # è·å–é¢‘ç‡ç®¡ç†ä¿¡æ¯
            if self.data_collection_mode:
                available_freqs = 0
                pruned_freqs = 0
            else:
                available_freqs = len(getattr(self.model, 'available_frequencies', []))
                pruned_freqs = len(getattr(self.model, 'pruned_frequencies', set()))
            
            # è·å–å½“å‰é¢‘ç‡çš„æ¢ç´¢æ¬¡æ•°
            freq_exploration_count = 0
            if not self.data_collection_mode and hasattr(self.model, 'action_counts'):
                freq_exploration_count = self.model.action_counts.get(selected_action, 0)
            
            # æ£€æŸ¥SLOè¿è§„
            control_config = self.config.get('control', {})
            ttft_limit = control_config.get('ttft_limit', 2.0)
            tpot_limit = control_config.get('tpot_limit', 0.3)
            slo_violation = ttft_avg > ttft_limit or tpot_avg > tpot_limit
            
            # æ„å»ºç‰¹å¾å­—å…¸
            features_dict = {}
            for i, name in enumerate(feature_names):
                if i < len(features):
                    features_dict[name] = float(features[i])
            
            # åˆ›å»ºè½®æ¬¡æ•°æ®
            round_data = create_round_data_dict(
                round_num=round_num,
                gpu_frequency=gpu_frequency,
                energy_j=energy_j,
                ttft=ttft_avg,
                tpot=tpot_avg,
                e2e=e2e_avg,
                total_throughput=total_throughput,
                prefill_throughput=prefill_throughput,
                decode_throughput=decode_throughput,
                edp_raw=edp_raw,
                edp_normalized=edp_normalized,
                edp_baseline=edp_baseline,
                active_requests=int(active_requests),
                cache_usage=cache_usage,
                completed_requests=int(completed_requests),
                learning_phase=learning_phase,
                reward=reward,
                alpha=alpha_value,
                ucb_confidence=ucb_confidence,
                action_method=action_method,
                available_freqs=available_freqs,
                pruned_freqs=pruned_freqs,
                freq_exploration_count=freq_exploration_count,
                slo_violation=slo_violation,
                ttft_limit=ttft_limit,
                tpot_limit=tpot_limit,
                features=features_dict
            )
            
            # è®°å½•åˆ°æ–‡ä»¶
            self.experiment_recorder.record_round_data(round_data)
            
        except Exception as e:
            self.logger.error(f"âŒ è®°å½•å®éªŒæ•°æ®å¤±è´¥: {e}")
    
    def _update_adaptive_sampler(self, action, reward: float, post_metrics: dict):
        """æ›´æ–°è‡ªé€‚åº”é‡‡æ ·å™¨çš„åé¦ˆä¿¡æ¯ - ä»…åœ¨å­¦ä¹ æ¨¡å¼ä¸‹æ‰§è¡Œï¼Œæ”¯æŒç»„åˆé¢‘ç‡"""
        # æå–æ ¸å¿ƒé¢‘ç‡ç”¨äºæ—¥å¿—æ˜¾ç¤º
        core_freq = action[0] if isinstance(action, tuple) else action
        action_desc = f"{action[0]}MHzæ ¸å¿ƒ+{action[1]}MHzæ˜¾å­˜" if isinstance(action, tuple) else f"{action}MHzæ ¸å¿ƒ"
        self.logger.debug(f"ğŸ”„ æ›´æ–°è‡ªé€‚åº”é‡‡æ ·å™¨: è½®æ¬¡{getattr(self.model, 'total_rounds', 'N/A')}, {action_desc}")
        
        if not post_metrics:
            self.logger.warning("âš ï¸ post_metricsä¸ºç©ºï¼Œè·³è¿‡è‡ªé€‚åº”é‡‡æ ·å™¨æ›´æ–°")
            return
        
        # âœ… å…³é”®æ”¹è¿›ï¼šä»…åœ¨å­¦ä¹ æ¨¡å¼ä¸‹æ‰§è¡Œè‡ªé€‚åº”é‡‡æ ·
        if self.model.exploitation_mode:
            # åˆ©ç”¨æ¨¡å¼ä¸‹ä¸è¿›è¡Œé¢‘ç‡ç©ºé—´æ¢ç´¢ï¼Œä½†æ£€æŸ¥æ˜¯å¦æœ‰ä¸¥é‡SLOè¿è§„
            control_config = self.config.get('control', {})
            ignore_slo = control_config.get('ignore_slo', True)
            
            if not ignore_slo:
                # åœ¨åˆ©ç”¨æ¨¡å¼ä¸‹ä¹Ÿéœ€è¦æ­£ç¡®å¤„ç†ç»„åˆé¢‘ç‡çš„SLOæ£€æŸ¥
                check_freq = action[0] if isinstance(action, tuple) else action
                slo_violated = self.reward_calculator.check_slo_violation(post_metrics, check_freq)
                if slo_violated:
                    self.logger.warning("âš ï¸ åˆ©ç”¨æ¨¡å¼ä¸‹æ£€æµ‹åˆ°SLOè¿è§„ï¼Œå¯èƒ½ç¯å¢ƒå‘ç”Ÿé‡å¤§å˜åŒ–")
                    self.logger.info("ğŸ”„ ä»åˆ©ç”¨æ¨¡å¼åˆ‡æ¢å›å­¦ä¹ æ¨¡å¼ä»¥é‡æ–°é€‚åº”ç¯å¢ƒ")
                    self.model.set_exploitation_mode(False)
                    self.model.is_converged = False
                    # ç»§ç»­æ‰§è¡Œä¸‹é¢çš„è‡ªé€‚åº”é‡‡æ ·é€»è¾‘
                else:
                    self.logger.debug("ğŸ”’ åˆ©ç”¨æ¨¡å¼ä¸‹è·³è¿‡è‡ªé€‚åº”é‡‡æ ·å™¨æ›´æ–°ï¼ˆå·²æ”¶æ•›ï¼Œæ€§èƒ½æ­£å¸¸ï¼‰")
                    return
            else:
                self.logger.debug("ğŸ”’ åˆ©ç”¨æ¨¡å¼ä¸‹è·³è¿‡è‡ªé€‚åº”é‡‡æ ·å™¨æ›´æ–°ï¼ˆå·²æ”¶æ•›ï¼Œä¸å†æ¢ç´¢ï¼‰")
                return
            
        # 1. æ›´æ–°é¢‘ç‡å¥–åŠ±åé¦ˆï¼ˆä¼ é€’LinUCBæ¨¡å‹å’Œå½“å‰ä¸Šä¸‹æ–‡ç”¨äºæ™ºèƒ½ç»†åŒ–ï¼‰
        # è·å–å½“å‰ä¸Šä¸‹æ–‡ç‰¹å¾
        try:
            current_features, _, _ = self._get_current_state()
        except:
            current_features = None
        
        frequency_space_updated = self.gpu_controller.update_frequency_reward(
            core_freq, reward, 
            linucb_model=self.model, 
            current_context=current_features
        )
        
        # 2. æ£€æŸ¥SLOè¿è§„ï¼ˆåªåœ¨éignore_sloæ¨¡å¼ä¸‹ï¼‰
        control_config = self.config.get('control', {})
        ignore_slo = control_config.get('ignore_slo', True)
        
        if not ignore_slo:
            # æ£€æŸ¥SLOè¿è§„æ—¶éœ€è¦ä¼ é€’å®Œæ•´çš„åŠ¨ä½œä¿¡æ¯ï¼ˆæ”¯æŒç»„åˆé¢‘ç‡ï¼‰
            check_freq = action[0] if isinstance(action, tuple) else action
            slo_violated = self.reward_calculator.check_slo_violation(post_metrics, check_freq)
            if slo_violated:
                # ä¼ é€’å®Œæ•´çš„åŠ¨ä½œç»™SLOè¿è§„å¤„ç†å™¨
                slo_space_updated = self.gpu_controller.update_slo_violation(action)
                if slo_space_updated:
                    frequency_space_updated = True
        
        # 3. å¦‚æœé¢‘ç‡ç©ºé—´å‘ç”Ÿäº†æ›´æ–°ï¼Œé‡æ–°è®¾ç½®æ¨¡å‹çš„åŠ¨ä½œç©ºé—´
        if frequency_space_updated:
            new_frequencies = self.gpu_controller.get_available_frequencies(self.model)
            self.model.update_action_space(new_frequencies)
            
            # å¦‚æœå¯ç”¨äº†æ˜¾å­˜é¢‘ç‡ä¼˜åŒ–ï¼Œä¹Ÿéœ€è¦åŒæ­¥æ˜¾å­˜é¢‘ç‡åˆ—è¡¨
            if (self.model.memory_optimization_enabled and 
                self.gpu_controller.enable_memory_frequency_control and 
                self.gpu_controller.memory_frequency_supported):
                
                new_memory_frequencies = self.gpu_controller.get_available_memory_frequencies()
                if hasattr(self.model, 'update_memory_frequencies'):
                    self.model.update_memory_frequencies(new_memory_frequencies)
                else:
                    # ç›´æ¥æ›´æ–°æ˜¾å­˜é¢‘ç‡åˆ—è¡¨
                    self.model.available_memory_frequencies = new_memory_frequencies
                    self.logger.info(f"ğŸ’¾ åŒæ­¥æ˜¾å­˜é¢‘ç‡åˆ—è¡¨: {len(new_memory_frequencies)}ä¸ªé¢‘ç‡")
            
            self.logger.info(f"ğŸ¯ å­¦ä¹ æ¨¡å¼ä¸‹è‡ªé€‚åº”é‡‡æ ·å™¨è§¦å‘é¢‘ç‡ç©ºé—´æ›´æ–°: {len(new_frequencies)}ä¸ªé¢‘ç‡")
            self.logger.info("ğŸ“Š å‘ç°æ–°çš„é¢‘ç‡åŒºåŸŸï¼Œç»§ç»­æ¢ç´¢å­¦ä¹ ")
    
    
    def run(self):
        """è¿è¡Œä¸»æ§åˆ¶å¾ªç¯"""
        self.logger.info("ğŸ® å¼€å§‹ä¸»æ§åˆ¶å¾ªç¯...")
        self.running = True
        
        
        # è¿è¡Œç»Ÿè®¡  
        start_time = time.time()
        self.logger.info(f"ğŸš€ å¼€å§‹æ—¶é—´: {datetime.fromtimestamp(start_time).strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            while self.running:
                try:
                    # è·å–å½“å‰çŠ¶æ€
                    features, available_frequencies, metrics = self._get_current_state()
                    
                    # Baselineæ”¶é›†ï¼šåªæœ‰åœ¨æœ‰ä»»åŠ¡æ—¶æ‰å¼€å§‹åŸºçº¿æ”¶é›†
                    current_round = getattr(self.model, 'total_rounds', 0) or 0
                    baseline_target = self.reward_calculator.baseline_target_count
                    if not self.reward_calculator.baseline_collected and current_round < baseline_target:
                        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡ - åªæœ‰åœ¨æœ‰ä»»åŠ¡æ—¶æ‰è¿›è¡ŒåŸºçº¿æ”¶é›†
                        running_requests = metrics.get('vllm:num_requests_running', 0)
                        has_queue = metrics.get('vllm:num_requests_waiting', 0) > 0
                        
                        if running_requests == 0 and not has_queue:
                            # æ²¡æœ‰ä»»åŠ¡ï¼Œç­‰å¾…ä»»åŠ¡å¼€å§‹
                            self.logger.info("â³ ç­‰å¾…ä»»åŠ¡å¼€å§‹ä»¥è¿›è¡ŒåŸºçº¿æ”¶é›†...")
                            self.logger.info(f"   å½“å‰çŠ¶æ€: è¿è¡Œä»»åŠ¡={running_requests}, ç­‰å¾…é˜Ÿåˆ—={has_queue}")
                            self.logger.info("   è¯´æ˜: ç³»ç»Ÿå°†ç­‰å¾…æ£€æµ‹åˆ°ä»»åŠ¡åæ‰å¼€å§‹åŸºçº¿EDPæ”¶é›†")
                            time.sleep(2)  # ç­‰å¾…ä»»åŠ¡åˆ°æ¥
                            continue
                        
                        measurement_num = len(self.reward_calculator.baseline_measurements) + 1
                        self.logger.info(f"ğŸ¯ æ£€æµ‹åˆ°ä»»åŠ¡ï¼Œå¼€å§‹åŸºçº¿EDPæ”¶é›†è½®æ¬¡ {measurement_num}/{baseline_target}...")
                        self.logger.info(f"   å½“å‰çŠ¶æ€: è¿è¡Œä»»åŠ¡={running_requests}, ç­‰å¾…é˜Ÿåˆ—={has_queue}")
                        # åŸºçº¿æ”¶é›†ä½¿ç”¨å®‰å…¨çš„é»˜è®¤é¢‘ç‡ï¼Œä¸å°è¯•æ”¹å˜é¢‘ç‡
                        default_freq = self.gpu_controller.current_freq
                        self.logger.info(f"ğŸ¯ åŸºçº¿æ”¶é›†ä½¿ç”¨å½“å‰é¢‘ç‡ {default_freq}MHzï¼ˆä¸æ”¹å˜é¢‘ç‡ï¼‰")
                        
                        # ç›´æ¥æ”¶é›†æŒ‡æ ‡è€Œä¸è®¾ç½®é¢‘ç‡
                        reward, post_metrics, edp_value = self._collect_baseline_metrics()
                        
                        # åªæœ‰åœ¨æ”¶é›†åˆ°æœ‰æ•ˆæŒ‡æ ‡æ—¶æ‰æ›´æ–°æ¨¡å‹
                        if post_metrics and reward != 0.0:
                            # æ›´æ–°æ¨¡å‹ä»¥å¢åŠ è½®æ¬¡è®¡æ•°
                            self.model.update(features, default_freq, reward, edp_value)
                            
                            # è®°å½•baselineæ”¶é›†
                            current_round = self.model.total_rounds
                            if self.reward_calculator.baseline_collected:
                                self.logger.info(f"âœ… Baseline EDPæ”¶é›†å…¨éƒ¨å®Œæˆ (è½®æ¬¡: {current_round}, é¢‘ç‡: {default_freq}MHz)")
                            else:
                                self.logger.info(f"ğŸ”„ Baseline EDPæµ‹é‡è¿›è¡Œä¸­ {measurement_num}/{baseline_target} (è½®æ¬¡: {current_round})")
                            
                            # è®°å½•è¯¦ç»†ä¿¡æ¯
                            self._log_round_details(current_round, features, default_freq, 
                                                  reward, edp_value, metrics, post_metrics)
                            self._record_experiment_data(current_round, features, default_freq, 
                                                       reward, edp_value, metrics, post_metrics)
                        else:
                            # æ²¡æœ‰æ”¶é›†åˆ°æœ‰æ•ˆæŒ‡æ ‡ï¼Œä¸å¢åŠ è½®æ¬¡è®¡æ•°
                            self.logger.info("â¸ï¸ åŸºçº¿æ”¶é›†æœŸé—´æ— ä»»åŠ¡ï¼Œæš‚åœæ­¤è½®æ”¶é›†")
                            time.sleep(1.0)  # çŸ­æš‚ç­‰å¾…åé‡è¯•
                        
                        # ç»§ç»­ä¸‹ä¸€è½®
                        time.sleep(1.8)  # åŸºçº¿æ”¶é›†åçŸ­æš‚ä¼‘æ¯
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥è¿›å…¥ä¼‘æ¯æ¨¡å¼
                    is_idle = self._check_idle_mode(metrics)
                    
                    if is_idle:
                        # è¿›å…¥ä¼‘æ¯æ¨¡å¼ï¼šé‡ç½®é¢‘ç‡ï¼Œç­‰å¾…ï¼Œä¸å¢åŠ å†³ç­–è½®æ¬¡
                        self._handle_idle_mode()
                        time.sleep(2)  # ä¼‘æ¯æ¨¡å¼ä¸‹ç­‰å¾…2ç§’
                        continue  # è·³è¿‡å­¦ä¹ ï¼Œä¸å¢åŠ è½®æ¬¡
                    
                    # æ•°æ®æ”¶é›†æ¨¡å¼ï¼šä»…æ”¶é›†æ•°æ®ä¸è°ƒé¢‘ï¼Œä½†æ”¶é›†å®Œæ•´çš„èƒ½é‡å’ŒEDPæ•°æ®
                    if self.data_collection_mode:
                        # æ•°æ®æ”¶é›†æ¨¡å¼ä¸‹ä¹Ÿéœ€è¦åŒé‡æŒ‡æ ‡æ”¶é›†æ¥è®¡ç®—èƒ½é‡å’ŒEDP
                        pre_metrics = metrics.copy()
                        
                        # ç­‰å¾…ç¡¬ä»¶ç¨³å®šï¼ˆä¸å­¦ä¹ æ¨¡å¼ç›¸åŒï¼‰
                        time.sleep(0.3)
                        
                        # æ”¶é›†æ‰§è¡Œåçš„æŒ‡æ ‡
                        post_metrics = self.metrics_collector.collect_metrics(
                            energy_reader=self.gpu_controller.read_energy_j
                        )
                        
                        # è®¡ç®—deltaæŒ‡æ ‡
                        for key in post_metrics:
                            if key in pre_metrics and (key.endswith('_total') or key.endswith('_sum') or key.endswith('_count')):
                                delta_key = key + '_delta'
                                post_metrics[delta_key] = post_metrics[key] - pre_metrics[key]
                        
                        # å¤„ç†æ•°æ®æ”¶é›†æ¨¡å¼
                        self._handle_data_collection_mode(features, pre_metrics, post_metrics)
                        
                        time.sleep(1.5)  # ä¿æŒä¸å†³ç­–é—´éš”ç›¸ä¼¼çš„èŠ‚å¥
                        continue
                    
                    # æ­£å¸¸å­¦ä¹ æ¨¡å¼ï¼šåšå‡ºå†³ç­–
                    selected_action = self._make_decision(features, available_frequencies)
                    
                    # æ‰§è¡ŒåŠ¨ä½œå¹¶æµ‹é‡å¥–åŠ±
                    reward, post_metrics, edp_value = self._execute_action_and_measure(selected_action, is_baseline=False)
                    
                    # æ›´æ–°æ¨¡å‹ï¼ˆåªæœ‰åœ¨æœ‰æœ‰æ•ˆåŠ¨ä½œæ—¶æ‰æ›´æ–°ï¼‰
                    if selected_action is not None:
                        self.model.update(features, selected_action, reward, edp_value)
                    else:
                        self.logger.info("ğŸ“Š é‡ç½®æ¨¡å¼ï¼Œè·³è¿‡æ¨¡å‹æ›´æ–°ï¼Œç»§ç»­ç›‘æ§ç³»ç»ŸçŠ¶æ€")
                    
                    # æ˜¾ç¤ºå½“å‰è½®æ¬¡å’Œè®°å½•æ•°æ®ï¼ˆåªæœ‰åœ¨æœ‰æ•ˆåŠ¨ä½œæ—¶ï¼‰
                    if selected_action is not None:
                        current_round = getattr(self.model, 'total_rounds', 0) or 0
                        print(f"ğŸ¯ å½“å‰å†³ç­–è½®æ¬¡: {current_round}")
                        
                        # è®°å½•è¯¦ç»†çš„æ¯è½®ä¿¡æ¯
                        self._log_round_details(self.model.total_rounds, features, selected_action, 
                                              reward, edp_value, metrics, post_metrics)
                        
                        # è®°å½•å®éªŒæ•°æ®åˆ°æ–‡ä»¶
                        self._record_experiment_data(self.model.total_rounds, features, selected_action, 
                                                    reward, edp_value, metrics, post_metrics)
                    else:
                        # é‡ç½®æ¨¡å¼ä¸‹åªæ˜¾ç¤ºçŠ¶æ€
                        current_freq = self.gpu_controller._get_current_frequency()
                        print(f"ğŸ”„ GPUé‡ç½®æ¨¡å¼è¿è¡Œä¸­ (å½“å‰é¢‘ç‡: {current_freq}MHz)")
                    
                    # é›†æˆè‡ªé€‚åº”é‡‡æ ·å™¨åé¦ˆ (ä»…åœ¨æœ‰æœ‰æ•ˆåŠ¨ä½œæ—¶)
                    if selected_action is not None:
                        # ä¿®å¤ï¼šä¼ é€’å®Œæ•´çš„åŠ¨ä½œä¿¡æ¯æ”¯æŒç»„åˆé¢‘ç‡SLOå¤„ç†
                        self._update_adaptive_sampler(selected_action, reward, post_metrics)
                    
                    # æ‰§è¡Œæ™ºèƒ½åŠ¨ä½œä¿®å‰ªæ£€æŸ¥ï¼ˆä»…åœ¨æœ‰æœ‰æ•ˆåŠ¨ä½œæ—¶ï¼‰
                    if selected_action is not None and hasattr(self.model, '_perform_action_pruning'):
                        # è®°å½•ä¿®å‰ªå‰çš„çŠ¶æ€
                        pruned_before = len(getattr(self.model, 'pruned_frequencies', set()))
                        
                        # æ‰§è¡Œä¿®å‰ªï¼ˆå†…éƒ¨ä¼šæ£€æŸ¥æ¡ä»¶ï¼‰
                        self.model._perform_action_pruning()
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„ä¿®å‰ªå‘ç”Ÿ
                        pruned_after = len(getattr(self.model, 'pruned_frequencies', set()))
                        if pruned_after > pruned_before:
                            # æœ‰æ–°ä¿®å‰ªå‘ç”Ÿï¼Œéœ€è¦åŒæ­¥å¯ç”¨é¢‘ç‡åˆ—è¡¨
                            self.logger.debug(f"ğŸ”„ æ£€æµ‹åˆ°æ–°ä¿®å‰ª({pruned_after - pruned_before}ä¸ª)ï¼ŒåŒæ­¥é¢‘ç‡åˆ—è¡¨")
                            # ä½¿ç”¨ç»Ÿä¸€æ–¹æ³•è·å–æœ€æ–°çš„å¯ç”¨é¢‘ç‡
                            if hasattr(self.gpu_controller, 'adaptive_sampler'):
                                updated_frequencies = self.gpu_controller.adaptive_sampler.get_available_frequencies_unified(
                                    linucb_model=self.model,
                                    gpu_controller=self.gpu_controller
                                )
                                # æ›´æ–°æ¨¡å‹çš„åŠ¨ä½œç©ºé—´
                                self.model.update_action_space(updated_frequencies)
                        
                        # æ¯20è½®æ˜¾ç¤ºä¸€æ¬¡ä¿®å‰ªçŠ¶æ€
                        if self.model.total_rounds % 20 == 0:
                            pruning_stats = self.model.get_model_stats()
                            self.logger.info(f"ğŸ“Š æ™ºèƒ½ä¿®å‰ªçŠ¶æ€ - è½®æ¬¡{self.model.total_rounds}: "
                                           f"å·²ä¿®å‰ª{pruning_stats.get('pruned_frequencies_count', 0)}ä¸ªé¢‘ç‡, "
                                           f"æ´»è·ƒé¢‘ç‡{pruning_stats.get('active_frequencies_count', 0)}ä¸ª")
                    
                    # å®šæœŸä¿å­˜æ¨¡å‹
                    if self.model.total_rounds % 50 == 0:
                        self.model.save_model()
                        
                        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
                        stats = self.model.get_model_stats()
                        mode_str = "åˆ©ç”¨(å·²æ”¶æ•›)" if self.model.exploitation_mode else "å­¦ä¹ (æ¢ç´¢ä¸­)"
                        self.logger.info(f"ğŸ“Š è½®æ¬¡ {self.model.total_rounds}: "
                                       f"å¥–åŠ±={reward:.3f}, "
                                       f"å¹³å‡å¥–åŠ±={stats['avg_reward']:.3f}, "
                                       f"æ¨¡å¼={mode_str}, "
                                       f"é¢‘ç‡ç©ºé—´={stats.get('n_arms', 0)}ä¸ª")
                    
                    # æ£€æŸ¥æ”¶æ•› (å­¦ä¹ â†’åˆ©ç”¨æ¨¡å¼åˆ‡æ¢)
                    self._check_convergence()
                    
                    # æ£€æŸ¥æ€§èƒ½é€€åŒ– (åˆ©ç”¨â†’å­¦ä¹ æ¨¡å¼åˆ‡æ¢)
                    if self.model.exploitation_mode and self._check_performance_degradation():
                        self.logger.warning("ğŸ”„ æ£€æµ‹åˆ°æ€§èƒ½é€€åŒ–ï¼Œä»åˆ©ç”¨æ¨¡å¼åˆ‡æ¢å›å­¦ä¹ æ¨¡å¼")
                        self.model.set_exploitation_mode(False)
                        self.model.is_converged = False
                        self.logger.info("ğŸ“Š é‡æ–°è¿›å…¥å­¦ä¹ é˜¶æ®µï¼Œå°†é‡æ–°æ¢ç´¢é¢‘ç‡ç©ºé—´")
                    
                except Exception as e:
                    self.logger.error(f"âŒ æ§åˆ¶å¾ªç¯å¼‚å¸¸: {e}")
                    time.sleep(5)  # é”™è¯¯åç­‰å¾…5ç§’
                    
        except KeyboardInterrupt:
            self.logger.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        
        finally:
            self._cleanup()
    
    def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†èµ„æº...")
        
        # ç»“æŸå®éªŒå¹¶ä¿å­˜æ•°æ®
        if hasattr(self, 'experiment_recorder'):
            self.experiment_recorder.finalize_experiment()
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        if hasattr(self, 'model'):
            self.model.save_model()
            
            # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
            stats = self.model.get_model_stats()
            self.logger.info("ğŸ“ˆ æœ€ç»ˆç»Ÿè®¡:")
            self.logger.info(f"   æ€»è½®æ¬¡: {stats['total_rounds']}")
            self.logger.info(f"   å¹³å‡å¥–åŠ±: {stats['avg_reward']:.3f}")
            self.logger.info(f"   æœ€è¿‘å¹³å‡å¥–åŠ±: {stats['recent_avg_reward']:.3f}")
            self.logger.info(f"   é¢‘ç‡æ•°é‡: {stats['n_arms']}")
        
        # é‡ç½®GPUé¢‘ç‡åˆ°å®‰å…¨å€¼
        if hasattr(self, 'gpu_controller'):
            self.gpu_controller.reset_gpu_clocks()
        
        self.logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")
        self.logger.info("ğŸ‘‹ vLLM GPUè‡ªåŠ¨è°ƒé¢‘å™¨å·²é€€å‡º")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="vLLM GPUè‡ªåŠ¨è°ƒé¢‘å™¨ - Contextual LinUCBç‰ˆæœ¬")
    parser.add_argument("--config", default="config/config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--reset-model", action="store_true", help="é‡ç½®æ¨¡å‹ï¼Œä»é›¶å¼€å§‹")
    parser.add_argument("--log-level", default="INFO", choices=["DEBUG", "INFO", "WARNING", "ERROR"])
    
    args = parser.parse_args()
    
    print("ğŸš€ å¯åŠ¨vLLM GPUè‡ªåŠ¨è°ƒé¢‘å™¨ (Contextual LinUCB)")
    print(f"ğŸ“ é…ç½®æ–‡ä»¶: {args.config}")
    print(f"ğŸ”„ é‡ç½®æ¨¡å‹: {'æ˜¯' if args.reset_model else 'å¦'}")
    print(f"ğŸ“Š æ—¥å¿—çº§åˆ«: {args.log_level}")
    print("=" * 60)
    
    try:
        # åˆ›å»ºå¹¶è¿è¡Œè‡ªåŠ¨è°ƒé¢‘å™¨
        autoscaler = VLLMGPUAutoscaler(
            config_path=args.config,
            reset_model=args.reset_model
        )
        autoscaler.run()
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()