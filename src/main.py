import time
import yaml
import signal
import sys
import argparse
import numpy as np
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Optional
from collections import Counter
import pynvml

from .logger import setup_logger
from .metrics_collector import MetricsCollector
from .gpu_controller import GPUController
from .feature_extractor import FeatureExtractor
from .contextual_bandit import ContextualLinUCB
from .reward_calculator import EDPRewardCalculator


def get_gpu_model_for_logging(gpu_id: int = 0) -> str:
    """è·å–GPUå‹å·ç”¨äºæ—¥å¿—ç›®å½•åˆ†ç±»"""
    try:
        pynvml.nvmlInit()
        nvml_handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_id)
        gpu_name = pynvml.nvmlDeviceGetName(nvml_handle)
        if isinstance(gpu_name, bytes):
            gpu_name = gpu_name.decode('utf-8')
        
        # æ¸…ç†GPUåç§°ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œç”¨äºç›®å½•å
        cleaned_name = gpu_name.replace("NVIDIA ", "").replace("GeForce ", "")
        cleaned_name = cleaned_name.replace(" ", "_").replace("-", "_")
        # ç§»é™¤å¸¸è§çš„åç¼€ä¿¡æ¯
        for suffix in ["_SXM2", "_32GB", "_16GB", "_8GB", "_PCIE", "_SMX2"]:
            if suffix in cleaned_name:
                cleaned_name = cleaned_name.split(suffix)[0]
                break
        
        return cleaned_name[:20]  # é™åˆ¶é•¿åº¦é¿å…è·¯å¾„è¿‡é•¿
        
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è·å–GPUå‹å·ä¿¡æ¯: {e}")
        return "Unknown_GPU"


def create_gpu_classified_log_dir(config_path: str = "config/config.yaml") -> tuple[Path, str]:
    """æ ¹æ®é…ç½®æ–‡ä»¶ä¸­çš„GPU IDåˆ›å»ºåˆ†ç±»çš„æ—¥å¿—ç›®å½•"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        gpu_id = config.get('gpu', {}).get('device_id', 0)
    except Exception:
        gpu_id = 0
    
    gpu_model = get_gpu_model_for_logging(gpu_id)
    log_dir = Path("logs") / gpu_model
    log_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = f"vllm_gpu_autoscaler_{timestamp}.log"
    
    return log_dir / log_file, gpu_model


class VLLMGPUAutoscaler:
    """vLLM GPUè‡ªåŠ¨è°ƒé¢‘å™¨ - çº¯Contextual LinUCBç‰ˆæœ¬"""
    
    def __init__(self, config_path: str = "config/config.yaml", reset_model: bool = False):
        """åˆå§‹åŒ–è‡ªåŠ¨è°ƒé¢‘å™¨"""
        self.config_path = config_path
        self.reset_model = reset_model
        self.running = False
        
        # åŠ è½½é…ç½®
        self.config = self._load_config()
        
        # è®¾ç½®æ—¥å¿—
        log_file_path, gpu_model = create_gpu_classified_log_dir(config_path)
        logging_config = self.config.get('logging', {})
        
        # è·å–æ—¥å¿—çº§åˆ«
        console_level_str = logging_config.get('console_level', 'INFO').upper()
        file_level_str = logging_config.get('file_level', 'DEBUG').upper()
        
        # è½¬æ¢ä¸ºloggingçº§åˆ«
        import logging
        level_map = {
            'DEBUG': logging.DEBUG,
            'INFO': logging.INFO,
            'WARNING': logging.WARNING,
            'ERROR': logging.ERROR,
            'CRITICAL': logging.CRITICAL
        }
        console_level = level_map.get(console_level_str, logging.INFO)
        file_level = level_map.get(file_level_str, logging.DEBUG)
        
        self.logger = setup_logger("VLLMAutoscaler", str(log_file_path), 
                                  console_level=console_level, file_level=file_level)
        
        self.logger.info("=" * 80)
        self.logger.info("ğŸš€ vLLM GPUè‡ªåŠ¨è°ƒé¢‘å™¨å¯åŠ¨")
        self.logger.info(f"ğŸ“ é…ç½®æ–‡ä»¶: {config_path}")
        self.logger.info(f"ğŸ”§ GPUå‹å·: {gpu_model}")
        self.logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file_path}")
        self.logger.info(f"ğŸ“Š æ—¥å¿—çº§åˆ«: æ§åˆ¶å°={console_level_str}, æ–‡ä»¶={file_level_str}")
        self.logger.info(f"ğŸ” è¯¦ç»†è½®æ¬¡è®°å½•: {'å¯ç”¨' if logging_config.get('detailed_round_logging', True) else 'ç¦ç”¨'}")
        self.logger.info("=" * 80)
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self._init_components()
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        self.logger.info("âœ… vLLM GPUè‡ªåŠ¨è°ƒé¢‘å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            sys.exit(1)
    
    def _init_components(self):
        """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""
        # åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†å™¨
        prometheus_url = self.config['vllm']['prometheus_url']
        metrics_config = self.config.get('metrics', {})
        self.metrics_collector = MetricsCollector(prometheus_url, **metrics_config)
        
        # åˆå§‹åŒ–GPUæ§åˆ¶å™¨
        gpu_config = self.config.get('gpu', {})
        # æ˜ å°„å‚æ•°åç§°ä»¥åŒ¹é…GPUControlleræœŸæœ›çš„å‚æ•°
        gpu_controller_args = {}
        if 'device_id' in gpu_config:
            gpu_controller_args['gpu_id'] = gpu_config['device_id']
        if 'frequency_step' in gpu_config:
            gpu_controller_args['step'] = gpu_config['frequency_step']
        if 'min_frequency' in gpu_config:
            gpu_controller_args['min_freq'] = gpu_config['min_frequency']
        # ç›´æ¥æ˜ å°„çš„å‚æ•° (ç§»é™¤max_action_counté™åˆ¶)
        for key in ['auto_step', 'enable_memory_frequency_control', 
                   'memory_auto_detect', 'memory_frequencies']:
            if key in gpu_config:
                gpu_controller_args[key] = gpu_config[key]
        # ä»controlé…ç½®ä¸­è·å–ignore_sloå‚æ•°å’Œæˆç†Ÿåº¦é˜ˆå€¼
        control_config = self.config.get('control', {})
        if 'ignore_slo' in control_config:
            gpu_controller_args['ignore_slo'] = control_config['ignore_slo']
        if 'adaptive_update_interval' in control_config:
            gpu_controller_args['adaptive_update_interval'] = control_config['adaptive_update_interval']
        if 'learner_maturity_threshold' in control_config:
            gpu_controller_args['learner_maturity_threshold'] = control_config['learner_maturity_threshold']
        if 'refinement_start_threshold' in control_config:
            gpu_controller_args['refinement_start_threshold'] = control_config['refinement_start_threshold']
        # ä»adaptive_samplingé…ç½®ä¸­è·å–reward_thresholdå‚æ•°
        adaptive_config = self.config.get('adaptive_sampling', {})
        if 'reward_threshold' in adaptive_config:
            gpu_controller_args['reward_threshold'] = adaptive_config['reward_threshold']
        
        self.gpu_controller = GPUController(**gpu_controller_args)
        
        # åˆå§‹åŒ–ç‰¹å¾æå–å™¨
        self.feature_extractor = FeatureExtractor()
        
        # åˆå§‹åŒ–å¥–åŠ±è®¡ç®—å™¨
        control_config = self.config.get('control', {})
        self.reward_calculator = EDPRewardCalculator(
            ttft_limit=control_config.get('ttft_limit', 2.0),
            tpot_limit=control_config.get('tpot_limit', 0.25),
            ignore_slo=control_config.get('ignore_slo', True)
        )
        
        # åˆå§‹åŒ–Contextual LinUCBæ¨¡å‹ (ä¸å†æ”¯æŒç¥ç»ç½‘ç»œ)
        linucb_config = self.config.get('linucb', {})
        self.model = ContextualLinUCB(
            n_features=7,  # ä»…å·¥ä½œè´Ÿè½½ç‰¹å¾ï¼Œä¸åŒ…å«é¢‘ç‡
            alpha=linucb_config.get('initial_alpha', 0.1),  # å¤§å¹…é™ä½alphaå‡å°‘è¿‡åº¦æ¢ç´¢
            lambda_reg=linucb_config.get('lambda_reg', 5.0),  # ä¿æŒæ­£åˆ™åŒ–æé«˜æ•°å€¼ç¨³å®šæ€§
            alpha_decay_rate=linucb_config.get('alpha_decay_rate', 0.01),  # alphaè¡°å‡ç‡
            min_alpha=linucb_config.get('min_alpha', 0.1),  # æœ€å°alphaå€¼
            # æ™ºèƒ½åŠ¨ä½œä¿®å‰ªå‚æ•°
            enable_action_pruning=linucb_config.get('enable_action_pruning', True),
            pruning_check_interval=linucb_config.get('pruning_check_interval', 100),
            pruning_threshold=linucb_config.get('pruning_threshold', 1.0),
            min_exploration_for_pruning=linucb_config.get('min_exploration_for_pruning', 5),
            pruning_maturity_threshold=linucb_config.get('pruning_maturity_threshold', 100),
            cascade_pruning_threshold=linucb_config.get('cascade_pruning_threshold', 600),
            gpu_max_freq=self.gpu_controller.max_freq,  # ä¼ å…¥GPUç¡¬ä»¶æœ€å¤§é¢‘ç‡
            # æç«¯é¢‘ç‡å³æ—¶ä¿®å‰ªå‚æ•°
            enable_extreme_pruning=linucb_config.get('enable_extreme_pruning', True),
            extreme_pruning_threshold=linucb_config.get('extreme_pruning_threshold', -1.5),
            extreme_pruning_min_samples=linucb_config.get('extreme_pruning_min_samples', 3),
            extreme_pruning_max_rounds=linucb_config.get('extreme_pruning_max_rounds', 20),
            auto_load=not self.reset_model
        )
        
        # å¯ç”¨æ˜¾å­˜+æ ¸å¿ƒé¢‘ç‡ç»„åˆä¼˜åŒ–ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if (self.gpu_controller.enable_memory_frequency_control and 
            self.gpu_controller.memory_frequency_supported and 
            hasattr(self.gpu_controller, 'memory_frequencies')):
            
            memory_freqs = self.gpu_controller.memory_frequencies
            self.model.enable_memory_frequency_optimization(memory_freqs)
            
            # è®¾ç½®LinUCBæ¨¡å‹å›è°ƒï¼Œç”¨äºç²¾ç»†çš„é¢‘ç‡ç¦ç”¨ç®¡ç†
            self.gpu_controller.set_linucb_callback(self.model)
            
            self.logger.info(f"ğŸ”§ æ˜¾å­˜+æ ¸å¿ƒé¢‘ç‡ç»„åˆä¼˜åŒ–å·²å¯ç”¨")
            self.logger.info(f"   æ˜¾å­˜é¢‘ç‡: {memory_freqs}")
            total_combinations = len(self.gpu_controller.frequencies) * len(memory_freqs)
            self.logger.info(f"   æ€»åŠ¨ä½œç©ºé—´: {total_combinations} ä¸ªç»„åˆ")
            self.logger.info(f"   ç²¾ç»†ç¦ç”¨ç®¡ç†: å·²å¯ç”¨")
        else:
            self.logger.info(f"ğŸ”§ ä»…æ ¸å¿ƒé¢‘ç‡ä¼˜åŒ–æ¨¡å¼")
        
        # æ§åˆ¶å‚æ•°
        self.convergence_window = control_config.get('convergence_window', 100)
        self.performance_degradation_threshold = control_config.get('performance_degradation_threshold', 1.2)
        self.convergence_top_k = control_config.get('convergence_top_k', 3)
        self.convergence_threshold = control_config.get('convergence_threshold', 0.70)
        
        # ä¼‘æ¯æ¨¡å¼çŠ¶æ€
        self.idle_mode = False              # å½“å‰æ˜¯å¦å¤„äºä¼‘æ¯æ¨¡å¼
        self.idle_confirmation_count = 0    # è¿ç»­ç©ºé—²æ£€æµ‹è®¡æ•°
        self.last_idle_reset = False        # æ˜¯å¦å·²ç»æ‰§è¡Œè¿‡é¢‘ç‡é‡ç½®
        
        self.logger.info("ğŸ”§ ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–å®Œæˆ:")
        self.logger.info(f"   ç®—æ³•: Contextual LinUCB (é¢‘ç‡ä½œä¸ºåŠ¨ä½œ)")
        self.logger.info(f"   ç‰¹å¾ç»´åº¦: 7ç»´ (ä»…å·¥ä½œè´Ÿè½½ç‰¹å¾)")
        self.logger.info(f"   æ”¶æ•›çª—å£: {self.convergence_window}è½®")
        self.logger.info(f"   æ”¶æ•›ç­–ç•¥: å‰{self.convergence_top_k}ä¸ªåŠ¨ä½œè”åˆå æ¯” >= {self.convergence_threshold:.0%}")
        
        # æ˜¾ç¤ºå½“å‰æ¨¡å‹çŠ¶æ€
        initial_mode = "åˆ©ç”¨(å·²æ”¶æ•›)" if self.model.exploitation_mode else "å­¦ä¹ (æ¢ç´¢ä¸­)"
        self.logger.info(f"   åˆå§‹æ¨¡å¼: {initial_mode}")
        if hasattr(self.model, 'total_rounds') and self.model.total_rounds > 0:
            self.logger.info(f"   å·²è®­ç»ƒè½®æ¬¡: {self.model.total_rounds}")
            self.logger.info(f"   å·²çŸ¥é¢‘ç‡: {len(self.model.available_frequencies)}ä¸ª")
    
    def _signal_handler(self, signum, _frame):
        """ä¿¡å·å¤„ç†å™¨"""
        self.logger.info(f"ğŸ›‘ æ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
        self.running = False
    
    def _get_current_state(self) -> tuple[np.ndarray, list, dict]:
        """è·å–å½“å‰ç³»ç»ŸçŠ¶æ€"""
        # æ”¶é›†æŒ‡æ ‡ï¼ˆåŒ…å«èƒ½è€—æ•°æ®ï¼‰
        metrics = self.metrics_collector.collect_metrics(
            energy_reader=self.gpu_controller.read_energy_mj
        )
        if not metrics:
            raise RuntimeError("æ— æ³•æ”¶é›†vLLMæŒ‡æ ‡")
        
        # æå–ç‰¹å¾ (ä»…å·¥ä½œè´Ÿè½½ç‰¹å¾ï¼Œä¸åŒ…å«é¢‘ç‡)
        features = self.feature_extractor.extract_features(metrics)
        if features is None or len(features) != 7:
            raise RuntimeError(f"ç‰¹å¾æå–å¤±è´¥ï¼ŒæœŸæœ›7ç»´ï¼Œå®é™…{len(features) if features is not None else 0}ç»´")
        
        # è·å–å¯ç”¨é¢‘ç‡ï¼ˆæ’é™¤ä¿®å‰ªå’Œå¤±è´¥çš„é¢‘ç‡ï¼‰
        available_frequencies = self.gpu_controller.get_available_frequencies(self.model)
        if not available_frequencies:
            raise RuntimeError("æ— å¯ç”¨GPUé¢‘ç‡")
        
        return features, available_frequencies, metrics
    
    def _make_decision(self, features: np.ndarray, available_frequencies: list) -> int:
        """åšå‡ºé¢‘ç‡å†³ç­–"""
        # æ›´æ–°æ¨¡å‹çš„åŠ¨ä½œç©ºé—´
        self.model.update_action_space(available_frequencies)
        
        # é€‰æ‹©é¢‘ç‡ (é¢‘ç‡ä½œä¸ºåŠ¨ä½œï¼Œä¸ä½œä¸ºç‰¹å¾)
        if self.model.exploitation_mode:
            selected_freq = self.model.select_action_exploitation(features, available_frequencies)
        else:
            selected_freq = self.model.select_action(features, available_frequencies)
        
        return selected_freq
    
    def _execute_action_and_measure(self, action) -> tuple[float, dict, Optional[float]]:
        """æ‰§è¡ŒåŠ¨ä½œå¹¶æµ‹é‡å¥–åŠ±ï¼ˆæ”¯æŒæ ¸å¿ƒé¢‘ç‡æˆ–ç»„åˆé¢‘ç‡ï¼‰"""
        # è®¾ç½®GPUé¢‘ç‡ï¼ˆç»„åˆé¢‘ç‡æˆ–æ ¸å¿ƒé¢‘ç‡ï¼‰
        if self.model.memory_optimization_enabled and isinstance(action, tuple):
            # ç»„åˆé¢‘ç‡æ¨¡å¼ï¼šè®¾ç½®æ ¸å¿ƒé¢‘ç‡å’Œæ˜¾å­˜é¢‘ç‡
            core_freq, memory_freq = action
            success = self.gpu_controller.set_frequency(core_freq)
            if success and hasattr(self.gpu_controller, 'set_memory_frequency'):
                success = success and self.gpu_controller.set_memory_frequency(memory_freq)
            
            if not success:
                action_desc = f"{core_freq}MHzæ ¸å¿ƒ+{memory_freq}MHzæ˜¾å­˜"
                self.logger.error(f"âŒ è®¾ç½®ç»„åˆé¢‘ç‡ {action_desc} å¤±è´¥")
                return -1.0, {}, None  # æƒ©ç½šå¤±è´¥çš„é¢‘ç‡è®¾ç½®
        else:
            # æ ¸å¿ƒé¢‘ç‡æ¨¡å¼ï¼šåªè®¾ç½®æ ¸å¿ƒé¢‘ç‡
            if not self.gpu_controller.set_frequency(action):
                self.logger.error(f"âŒ è®¾ç½®GPUæ ¸å¿ƒé¢‘ç‡ {action}MHz å¤±è´¥")
                return -1.0, {}, None  # æƒ©ç½šå¤±è´¥çš„é¢‘ç‡è®¾ç½®
        
        # ç­‰å¾…å†³ç­–é—´éš”
        time.sleep(0.3)
        
        # æ”¶é›†æ‰§è¡Œåçš„æŒ‡æ ‡ï¼ˆåŒ…å«èƒ½è€—æ•°æ®ï¼‰
        post_metrics = self.metrics_collector.collect_metrics(
            energy_reader=self.gpu_controller.read_energy_mj
        )
        if not post_metrics:
            self.logger.warning("âš ï¸ æ— æ³•æ”¶é›†æ‰§è¡ŒåæŒ‡æ ‡")
            return -0.5, {}, None
        
        # ä»æŒ‡æ ‡ä¸­è·å–èƒ½è€—å¢é‡
        energy_delta = post_metrics.get('energy_delta_mj', 0.0)
        
        # è®¡ç®—å¥–åŠ±å’ŒEDPå€¼
        # ä»vLLMæŒ‡æ ‡ä¸­æå–è®¡æ•°å™¨å¢é‡
        counter_deltas = {}
        ttft_sum_key = "vllm:time_to_first_token_seconds_sum_delta"
        ttft_count_key = "vllm:time_to_first_token_seconds_count_delta"
        tpot_sum_key = "vllm:time_per_output_token_seconds_sum_delta"
        tpot_count_key = "vllm:time_per_output_token_seconds_count_delta"
        
        for key in [ttft_sum_key, ttft_count_key, tpot_sum_key, tpot_count_key]:
            if key in post_metrics:
                counter_deltas[key] = post_metrics[key]
        
        # è°ƒç”¨calculateæ–¹æ³•è·å–è¯¦ç»†ä¿¡æ¯
        reward, info = self.reward_calculator.calculate(
            counter_deltas=counter_deltas,
            energy_consumed_mj=energy_delta
        )
        
        # æå–EDPå€¼
        edp_value = info.get('edp', None)
        
        return reward, post_metrics, edp_value
    
    def _check_convergence(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¶æ•› - åŸºäºå‰å‡ ä¸ªæœ€ä¼˜åŠ¨ä½œçš„è”åˆç¨³å®šæ€§"""
        if self.model.total_rounds < self.convergence_window:
            return False
        
        # è·å–æœ€è¿‘çš„åŠ¨ä½œå†å²
        recent_actions = self.model.action_history[-self.convergence_window:]
        if len(recent_actions) < self.convergence_window:
            return False
        
        # ç»Ÿè®¡æ¯ä¸ªåŠ¨ä½œçš„é€‰æ‹©æ¬¡æ•°
        action_counts = Counter(recent_actions)
        
        # ä»é…ç½®ä¸­è·å–æ”¶æ•›å‚æ•°
        control_config = self.config.get('control', {})
        top_k = control_config.get('convergence_top_k', 3)  # è€ƒè™‘å‰kä¸ªæœ€ä¼˜åŠ¨ä½œ
        convergence_threshold = control_config.get('convergence_threshold', 0.70)  # æ”¶æ•›é˜ˆå€¼
        
        # è·å–è¢«é€‰æ‹©æ¬¡æ•°æœ€å¤šçš„å‰kä¸ªåŠ¨ä½œ
        most_common_actions = action_counts.most_common(top_k)
        
        if not most_common_actions:
            return False
        
        # è®¡ç®—å‰kä¸ªåŠ¨ä½œçš„æ€»å æ¯”
        top_k_total_count = sum(count for _, count in most_common_actions)
        top_k_combined_ratio = top_k_total_count / len(recent_actions)
        is_converged = top_k_combined_ratio >= convergence_threshold
        
        # è®°å½•æ”¶æ•›çŠ¶æ€å˜åŒ–
        if is_converged and not self.model.exploitation_mode:
            # æ„å»ºæ”¶æ•›ä¿¡æ¯å­—ç¬¦ä¸²
            top_actions_info = ", ".join([f"{action}MHz({count}æ¬¡,{count/len(recent_actions):.1%})" 
                                        for action, count in most_common_actions])
            
            self.logger.info(f"ğŸ¯ æ¨¡å‹æ”¶æ•›æ£€æµ‹: å‰{len(most_common_actions)}ä¸ªä¼˜åŠ¿åŠ¨ä½œè”åˆå æ¯”{top_k_combined_ratio:.1%} >= {convergence_threshold:.0%}")
            self.logger.info(f"ğŸ“Š ç¨³å®šçŠ¶æ€é›†: {top_actions_info}")
            self.logger.info(f"ğŸ”„ ä»å­¦ä¹ æ¨¡å¼åˆ‡æ¢åˆ°åˆ©ç”¨æ¨¡å¼")
            self.model.set_exploitation_mode(True)
            self.model.is_converged = True
            self.model.save_model("final_contextual_model.pkl")
            
            # è®°å½•æ”¶æ•›æ—¶çš„ç»Ÿè®¡ä¿¡æ¯
            self.logger.info(f"ğŸ“Š æ”¶æ•›ç»Ÿè®¡: æ€»è½®æ¬¡={self.model.total_rounds}, åŠ¨ä½œç©ºé—´={len(self.model.available_frequencies)}ä¸ªé¢‘ç‡")
            
        elif not is_converged and self.model.exploitation_mode:
            # å¦‚æœä¹‹å‰æ”¶æ•›ä½†ç°åœ¨ä¸ç¨³å®šäº†ï¼Œå¯èƒ½éœ€è¦é‡æ–°å­¦ä¹ 
            self.logger.warning(f"âš ï¸ æ”¶æ•›çŠ¶æ€ä¸ç¨³å®š: å‰{top_k}ä¸ªåŠ¨ä½œè”åˆå æ¯”é™è‡³{top_k_combined_ratio:.1%} < {convergence_threshold:.0%}")
        
        return is_converged
    
    def _check_performance_degradation(self) -> bool:
        """æ£€æŸ¥æ€§èƒ½æ˜¯å¦é€€åŒ– - åŸºäºåŸå§‹EDPå€¼"""
        if self.model.total_rounds < 100:
            return False
        
        # ä½¿ç”¨EDPå†å²è€Œä¸æ˜¯å¥–åŠ±å†å²
        edp_history = self.model.edp_history
        if len(edp_history) < 100:
            return False
        
        recent_50_edp = edp_history[-50:]
        previous_50_edp = edp_history[-100:-50]
        
        if not previous_50_edp or not recent_50_edp:
            return False
        
        recent_avg_edp = np.mean(recent_50_edp)
        previous_avg_edp = np.mean(previous_50_edp)
        
        # EDPè¶Šå°è¶Šå¥½ï¼Œæ‰€ä»¥å¦‚æœæœ€è¿‘çš„å¹³å‡EDPæ¯”ä¹‹å‰çš„é«˜å‡ºé…ç½®é˜ˆå€¼ï¼Œå°±è®¤ä¸ºæ€§èƒ½é€€åŒ–
        if previous_avg_edp > 0:
            edp_ratio = recent_avg_edp / previous_avg_edp
            # ä¿®æ­£é˜ˆå€¼é€»è¾‘ï¼šåªæœ‰å½“EDPæ¶åŒ–è¶…è¿‡é…ç½®çš„ç™¾åˆ†æ¯”æ—¶æ‰è§¦å‘
            degradation_threshold = 1.0 + self.performance_degradation_threshold  # 0.65 -> 1.65
            if edp_ratio > degradation_threshold:
                self.logger.warning(f"âš ï¸ æ€§èƒ½é€€åŒ–æ£€æµ‹: æœ€è¿‘50è½®EDPå¹³å‡å€¼({recent_avg_edp:.4f}) "
                                  f"æ¯”å‰50è½®({previous_avg_edp:.4f})æ¶åŒ–äº†{(edp_ratio-1)*100:.1f}% > {self.performance_degradation_threshold*100:.0f}%")
                self.logger.warning(f"ğŸ”„ æ€§èƒ½é€€åŒ–è§¦å‘æ¡ä»¶: EDPæ¶åŒ–æ¯”ä¾‹ {edp_ratio:.3f} > é˜ˆå€¼ {degradation_threshold:.3f}")
                return True
            else:
                # è®°å½•è½»å¾®æ¶åŒ–ä½†æœªè§¦å‘çš„æƒ…å†µ
                if edp_ratio > 1.05:  # æ¶åŒ–è¶…è¿‡5%æ—¶è®°å½•infoçº§åˆ«æ—¥å¿—
                    self.logger.info(f"ğŸ“Š è½»å¾®æ€§èƒ½å˜åŒ–: EDPæ¶åŒ–{(edp_ratio-1)*100:.1f}% (æœªè¾¾åˆ°{self.performance_degradation_threshold*100:.0f}%è§¦å‘é˜ˆå€¼)")
        
        return False
    
    def _check_idle_mode(self, metrics: dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è¿›å…¥/é€€å‡ºä¼‘æ¯æ¨¡å¼ - åŸºäºæ­£åœ¨è¿è¡Œçš„è¯·æ±‚æ•°"""
        # è·å–æ­£åœ¨è¿è¡Œçš„è¯·æ±‚æ•°
        running_requests = metrics.get('vllm:num_requests_running', 0)
        
        # ç©ºé—²æ£€æµ‹ï¼šæ²¡æœ‰æ­£åœ¨è¿è¡Œçš„è¯·æ±‚
        is_currently_idle = (running_requests == 0)
        
        if is_currently_idle:
            self.idle_confirmation_count += 1
            
            # è¿ç»­3æ¬¡æ£€æµ‹åˆ°ç©ºé—²æ‰è¿›å…¥ä¼‘æ¯æ¨¡å¼ï¼ˆé¿å…çŸ­æš‚ç©ºé—²çš„è¯¯åˆ¤ï¼‰
            if not self.idle_mode and self.idle_confirmation_count >= 3:
                self.idle_mode = True
                self.last_idle_reset = False  # é‡ç½®é¢‘ç‡é‡ç½®æ ‡å¿—
                self.logger.info("ğŸ˜´ æ£€æµ‹åˆ°æŒç»­ç©ºé—²ï¼ˆæ— è¿è¡Œä»»åŠ¡ï¼‰ï¼Œè¿›å…¥ä¼‘æ¯æ¨¡å¼")
                return True
        else:
            # æœ‰è¿è¡Œä»»åŠ¡æ—¶é‡ç½®è®¡æ•°å¹¶é€€å‡ºä¼‘æ¯æ¨¡å¼
            if self.idle_mode:
                self.idle_mode = False
                self.idle_confirmation_count = 0
                self.logger.info(f"ğŸƒ æ£€æµ‹åˆ°è¿è¡Œä»»åŠ¡({running_requests}ä¸ª)ï¼Œé€€å‡ºä¼‘æ¯æ¨¡å¼ï¼Œæ¢å¤å­¦ä¹ ")
            else:
                self.idle_confirmation_count = 0
        
        return self.idle_mode
    
    def _handle_idle_mode(self):
        """å¤„ç†ä¼‘æ¯æ¨¡å¼ï¼šé‡ç½®é¢‘ç‡åˆ°å®‰å…¨å€¼ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰"""
        if self.idle_mode and not self.last_idle_reset:
            # é‡ç½®GPUé¢‘ç‡åˆ°å®‰å…¨çš„ç©ºé—²é¢‘ç‡ï¼ˆ210MHzï¼‰
            idle_frequency = 210  # MHzï¼Œå®‰å…¨çš„ç©ºé—²é¢‘ç‡
            if self.gpu_controller.set_frequency(idle_frequency):
                self.logger.info(f"ğŸ”§ ä¼‘æ¯æ¨¡å¼ï¼šGPUé¢‘ç‡å·²é‡ç½®ä¸º {idle_frequency}MHz")
                self.last_idle_reset = True
            else:
                self.logger.warning(f"âš ï¸ ä¼‘æ¯æ¨¡å¼ï¼šGPUé¢‘ç‡é‡ç½®å¤±è´¥")
    
    def _log_round_details(self, round_num: int, features: np.ndarray, action, 
                          reward: float, edp_value: Optional[float], 
                          _pre_metrics: dict, post_metrics: dict):
        """è®°å½•æ¯ä¸€è½®çš„è¯¦ç»†ä¿¡æ¯åˆ°æ—¥å¿—æ–‡ä»¶"""
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—
        logging_config = self.config.get('logging', {})
        if not logging_config.get('detailed_round_logging', True):
            return
        
        # æå–å…³é”®æŒ‡æ ‡
        energy_delta = post_metrics.get('energy_delta_mj', 0.0)
        
        # vLLMæŒ‡æ ‡
        ttft_count = post_metrics.get('vllm:time_to_first_token_seconds_count_delta', 0)
        ttft_sum = post_metrics.get('vllm:time_to_first_token_seconds_sum_delta', 0.0)
        tpot_count = post_metrics.get('vllm:time_per_output_token_seconds_count_delta', 0)
        tpot_sum = post_metrics.get('vllm:time_per_output_token_seconds_sum_delta', 0.0)
        
        # è®¡ç®—å¹³å‡å€¼
        avg_ttft = ttft_sum / ttft_count if ttft_count > 0 else 0.0
        avg_tpot = tpot_sum / tpot_count if tpot_count > 0 else 0.0
        
        # GPUä½¿ç”¨ç‡å’Œå†…å­˜ç­‰å…¶ä»–æŒ‡æ ‡
        gpu_util = post_metrics.get('gpu_utilization', 0.0)
        gpu_memory = post_metrics.get('gpu_memory_used', 0.0)
        queue_size = post_metrics.get('vllm:num_requests_waiting', 0)
        
        # æ¨¡å‹çŠ¶æ€
        model_stats = self.model.get_model_stats()
        
        # è·å–åŠ¨ä½œé€‰æ‹©ç»Ÿè®¡ï¼ˆå‘åå…¼å®¹ï¼‰
        available_freqs = self.gpu_controller.get_available_frequencies(self.model)
        action_selection_count = getattr(self.model, 'arm_counts', {}).get(action, 0)
        
        # åŠ¨ä½œæè¿°ï¼ˆå‘åå…¼å®¹ï¼‰
        if self.model.memory_optimization_enabled and isinstance(action, tuple):
            action_desc = f"{action[0]}MHzæ ¸å¿ƒ+{action[1]}MHzæ˜¾å­˜"
            freq_for_compat = action[0]  # ç”¨äºå…¼å®¹æ€§çš„æ ¸å¿ƒé¢‘ç‡
        else:
            action_desc = f"{action}MHzæ ¸å¿ƒ"
            freq_for_compat = action
        
        # è·å–æ­£ç¡®çš„ç‰¹å¾åç§°
        feature_names = self.feature_extractor.feature_names
        
        # è®°å½•å®Œæ•´ä¿¡æ¯
        self.logger.info(
            f"ğŸ” è½®æ¬¡ {round_num} è¯¦ç»†è®°å½•:\n"
            f"ğŸ“Š å†³ç­–ä¿¡æ¯:\n"
            f"   é€‰æ‹©åŠ¨ä½œ: {action_desc} (é€‰æ‹©æ¬¡æ•°: {action_selection_count})\n"
            f"   å¯ç”¨é¢‘ç‡: {len(available_freqs)}ä¸ª [{min(available_freqs)}-{max(available_freqs)}MHz]\n"
            f"   æ¨¡å¼: {'åˆ©ç”¨' if self.model.exploitation_mode else 'å­¦ä¹ '}\n"
            f"ğŸ¯ ç‰¹å¾å‘é‡ (7ç»´):\n"
            f"   [0]{feature_names[0]}: {features[0]:.3f}\n"
            f"   [1]{feature_names[1]}: {features[1]:.3f}\n"
            f"   [2]{feature_names[2]}: {features[2]:.3f}\n"
            f"   [3]{feature_names[3]}: {features[3]:.3f}\n"
            f"   [4]{feature_names[4]}: {features[4]:.3f}\n"
            f"   [5]{feature_names[5]}: {features[5]:.3f}\n"
            f"   [6]{feature_names[6]}: {features[6]:.3f}\n"
            f"âš¡ æ€§èƒ½æŒ‡æ ‡:\n"
            f"   TTFT: {avg_ttft:.4f}s (è®¡æ•°: {ttft_count})\n"
            f"   TPOT: {avg_tpot:.4f}s (è®¡æ•°: {tpot_count})\n"
            f"   èƒ½è€—å¢é‡: {energy_delta:.2f}mJ ({energy_delta/1000:.5f}J)\n"
            f"   EDPå€¼: {f'{edp_value:.6f}' if edp_value is not None else 'N/A'}\n"
            f"ğŸ’° å¥–åŠ±ä¿¡æ¯:\n"
            f"   å½“å‰å¥–åŠ±: {reward:+.4f}\n"
            f"   å¹³å‡å¥–åŠ±: {model_stats.get('avg_reward', 0.0):.4f}\n"
            f"   æœ€è¿‘å¹³å‡: {model_stats.get('recent_avg_reward', 0.0):.4f}\n"
            f"ğŸ–¥ï¸ ç³»ç»ŸçŠ¶æ€:\n"
            f"   GPUåˆ©ç”¨ç‡: {gpu_util:.1f}%\n"
            f"   GPUå†…å­˜: {gpu_memory:.1f}MB\n"
            f"   ç­‰å¾…é˜Ÿåˆ—: {queue_size}ä¸ªè¯·æ±‚\n"
            f"ğŸ“ˆ æ¨¡å‹ç»Ÿè®¡:\n"
            f"   æ€»è½®æ¬¡: {model_stats.get('total_rounds', 0)}\n"
            f"   åŠ¨ä½œç©ºé—´: {model_stats.get('n_arms', 0)}ä¸ªé¢‘ç‡\n"
            f"   æ¢ç´¢/åˆ©ç”¨: {'æ”¶æ•›' if model_stats.get('converged', False) else 'å­¦ä¹ ä¸­'}\n"
            f"{'='*80}"
        )
        
        # åŒæ—¶è®°å½•JSONæ ¼å¼çš„ç»“æ„åŒ–æ•°æ®ï¼Œä¾¿äºåç»­åˆ†æ
        round_data = {
            'timestamp': datetime.now().isoformat(),
            'round': round_num,
            'decision': {
                'selected_action': action_desc,
                'selected_frequency_compat': freq_for_compat,  # å‘åå…¼å®¹
                'selection_count': action_selection_count,
                'available_frequencies': available_freqs,
                'mode': 'exploitation' if self.model.exploitation_mode else 'exploration'
            },
            'features': {
                feature_names[0]: float(features[0]),
                feature_names[1]: float(features[1]),
                feature_names[2]: float(features[2]),
                feature_names[3]: float(features[3]),
                feature_names[4]: float(features[4]),
                feature_names[5]: float(features[5]),
                feature_names[6]: float(features[6])
            },
            'performance': {
                'avg_ttft': avg_ttft,
                'avg_tpot': avg_tpot,
                'ttft_count': ttft_count,
                'tpot_count': tpot_count,
                'energy_delta_mj': energy_delta,
                'energy_delta_j': energy_delta / 1000,
                'edp_value': edp_value
            },
            'reward': {
                'current': reward,
                'average': model_stats.get('avg_reward', 0.0),
                'recent_average': model_stats.get('recent_avg_reward', 0.0)
            },
            'system': {
                'gpu_utilization': gpu_util,
                'gpu_memory_mb': gpu_memory,
                'queue_size': queue_size
            },
            'model': {
                'total_rounds': model_stats.get('total_rounds', 0),
                'n_arms': model_stats.get('n_arms', 0),
                'converged': model_stats.get('converged', False),
                'exploitation_mode': self.model.exploitation_mode
            }
        }
        
        # è®°å½•JSONæ ¼å¼æ•°æ®
        self.logger.info(f"ğŸ“‹ JSONæ•°æ®: {json.dumps(round_data, ensure_ascii=False)}")
    
    def _update_adaptive_sampler(self, action, reward: float, post_metrics: dict):
        """æ›´æ–°è‡ªé€‚åº”é‡‡æ ·å™¨çš„åé¦ˆä¿¡æ¯ - ä»…åœ¨å­¦ä¹ æ¨¡å¼ä¸‹æ‰§è¡Œï¼Œæ”¯æŒç»„åˆé¢‘ç‡"""
        # æå–æ ¸å¿ƒé¢‘ç‡ç”¨äºæ—¥å¿—æ˜¾ç¤º
        core_freq = action[0] if isinstance(action, tuple) else action
        action_desc = f"{action[0]}MHzæ ¸å¿ƒ+{action[1]}MHzæ˜¾å­˜" if isinstance(action, tuple) else f"{action}MHzæ ¸å¿ƒ"
        self.logger.debug(f"ğŸ”„ æ›´æ–°è‡ªé€‚åº”é‡‡æ ·å™¨: è½®æ¬¡{getattr(self.model, 'total_rounds', 'N/A')}, {action_desc}")
        
        if not post_metrics:
            self.logger.warning("âš ï¸ post_metricsä¸ºç©ºï¼Œè·³è¿‡è‡ªé€‚åº”é‡‡æ ·å™¨æ›´æ–°")
            return
        
        # âœ… å…³é”®æ”¹è¿›ï¼šä»…åœ¨å­¦ä¹ æ¨¡å¼ä¸‹æ‰§è¡Œè‡ªé€‚åº”é‡‡æ ·
        if self.model.exploitation_mode:
            # åˆ©ç”¨æ¨¡å¼ä¸‹ä¸è¿›è¡Œé¢‘ç‡ç©ºé—´æ¢ç´¢ï¼Œä½†æ£€æŸ¥æ˜¯å¦æœ‰ä¸¥é‡SLOè¿è§„
            control_config = self.config.get('control', {})
            ignore_slo = control_config.get('ignore_slo', True)
            
            if not ignore_slo:
                # åœ¨åˆ©ç”¨æ¨¡å¼ä¸‹ä¹Ÿéœ€è¦æ­£ç¡®å¤„ç†ç»„åˆé¢‘ç‡çš„SLOæ£€æŸ¥
                check_freq = action[0] if isinstance(action, tuple) else action
                slo_violated = self.reward_calculator.check_slo_violation(post_metrics, check_freq)
                if slo_violated:
                    self.logger.warning("âš ï¸ åˆ©ç”¨æ¨¡å¼ä¸‹æ£€æµ‹åˆ°SLOè¿è§„ï¼Œå¯èƒ½ç¯å¢ƒå‘ç”Ÿé‡å¤§å˜åŒ–")
                    self.logger.info("ğŸ”„ ä»åˆ©ç”¨æ¨¡å¼åˆ‡æ¢å›å­¦ä¹ æ¨¡å¼ä»¥é‡æ–°é€‚åº”ç¯å¢ƒ")
                    self.model.set_exploitation_mode(False)
                    self.model.is_converged = False
                    # ç»§ç»­æ‰§è¡Œä¸‹é¢çš„è‡ªé€‚åº”é‡‡æ ·é€»è¾‘
                else:
                    self.logger.debug("ğŸ”’ åˆ©ç”¨æ¨¡å¼ä¸‹è·³è¿‡è‡ªé€‚åº”é‡‡æ ·å™¨æ›´æ–°ï¼ˆå·²æ”¶æ•›ï¼Œæ€§èƒ½æ­£å¸¸ï¼‰")
                    return
            else:
                self.logger.debug("ğŸ”’ åˆ©ç”¨æ¨¡å¼ä¸‹è·³è¿‡è‡ªé€‚åº”é‡‡æ ·å™¨æ›´æ–°ï¼ˆå·²æ”¶æ•›ï¼Œä¸å†æ¢ç´¢ï¼‰")
                return
            
        # 1. æ›´æ–°é¢‘ç‡å¥–åŠ±åé¦ˆï¼ˆä¼ é€’LinUCBæ¨¡å‹å’Œå½“å‰ä¸Šä¸‹æ–‡ç”¨äºæ™ºèƒ½ç»†åŒ–ï¼‰
        # è·å–å½“å‰ä¸Šä¸‹æ–‡ç‰¹å¾
        try:
            current_features, _, _ = self._get_current_state()
        except:
            current_features = None
        
        frequency_space_updated = self.gpu_controller.update_frequency_reward(
            core_freq, reward, 
            linucb_model=self.model, 
            current_context=current_features
        )
        
        # 2. æ£€æŸ¥SLOè¿è§„ï¼ˆåªåœ¨éignore_sloæ¨¡å¼ä¸‹ï¼‰
        control_config = self.config.get('control', {})
        ignore_slo = control_config.get('ignore_slo', True)
        
        if not ignore_slo:
            # æ£€æŸ¥SLOè¿è§„æ—¶éœ€è¦ä¼ é€’å®Œæ•´çš„åŠ¨ä½œä¿¡æ¯ï¼ˆæ”¯æŒç»„åˆé¢‘ç‡ï¼‰
            check_freq = action[0] if isinstance(action, tuple) else action
            slo_violated = self.reward_calculator.check_slo_violation(post_metrics, check_freq)
            if slo_violated:
                # ä¼ é€’å®Œæ•´çš„åŠ¨ä½œç»™SLOè¿è§„å¤„ç†å™¨
                slo_space_updated = self.gpu_controller.update_slo_violation(action)
                if slo_space_updated:
                    frequency_space_updated = True
        
        # 3. å¦‚æœé¢‘ç‡ç©ºé—´å‘ç”Ÿäº†æ›´æ–°ï¼Œé‡æ–°è®¾ç½®æ¨¡å‹çš„åŠ¨ä½œç©ºé—´
        if frequency_space_updated:
            new_frequencies = self.gpu_controller.get_available_frequencies(self.model)
            self.model.update_action_space(new_frequencies)
            
            # å¦‚æœå¯ç”¨äº†æ˜¾å­˜é¢‘ç‡ä¼˜åŒ–ï¼Œä¹Ÿéœ€è¦åŒæ­¥æ˜¾å­˜é¢‘ç‡åˆ—è¡¨
            if (self.model.memory_optimization_enabled and 
                self.gpu_controller.enable_memory_frequency_control and 
                self.gpu_controller.memory_frequency_supported):
                
                new_memory_frequencies = self.gpu_controller.get_available_memory_frequencies()
                if hasattr(self.model, 'update_memory_frequencies'):
                    self.model.update_memory_frequencies(new_memory_frequencies)
                else:
                    # ç›´æ¥æ›´æ–°æ˜¾å­˜é¢‘ç‡åˆ—è¡¨
                    self.model.available_memory_frequencies = new_memory_frequencies
                    self.logger.info(f"ğŸ’¾ åŒæ­¥æ˜¾å­˜é¢‘ç‡åˆ—è¡¨: {len(new_memory_frequencies)}ä¸ªé¢‘ç‡")
            
            self.logger.info(f"ğŸ¯ å­¦ä¹ æ¨¡å¼ä¸‹è‡ªé€‚åº”é‡‡æ ·å™¨è§¦å‘é¢‘ç‡ç©ºé—´æ›´æ–°: {len(new_frequencies)}ä¸ªé¢‘ç‡")
            self.logger.info("ğŸ“Š å‘ç°æ–°çš„é¢‘ç‡åŒºåŸŸï¼Œç»§ç»­æ¢ç´¢å­¦ä¹ ")
    
    
    def run(self):
        """è¿è¡Œä¸»æ§åˆ¶å¾ªç¯"""
        self.logger.info("ğŸ® å¼€å§‹ä¸»æ§åˆ¶å¾ªç¯...")
        self.running = True
        
        
        # è¿è¡Œç»Ÿè®¡  
        start_time = time.time()
        self.logger.info(f"ğŸš€ å¼€å§‹æ—¶é—´: {datetime.fromtimestamp(start_time).strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            while self.running:
                try:
                    # è·å–å½“å‰çŠ¶æ€
                    features, available_frequencies, metrics = self._get_current_state()
                    
                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥è¿›å…¥ä¼‘æ¯æ¨¡å¼
                    is_idle = self._check_idle_mode(metrics)
                    
                    if is_idle:
                        # è¿›å…¥ä¼‘æ¯æ¨¡å¼ï¼šé‡ç½®é¢‘ç‡ï¼Œç­‰å¾…ï¼Œä¸å¢åŠ å†³ç­–è½®æ¬¡
                        self._handle_idle_mode()
                        time.sleep(2)  # ä¼‘æ¯æ¨¡å¼ä¸‹ç­‰å¾…2ç§’
                        continue  # è·³è¿‡å­¦ä¹ ï¼Œä¸å¢åŠ è½®æ¬¡
                    
                    # æ­£å¸¸å­¦ä¹ æ¨¡å¼ï¼šåšå‡ºå†³ç­–
                    selected_action = self._make_decision(features, available_frequencies)
                    
                    # æ‰§è¡ŒåŠ¨ä½œå¹¶æµ‹é‡å¥–åŠ±
                    reward, post_metrics, edp_value = self._execute_action_and_measure(selected_action)
                    
                    # æ›´æ–°æ¨¡å‹ï¼ˆåªæœ‰åœ¨éä¼‘æ¯æ¨¡å¼ä¸‹æ‰æ›´æ–°ï¼‰
                    self.model.update(features, selected_action, reward, edp_value)
                    
                    # æ˜¾ç¤ºå½“å‰è½®æ¬¡
                    current_round = getattr(self.model, 'total_rounds', 0) or 0
                    print(f"ğŸ¯ å½“å‰å†³ç­–è½®æ¬¡: {current_round}")
                    
                    # è®°å½•è¯¦ç»†çš„æ¯è½®ä¿¡æ¯
                    self._log_round_details(self.model.total_rounds, features, selected_action, 
                                          reward, edp_value, metrics, post_metrics)
                    
                    # é›†æˆè‡ªé€‚åº”é‡‡æ ·å™¨åé¦ˆ (ä»…å­¦ä¹ æ¨¡å¼)
                    # ä¿®å¤ï¼šä¼ é€’å®Œæ•´çš„åŠ¨ä½œä¿¡æ¯æ”¯æŒç»„åˆé¢‘ç‡SLOå¤„ç†
                    self._update_adaptive_sampler(selected_action, reward, post_metrics)
                    
                    # æ‰§è¡Œæ™ºèƒ½åŠ¨ä½œä¿®å‰ªæ£€æŸ¥ï¼ˆå¦‚æœå¯ç”¨ä¸”å­¦ä¹ å™¨å·²æˆç†Ÿï¼‰
                    if hasattr(self.model, '_perform_action_pruning'):
                        # è®°å½•ä¿®å‰ªå‰çš„çŠ¶æ€
                        pruned_before = len(getattr(self.model, 'pruned_frequencies', set()))
                        
                        # æ‰§è¡Œä¿®å‰ªï¼ˆå†…éƒ¨ä¼šæ£€æŸ¥æ¡ä»¶ï¼‰
                        self.model._perform_action_pruning()
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„ä¿®å‰ªå‘ç”Ÿ
                        pruned_after = len(getattr(self.model, 'pruned_frequencies', set()))
                        if pruned_after > pruned_before:
                            # æœ‰æ–°ä¿®å‰ªå‘ç”Ÿï¼Œéœ€è¦åŒæ­¥å¯ç”¨é¢‘ç‡åˆ—è¡¨
                            self.logger.debug(f"ğŸ”„ æ£€æµ‹åˆ°æ–°ä¿®å‰ª({pruned_after - pruned_before}ä¸ª)ï¼ŒåŒæ­¥é¢‘ç‡åˆ—è¡¨")
                            # ä½¿ç”¨ç»Ÿä¸€æ–¹æ³•è·å–æœ€æ–°çš„å¯ç”¨é¢‘ç‡
                            if hasattr(self.gpu_controller, 'adaptive_sampler'):
                                updated_frequencies = self.gpu_controller.adaptive_sampler.get_available_frequencies_unified(
                                    linucb_model=self.model,
                                    gpu_controller=self.gpu_controller
                                )
                                # æ›´æ–°æ¨¡å‹çš„åŠ¨ä½œç©ºé—´
                                self.model.update_action_space(updated_frequencies)
                        
                        # æ¯20è½®æ˜¾ç¤ºä¸€æ¬¡ä¿®å‰ªçŠ¶æ€
                        if self.model.total_rounds % 20 == 0:
                            pruning_stats = self.model.get_model_stats()
                            self.logger.info(f"ğŸ“Š æ™ºèƒ½ä¿®å‰ªçŠ¶æ€ - è½®æ¬¡{self.model.total_rounds}: "
                                           f"å·²ä¿®å‰ª{pruning_stats.get('pruned_frequencies_count', 0)}ä¸ªé¢‘ç‡, "
                                           f"æ´»è·ƒé¢‘ç‡{pruning_stats.get('active_frequencies_count', 0)}ä¸ª")
                    
                    # å®šæœŸä¿å­˜æ¨¡å‹
                    if self.model.total_rounds % 50 == 0:
                        self.model.save_model()
                        
                        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
                        stats = self.model.get_model_stats()
                        mode_str = "åˆ©ç”¨(å·²æ”¶æ•›)" if self.model.exploitation_mode else "å­¦ä¹ (æ¢ç´¢ä¸­)"
                        self.logger.info(f"ğŸ“Š è½®æ¬¡ {self.model.total_rounds}: "
                                       f"å¥–åŠ±={reward:.3f}, "
                                       f"å¹³å‡å¥–åŠ±={stats['avg_reward']:.3f}, "
                                       f"æ¨¡å¼={mode_str}, "
                                       f"é¢‘ç‡ç©ºé—´={stats.get('n_arms', 0)}ä¸ª")
                    
                    # æ£€æŸ¥æ”¶æ•› (å­¦ä¹ â†’åˆ©ç”¨æ¨¡å¼åˆ‡æ¢)
                    self._check_convergence()
                    
                    # æ£€æŸ¥æ€§èƒ½é€€åŒ– (åˆ©ç”¨â†’å­¦ä¹ æ¨¡å¼åˆ‡æ¢)
                    if self.model.exploitation_mode and self._check_performance_degradation():
                        self.logger.warning("ğŸ”„ æ£€æµ‹åˆ°æ€§èƒ½é€€åŒ–ï¼Œä»åˆ©ç”¨æ¨¡å¼åˆ‡æ¢å›å­¦ä¹ æ¨¡å¼")
                        self.model.set_exploitation_mode(False)
                        self.model.is_converged = False
                        self.logger.info("ğŸ“Š é‡æ–°è¿›å…¥å­¦ä¹ é˜¶æ®µï¼Œå°†é‡æ–°æ¢ç´¢é¢‘ç‡ç©ºé—´")
                    
                except Exception as e:
                    self.logger.error(f"âŒ æ§åˆ¶å¾ªç¯å¼‚å¸¸: {e}")
                    time.sleep(5)  # é”™è¯¯åç­‰å¾…5ç§’
                    
        except KeyboardInterrupt:
            self.logger.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        
        finally:
            self._cleanup()
    
    def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†èµ„æº...")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        if hasattr(self, 'model'):
            self.model.save_model()
            
            # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
            stats = self.model.get_model_stats()
            self.logger.info("ğŸ“ˆ æœ€ç»ˆç»Ÿè®¡:")
            self.logger.info(f"   æ€»è½®æ¬¡: {stats['total_rounds']}")
            self.logger.info(f"   å¹³å‡å¥–åŠ±: {stats['avg_reward']:.3f}")
            self.logger.info(f"   æœ€è¿‘å¹³å‡å¥–åŠ±: {stats['recent_avg_reward']:.3f}")
            self.logger.info(f"   é¢‘ç‡æ•°é‡: {stats['n_arms']}")
        
        # é‡ç½®GPUé¢‘ç‡åˆ°å®‰å…¨å€¼
        if hasattr(self, 'gpu_controller'):
            self.gpu_controller.reset_gpu_clocks()
        
        self.logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")
        self.logger.info("ğŸ‘‹ vLLM GPUè‡ªåŠ¨è°ƒé¢‘å™¨å·²é€€å‡º")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="vLLM GPUè‡ªåŠ¨è°ƒé¢‘å™¨ - Contextual LinUCBç‰ˆæœ¬")
    parser.add_argument("--config", default="config/config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--reset-model", action="store_true", help="é‡ç½®æ¨¡å‹ï¼Œä»é›¶å¼€å§‹")
    parser.add_argument("--log-level", default="INFO", choices=["DEBUG", "INFO", "WARNING", "ERROR"])
    
    args = parser.parse_args()
    
    print("ğŸš€ å¯åŠ¨vLLM GPUè‡ªåŠ¨è°ƒé¢‘å™¨ (Contextual LinUCB)")
    print(f"ğŸ“ é…ç½®æ–‡ä»¶: {args.config}")
    print(f"ğŸ”„ é‡ç½®æ¨¡å‹: {'æ˜¯' if args.reset_model else 'å¦'}")
    print(f"ğŸ“Š æ—¥å¿—çº§åˆ«: {args.log_level}")
    print("=" * 60)
    
    try:
        # åˆ›å»ºå¹¶è¿è¡Œè‡ªåŠ¨è°ƒé¢‘å™¨
        autoscaler = VLLMGPUAutoscaler(
            config_path=args.config,
            reset_model=args.reset_model
        )
        autoscaler.run()
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()