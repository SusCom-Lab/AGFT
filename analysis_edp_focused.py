#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
vLLM GPU Autoscaler EDPä¸“é¡¹åˆ†æå·¥å…·
EDP-Focused Analysis Tool - ä¸“æ³¨äºé•¿æœŸåŸå§‹EDPå˜åŒ–è¶‹åŠ¿åˆ†æ
"""

import os
import re
import json
import pandas as pd
import numpy as np
from datetime import datetime
from glob import glob
from typing import Dict, List, Tuple, Optional, Any
import warnings
warnings.filterwarnings('ignore')

# Set matplotlib environment
os.environ['MPLCONFIGDIR'] = '/tmp/matplotlib_cache'
os.makedirs('/tmp/matplotlib_cache', exist_ok=True)

import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter, defaultdict

# é…ç½®matplotlibæ”¯æŒä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.figsize'] = (15, 10)
plt.rcParams['figure.dpi'] = 100

class EDPAnalyzer:
    """EDPä¸“é¡¹åˆ†æå™¨ - ä¸“æ³¨äºåŸå§‹EDPå€¼çš„é•¿æœŸå˜åŒ–è¶‹åŠ¿"""
    
    def __init__(self, log_pattern: str = "logs/**/*.log", max_rounds: Optional[int] = None):
        self.log_pattern = log_pattern
        self.max_rounds = max_rounds
        self.data = []
        self.idle_periods = []
        self.alpha_history = []
        self.pruning_history = []
        print("ğŸ” vLLM GPUè°ƒé¢‘å™¨EDPä¸“é¡¹åˆ†æå™¨å·²åˆå§‹åŒ–")
        print(f"ğŸ“‚ æ—¥å¿—æ¨¡å¼: {log_pattern}")
        if max_rounds:
            print(f"ğŸ”¢ åˆ†æèŒƒå›´: å‰{max_rounds}è½®æ•°æ®")
    
    def find_latest_log(self) -> str:
        """æŸ¥æ‰¾æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶"""
        log_files = glob(self.log_pattern, recursive=True)
        if not log_files:
            print(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„æ—¥å¿—æ–‡ä»¶: {self.log_pattern}")
            return None
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        latest_log = max(log_files, key=lambda x: os.path.getmtime(x))
        mtime = datetime.fromtimestamp(os.path.getmtime(latest_log))
        size_mb = os.path.getsize(latest_log) / (1024 * 1024)
        
        print(f"ğŸ“„ æ‰¾åˆ°æœ€æ–°æ—¥å¿—æ–‡ä»¶:")
        print(f"   {latest_log} ({size_mb:.1f}MB, {mtime.strftime('%Y-%m-%d %H:%M:%S')})")
        
        return latest_log
    
    def parse_log_file(self, log_file: str):
        """è§£ææ—¥å¿—æ–‡ä»¶ï¼Œä¸“æ³¨æå–EDPç›¸å…³æ•°æ®"""
        print(f"ğŸ“– è§£ææ—¥å¿—æ–‡ä»¶: {log_file}")
        
        json_count = 0
        idle_count = 0
        alpha_count = 0
        pruning_count = 0
        
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    
                    # è§£æJSONæ ¼å¼çš„å†³ç­–æ•°æ®
                    if 'ğŸ“‹ JSONæ•°æ®:' in line:
                        try:
                            json_str = line.split('ğŸ“‹ JSONæ•°æ®: ', 1)[1]
                            data = json.loads(json_str)
                            data['log_file'] = log_file
                            data['line_num'] = line_num
                            
                            # ç¡®ä¿EDPå€¼å­˜åœ¨ä¸”æœ‰æ•ˆ
                            edp_val = data.get('performance', {}).get('edp_value')
                            if edp_val is not None and edp_val > 0:
                                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§è½®æ¬¡é™åˆ¶
                                round_num = data.get('round', 0)
                                if self.max_rounds is None or round_num <= self.max_rounds:
                                    self.data.append(data)
                                    json_count += 1
                        except json.JSONDecodeError:
                            pass
                    
                    # è§£æä¼‘æ¯æ¨¡å¼ä¿¡æ¯
                    elif 'ğŸ˜´ æ£€æµ‹åˆ°æŒç»­ç©ºé—²' in line or 'ğŸƒ æ£€æµ‹åˆ°è¿è¡Œä»»åŠ¡' in line:
                        timestamp_match = re.match(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})', line)
                        if timestamp_match:
                            timestamp = timestamp_match.group(1)
                            event_type = 'enter_idle' if 'ğŸ˜´' in line else 'exit_idle'
                            self.idle_periods.append({
                                'timestamp': timestamp,
                                'event': event_type,
                                'line': line
                            })
                            idle_count += 1
                    
                    # è§£æalphaè¡°å‡ä¿¡æ¯
                    elif 'å½“å‰Î±=' in line:
                        try:
                            alpha_match = re.search(r'å½“å‰Î±=(\d+\.\d+)', line)
                            if alpha_match:
                                current_alpha = float(alpha_match.group(1))
                                self.alpha_history.append({
                                    'alpha': current_alpha,
                                    'line': line
                                })
                                alpha_count += 1
                        except ValueError:
                            pass
                    
                    # è§£ææ™ºèƒ½ä¿®å‰ªä¿¡æ¯
                    elif 'ğŸ—‚ï¸ [æ™ºèƒ½ä¿®å‰ª]' in line:
                        self.pruning_history.append({
                            'line': line
                        })
                        pruning_count += 1
        
        except Exception as e:
            print(f"âŒ æ–‡ä»¶è¯»å–é”™è¯¯: {e}")
            return
        
        max_rounds_info = f" (é™åˆ¶å‰{self.max_rounds}è½®)" if self.max_rounds else ""
        print(f"   âœ… è§£æå®Œæˆ: {json_count}æ¡æœ‰æ•ˆEDPæ•°æ®{max_rounds_info}, {idle_count}æ¡ä¼‘æ¯è®°å½•, {alpha_count}æ¡Î±è®°å½•, {pruning_count}æ¡ä¿®å‰ªè®°å½•")
    
    def analyze_edp_trends(self):
        """åˆ†æEDPè¶‹åŠ¿"""
        if not self.data:
            print("âŒ æ²¡æœ‰æ•°æ®å¯åˆ†æ")
            return None
        
        # æå–EDPæ•°æ®
        edp_data = []
        for d in self.data:
            round_num = d['round']
            edp_value = d['performance']['edp_value']
            frequency = d['decision']['selected_frequency_compat']
            energy = d['performance']['energy_delta_j']
            avg_ttft = d['performance']['avg_ttft']
            avg_tpot = d['performance']['avg_tpot']
            reward = d['reward']['current']
            
            edp_data.append({
                'round': round_num,
                'edp': edp_value,
                'frequency': frequency,
                'energy': energy,
                'ttft': avg_ttft,
                'tpot': avg_tpot,
                'delay': avg_ttft + avg_tpot,  # æ€»å»¶è¿Ÿ
                'reward': reward
            })
        
        df = pd.DataFrame(edp_data)
        
        # è®¡ç®—EDPè¶‹åŠ¿ç»Ÿè®¡
        analysis_result = {
            'total_rounds': len(df),
            'edp_stats': {
                'min_edp': df['edp'].min(),
                'max_edp': df['edp'].max(),
                'mean_edp': df['edp'].mean(),
                'std_edp': df['edp'].std(),
                'median_edp': df['edp'].median(),
                'p25_edp': df['edp'].quantile(0.25),
                'p75_edp': df['edp'].quantile(0.75)
            },
            'trend_analysis': self._analyze_edp_trend(df),
            'frequency_performance': self._analyze_frequency_performance(df),
            'data': df,
            'improvement_analysis': self._calculate_improvement(df)
        }
        
        return analysis_result
    
    def _analyze_edp_trend(self, df):
        """åˆ†æEDPè¶‹åŠ¿å˜åŒ–"""
        if len(df) < 10:
            return {'trend': 'insufficient_data'}
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡
        window_sizes = [10, 20, 50]
        trends = {}
        
        for window in window_sizes:
            if len(df) >= window:
                ma = df['edp'].rolling(window=window, center=True).mean()
                # è®¡ç®—è¶‹åŠ¿æ–œç‡ï¼ˆæœ€åéƒ¨åˆ†vså¼€å§‹éƒ¨åˆ†ï¼‰
                start_avg = ma.iloc[:window].mean()
                end_avg = ma.iloc[-window:].mean()
                
                if start_avg > 0:
                    improvement_pct = (start_avg - end_avg) / start_avg * 100
                    trends[f'ma_{window}'] = {
                        'improvement_percent': improvement_pct,
                        'start_avg': start_avg,
                        'end_avg': end_avg,
                        'trend': 'improving' if improvement_pct > 5 else 'stable' if abs(improvement_pct) <= 5 else 'degrading'
                    }
        
        return trends
    
    def _analyze_frequency_performance(self, df):
        """åˆ†æä¸åŒé¢‘ç‡çš„EDPè¡¨ç°"""
        freq_performance = df.groupby('frequency').agg({
            'edp': ['count', 'mean', 'std', 'min'],
            'energy': 'mean',
            'delay': 'mean',
            'reward': 'mean'
        }).round(4)
        
        # å±•å¹³åˆ—å
        freq_performance.columns = ['_'.join(col).strip() for col in freq_performance.columns]
        freq_performance = freq_performance.reset_index()
        
        # æŒ‰å¹³å‡EDPæ’åºï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        freq_performance = freq_performance.sort_values('edp_mean')
        
        return freq_performance
    
    def _calculate_improvement(self, df):
        """è®¡ç®—æ•´ä½“æ”¹è¿›æ•ˆæœ"""
        if len(df) < 20:
            return {'status': 'insufficient_data'}
        
        # åˆ†å‰²å‰åæœŸæ•°æ®
        split_point = len(df) // 2
        early_period = df.iloc[:split_point]
        late_period = df.iloc[split_point:]
        
        early_edp = early_period['edp'].mean()
        late_edp = late_period['edp'].mean()
        
        if early_edp > 0:
            improvement_pct = (early_edp - late_edp) / early_edp * 100
            
            return {
                'early_avg_edp': early_edp,
                'late_avg_edp': late_edp,
                'improvement_percent': improvement_pct,
                'status': 'improving' if improvement_pct > 5 else 'stable' if abs(improvement_pct) <= 5 else 'degrading',
                'early_rounds': len(early_period),
                'late_rounds': len(late_period)
            }
        
        return {'status': 'calculation_error'}
    
    def create_edp_visualizations(self, analysis_result: dict):
        """ç”ŸæˆEDPä¸“é¡¹å¯è§†åŒ–å›¾è¡¨ - å›¾è¡¨æ ‡ç­¾çº¯è‹±æ–‡"""
        if not analysis_result:
            return
        
        df = analysis_result['data']
        
        # åˆ›å»ºç»¼åˆå›¾è¡¨
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        title_suffix = f" (First {self.max_rounds} Rounds)" if self.max_rounds else ""
        fig.suptitle(f'vLLM GPU Auto-Scaler: Long-term EDP Analysis{title_suffix}', fontsize=16, fontweight='bold')
        
        # 1. åŸå§‹EDPå˜åŒ–è¶‹åŠ¿
        rounds = df['round'].values
        edp_values = df['edp'].values
        
        axes[0, 0].plot(rounds, edp_values, 'b-', alpha=0.6, linewidth=1, label='Raw EDP')
        
        # æ·»åŠ ç§»åŠ¨å¹³å‡çº¿
        for window in [10, 20, 50]:
            if len(df) >= window:
                ma = df['edp'].rolling(window=window, center=True).mean()
                axes[0, 0].plot(rounds, ma, linewidth=2, label=f'MA-{window}')
        
        axes[0, 0].set_title('Raw EDP Evolution Over Time')
        axes[0, 0].set_xlabel('Decision Round')
        axes[0, 0].set_ylabel('EDP (Energy Ã— Delay)')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # æ·»åŠ æ”¹è¿›åŒºé—´æ ‡æ³¨
        improvement = analysis_result['improvement_analysis']
        if improvement['status'] == 'improving':
            axes[0, 0].text(0.7, 0.9, f'Improvement: {improvement["improvement_percent"]:.1f}%', 
                           transform=axes[0, 0].transAxes, bbox=dict(boxstyle="round,pad=0.3", 
                           facecolor="lightgreen", alpha=0.7), fontsize=10)
        
        # 2. EDP vs é¢‘ç‡æ•£ç‚¹å›¾
        freq_perf = analysis_result['frequency_performance']
        frequencies = freq_perf['frequency'].values
        avg_edp = freq_perf['edp_mean'].values
        selection_counts = freq_perf['edp_count'].values
        
        scatter = axes[0, 1].scatter(frequencies, avg_edp, s=selection_counts*10, 
                                   alpha=0.6, c=avg_edp, cmap='RdYlBu_r')
        axes[0, 1].set_title('Frequency vs Average EDP')
        axes[0, 1].set_xlabel('Frequency (MHz)')
        axes[0, 1].set_ylabel('Average EDP')
        axes[0, 1].grid(True, alpha=0.3)
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(scatter, ax=axes[0, 1])
        cbar.set_label('Average EDP')
        
        # 3. EDPåˆ†å¸ƒç›´æ–¹å›¾
        axes[0, 2].hist(edp_values, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0, 2].axvline(np.mean(edp_values), color='red', linestyle='--', 
                          label=f'Mean: {np.mean(edp_values):.3f}')
        axes[0, 2].axvline(np.median(edp_values), color='orange', linestyle='--', 
                          label=f'Median: {np.median(edp_values):.3f}')
        axes[0, 2].set_title('EDP Distribution')
        axes[0, 2].set_xlabel('EDP Value')
        axes[0, 2].set_ylabel('Frequency')
        axes[0, 2].legend()
        axes[0, 2].grid(True, alpha=0.3)
        
        # 4. èƒ½è€—å’Œå»¶è¿Ÿçš„åŒè½´å›¾
        ax_energy = axes[1, 0]
        ax_delay = ax_energy.twinx()
        
        line1 = ax_energy.plot(rounds, df['energy'], 'g-', alpha=0.7, label='Energy (J)')
        line2 = ax_delay.plot(rounds, df['delay']*1000, 'r-', alpha=0.7, label='Delay (ms)')
        
        ax_energy.set_xlabel('Decision Round')
        ax_energy.set_ylabel('Energy Consumption (J)', color='g')
        ax_delay.set_ylabel('Total Delay (ms)', color='r')
        ax_energy.set_title('Energy vs Delay Trade-off')
        
        # åˆå¹¶å›¾ä¾‹
        lines = line1 + line2
        labels = [l.get_label() for l in lines]
        ax_energy.legend(lines, labels, loc='upper right')
        ax_energy.grid(True, alpha=0.3)
        
        # 5. é¢‘ç‡ä½¿ç”¨çƒ­å›¾
        freq_counts = df.groupby(['round', 'frequency']).size().unstack(fill_value=0)
        if len(freq_counts.columns) > 1:
            # åªæ˜¾ç¤ºæœ€å¸¸ç”¨çš„é¢‘ç‡
            top_freqs = df['frequency'].value_counts().head(10).index
            freq_counts_top = freq_counts[top_freqs]
            
            sns.heatmap(freq_counts_top.T, cmap='YlOrRd', ax=axes[1, 1], 
                       cbar_kws={'label': 'Selection Count'})
            axes[1, 1].set_title('Frequency Usage Pattern')
            axes[1, 1].set_xlabel('Decision Round')
            axes[1, 1].set_ylabel('Frequency (MHz)')
        else:
            axes[1, 1].text(0.5, 0.5, 'Insufficient frequency variation', 
                           ha='center', va='center', transform=axes[1, 1].transAxes)
            axes[1, 1].set_title('Frequency Usage Pattern')
        
        # 6. EDPæ”¹è¿›è¶‹åŠ¿
        if len(df) >= 50:
            # è®¡ç®—æ»šåŠ¨æœ€ä½³EDP
            rolling_min_edp = df['edp'].expanding().min()
            axes[1, 2].plot(rounds, edp_values, 'b-', alpha=0.3, label='Raw EDP')
            axes[1, 2].plot(rounds, rolling_min_edp, 'r-', linewidth=2, label='Best EDP So Far')
            axes[1, 2].set_title('EDP Improvement Progress')
            axes[1, 2].set_xlabel('Decision Round')
            axes[1, 2].set_ylabel('EDP Value')
            axes[1, 2].legend()
            axes[1, 2].grid(True, alpha=0.3)
            
            # è®¡ç®—æ”¹è¿›ç‡
            if len(rolling_min_edp) > 10:
                initial_best = rolling_min_edp.iloc[9]  # å‰10è½®çš„æœ€ä½³
                final_best = rolling_min_edp.iloc[-1]
                if initial_best > 0:
                    total_improvement = (initial_best - final_best) / initial_best * 100
                    axes[1, 2].text(0.7, 0.1, f'Total Improvement: {total_improvement:.1f}%',
                                   transform=axes[1, 2].transAxes, 
                                   bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))
        else:
            axes[1, 2].text(0.5, 0.5, 'Insufficient data for trend analysis', 
                           ha='center', va='center', transform=axes[1, 2].transAxes)
            axes[1, 2].set_title('EDP Improvement Progress')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        suffix = f"_first{self.max_rounds}rounds" if self.max_rounds else ""
        output_file = f"data/analysis/edp_comprehensive_analysis{suffix}.png"
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"\nğŸ“Š EDPä¸“é¡¹å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {output_file}")
        
        return output_file
    
    def create_comprehensive_report(self, analysis_result: dict):
        """ç”ŸæˆEDPä¸“é¡¹åˆ†ææŠ¥å‘Š"""
        if not analysis_result:
            return
        
        print("\n" + "="*80)
        print("ğŸ“Š vLLM GPUè‡ªåŠ¨è°ƒé¢‘å™¨ - EDPä¸“é¡¹åˆ†ææŠ¥å‘Š")
        print("="*80)
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"\nğŸ¯ åŸºæœ¬ç»Ÿè®¡:")
        total_rounds_info = f"æ€»å†³ç­–è½®æ¬¡: {analysis_result['total_rounds']}"
        if self.max_rounds:
            total_rounds_info += f" (åˆ†æå‰{self.max_rounds}è½®)"
        print(f"   {total_rounds_info}")
        
        # EDPç»Ÿè®¡
        edp_stats = analysis_result['edp_stats']
        print(f"\nâš¡ EDPç»Ÿè®¡ (Energy-Delay Product):")
        print(f"   æœ€å°å€¼: {edp_stats['min_edp']:.4f}")
        print(f"   æœ€å¤§å€¼: {edp_stats['max_edp']:.4f}")
        print(f"   å¹³å‡å€¼: {edp_stats['mean_edp']:.4f} Â± {edp_stats['std_edp']:.4f}")
        print(f"   ä¸­ä½æ•°: {edp_stats['median_edp']:.4f}")
        print(f"   25%åˆ†ä½: {edp_stats['p25_edp']:.4f}")
        print(f"   75%åˆ†ä½: {edp_stats['p75_edp']:.4f}")
        
        # è¶‹åŠ¿åˆ†æ
        trends = analysis_result['trend_analysis']
        print(f"\nğŸ“ˆ EDPè¶‹åŠ¿åˆ†æ:")
        for ma_name, trend_data in trends.items():
            if isinstance(trend_data, dict) and 'improvement_percent' in trend_data:
                window = ma_name.split('_')[1]
                improvement = trend_data['improvement_percent']
                status = trend_data['trend']
                print(f"   {window}è½®ç§»åŠ¨å¹³å‡: {improvement:+.2f}% ({status})")
        
        # æ•´ä½“æ”¹è¿›åˆ†æ
        improvement = analysis_result['improvement_analysis']
        if improvement['status'] != 'insufficient_data':
            print(f"\nğŸš€ æ•´ä½“æ”¹è¿›æ•ˆæœ:")
            print(f"   å‰æœŸå¹³å‡EDP: {improvement['early_avg_edp']:.4f}")
            print(f"   åæœŸå¹³å‡EDP: {improvement['late_avg_edp']:.4f}")
            print(f"   æ”¹è¿›ç¨‹åº¦: {improvement['improvement_percent']:+.2f}% ({improvement['status']})")
        
        # é¢‘ç‡æ€§èƒ½æ’å
        freq_perf = analysis_result['frequency_performance']
        print(f"\nğŸ† é¢‘ç‡æ€§èƒ½æ’å (æŒ‰å¹³å‡EDPæ’åº, è¶Šå°è¶Šå¥½):")
        print(f"   {'é¢‘ç‡(MHz)':<10} {'é€‰æ‹©æ¬¡æ•°':<8} {'å¹³å‡EDP':<10} {'å¹³å‡èƒ½è€—(J)':<12} {'å¹³å‡å»¶è¿Ÿ(s)':<12}")
        print(f"   {'-'*60}")
        
        for _, row in freq_perf.head(10).iterrows():
            freq = int(row['frequency'])
            count = int(row['edp_count'])
            avg_edp = row['edp_mean']
            avg_energy = row['energy_mean']
            avg_delay = row['delay_mean']
            print(f"   {freq:<10} {count:<8} {avg_edp:<10.4f} {avg_energy:<12.2f} {avg_delay:<12.4f}")
        
        return analysis_result
    
    def run_analysis(self, target_log: str = None):
        """è¿è¡ŒEDPä¸“é¡¹åˆ†æ"""
        rounds_info = f" (å‰{self.max_rounds}è½®)" if self.max_rounds else ""
        print(f"ğŸš€ å¼€å§‹EDPä¸“é¡¹åˆ†æ{rounds_info}...")
        
        # æŸ¥æ‰¾æ—¥å¿—æ–‡ä»¶
        if target_log:
            log_file = target_log
        else:
            log_file = self.find_latest_log()
        
        if not log_file:
            return None
        
        # è§£ææ—¥å¿—
        self.parse_log_file(log_file)
        
        # åˆ†æEDPè¶‹åŠ¿
        analysis_result = self.analyze_edp_trends()
        if not analysis_result:
            return None
        
        # ç”ŸæˆæŠ¥å‘Š
        self.create_comprehensive_report(analysis_result)
        
        # ç”Ÿæˆå¯è§†åŒ–
        self.create_edp_visualizations(analysis_result)
        
        # ä¿å­˜åˆ†æç»“æœ
        suffix = f"_first{self.max_rounds}rounds" if self.max_rounds else ""
        output_file = f"data/analysis/edp_analysis_report{suffix}.json"
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            # è½¬æ¢DataFrameä¸ºå­—å…¸ä»¥ä¾¿JSONåºåˆ—åŒ–
            result_copy = analysis_result.copy()
            result_copy['data'] = result_copy['data'].to_dict('records')
            result_copy['frequency_performance'] = result_copy['frequency_performance'].to_dict('records')
            json.dump(result_copy, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ’¾ EDPåˆ†æç»“æœå·²ä¿å­˜: {output_file}")
        print("âœ… EDPä¸“é¡¹åˆ†æå®Œæˆ!")
        
        return analysis_result

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="vLLM GPUè°ƒé¢‘å™¨EDPä¸“é¡¹åˆ†æå·¥å…·")
    parser.add_argument("--log", help="æŒ‡å®šè¦åˆ†æçš„æ—¥å¿—æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--pattern", default="logs/**/*.log", help="æ—¥å¿—æ–‡ä»¶æœç´¢æ¨¡å¼")
    parser.add_argument("--max-rounds", type=int, help="æŒ‡å®šåˆ†æå‰nè½®æ•°æ®ï¼Œä¸æŒ‡å®šåˆ™åˆ†æå…¨éƒ¨æ•°æ®")
    
    args = parser.parse_args()
    
    # åˆ›å»ºEDPåˆ†æå™¨
    analyzer = EDPAnalyzer(args.pattern, args.max_rounds)
    
    # è¿è¡Œåˆ†æ
    result = analyzer.run_analysis(args.log)
    
    if result:
        suffix = f"_first{args.max_rounds}rounds" if args.max_rounds else ""
        print(f"\nğŸ‰ EDPä¸“é¡¹åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“Š æŸ¥çœ‹EDPå¯è§†åŒ–å›¾è¡¨: data/analysis/edp_comprehensive_analysis{suffix}.png")
        print(f"ğŸ“„ æŸ¥çœ‹è¯¦ç»†æ•°æ®: data/analysis/edp_analysis_report{suffix}.json")

if __name__ == "__main__":
    main()