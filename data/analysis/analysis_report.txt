# vLLM GPU Autoscaler 在线学习效果分析报告
==================================================

## 基础统计信息
- 总轮次: 1308
- 学习轮次: 128
- 利用轮次: 1180
- 尝试频率数: 38
- 可用频率数: 3
- 算法: Contextual LinUCB
- GPU型号: RTX_A6000

## 收敛性分析
✅ **模型已收敛**
- 收敛轮次: 128
- 收敛比例: 90.2%
- 主导频率: 1245 MHz
- 频率稳定性: 49.3%

## 模式切换事件分析
- 切换事件总数: 1208
- 收敛事件: 0
- 性能退化事件: 9
- 学习-利用循环: 0
- 平均切换间隔: 3.6秒
- 收敛行为: 未检测到收敛事件
- 适应行为: 检测到 9 次性能退化，系统主动切换回学习模式

## 学习质量评估
- 学习效率: Fast
- 学习效率比例: 9.8%
- 决策质量: 正奖励比例 52.5%
- 学习稳定性: Volatile
- 算法性能: Good
- 性能改善: Yes

## 探索-利用权衡分析
- 频率多样性: 38 个不同频率
- 选择熵: 2.591
- 最常选择频率: 1245 MHz (45.5%)
- 探索阶段频率数: 29
- 探索均匀性: 0.432
- 利用阶段集中度: 49.3%

## 性能优化效果
- TTFT优化: -0.0674s (0.0%)
- TPOT优化: -0.0328s (0.0%)
- 总延迟优化: -0.1002s (0.0%)

## 能效优化分析
- EDP优化: -0.889 (-23.5%)
- 最佳EDP: 1.469
- 平均EDP: 4.571
- 能效提升: 0.0%

## 频率偏好学习
- 最优频率(奖励): 1470 MHz
- 最常选择频率: 1245 MHz
- 偏好匹配: ❌
- 最优频率(EDP): 1830 MHz
- 最佳EDP值: 0.000

## 总结与建议
✅ 模型训练成功，已达到收敛状态
👍 算法性能良好，有一定改善效果
⚠️ 可能存在探索不充分，建议增加探索