# vLLM Multi-Armed Bandit GPU Autoscaler

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![GPU](https://img.shields.io/badge/GPU-NVIDIA-76B900.svg)](https://developer.nvidia.com/cuda-zone)
[![vLLM](https://img.shields.io/badge/vLLM-Compatible-orange.svg)](https://github.com/vllm-project/vllm)

An intelligent GPU frequency optimization system that uses **Contextual LinUCB Multi-Armed Bandit** algorithms to automatically adjust NVIDIA GPU clock frequencies in real-time, minimizing Energy-Delay Product (EDP) while maintaining quality of service constraints for vLLM inference servers.

## üéØ Key Features

- **üß† Contextual LinUCB Algorithm**: Pure contextual bandit where frequencies are arms/actions and workload features serve as context
- **‚ö° Real-Time Energy Optimization**: Direct GPU power measurement with fixed 0.3s decision cycles
- **üéõÔ∏è Adaptive Frequency Discovery**: Intelligent exploration with dual-mode sampling (SLO-aware vs EDP-optimal)
- **‚úÇÔ∏è Smart Action Pruning**: Advanced frequency pruning with adaptive cascade and extreme frequency instant removal
- **üîÑ Mixed Maturity-Based Refinement**: Statistical refinement for immature models, predictive refinement for mature models
- **üíæ Optional Memory Frequency Control**: Combined core and memory frequency optimization when hardware supports it
- **üìä GPU-Classified Logging**: Automatic log organization by GPU model with detailed performance tracking

## üèóÔ∏è Architecture Overview

The system consists of 8 main components working in a control loop:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   vLLM Server   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Metrics Collector ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Feature Extractor‚îÇ
‚îÇ (Prometheus API)‚îÇ    ‚îÇ  (Session Reuse)  ‚îÇ    ‚îÇ (7D + Welford)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   GPU Controller‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ  Main Controller  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ Contextual LinUCB‚îÇ
‚îÇ (Adaptive Freq) ‚îÇ    ‚îÇ  (Orchestration)  ‚îÇ    ‚îÇ (Action Pruning) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       ‚ñ≤
         ‚ñº                       ‚ñº                       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇAdaptive Sampler ‚îÇ    ‚îÇ Reward Calculator‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     Logger      ‚îÇ
‚îÇ (Dual-Mode)     ‚îÇ    ‚îÇ   (EDP-Based)    ‚îÇ    ‚îÇ (GPU-Classified)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Quick Start

### Prerequisites

- **NVIDIA GPU** with frequency control support
- **Python 3.8+** with required packages
- **vLLM server** running with Prometheus metrics endpoint
- **CUDA drivers** and nvidia-smi access


### Installation (‰ºòÂåñÁâà)

1. ÂÖãÈöÜ‰ª£Á†ÅÂ∫ì (Clone the Repository)

È¶ñÂÖàÔºåÂÖãÈöÜ `AGFT` ÁöÑ‰ª£Á†ÅÂ∫ìÂπ∂ËøõÂÖ•È°πÁõÆÁõÆÂΩï„ÄÇ
git clone https://github.com/SusCom-Lab/AGFT
cd AGFT
2. ÂàõÂª∫Âπ∂ÊøÄÊ¥ª Conda ÁéØÂ¢É (Create and Activate Conda Environment)
‰∏∫‰∫Ü‰øùÊåÅÈ°πÁõÆ‰æùËµñÁöÑÊï¥Ê¥ÅÔºåÊàë‰ª¨Âº∫ÁÉàÂª∫ËÆÆÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑ Conda ÁéØÂ¢É„ÄÇËøôÈáåÊàë‰ª¨ÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫ agft ÁöÑÁéØÂ¢ÉÔºåÂπ∂ÊåáÂÆö Python ÁâàÊú¨‰∏∫ 3.9 (ÊÇ®ÂèØ‰ª•Ê†πÊçÆÈ°πÁõÆÈúÄÊ±ÇÈÄâÊã©ÂÖ∂‰ªñÁâàÊú¨)„ÄÇ

ÂàõÂª∫‰∏Ä‰∏™Âêç‰∏∫ agft ÁöÑÊñ∞ÁéØÂ¢É
conda create -n agft python=3.9 -y

ÊøÄÊ¥ªËØ•ÁéØÂ¢É
conda activate agft
ÈáçË¶ÅÊèêÁ§∫: Âú®ÂêéÁª≠ÊâÄÊúâÊìç‰ΩúÂâçÔºåËØ∑Á°Æ‰øùÊÇ®Â∑≤ÁªèÊøÄÊ¥ª‰∫Ü agft ÁéØÂ¢É„ÄÇÊÇ®‰ºöÁúãÂà∞ÂëΩ‰ª§Ë°åÊèêÁ§∫Á¨¶ÂâçÂá∫Áé∞ (agft) Â≠óÊ†∑„ÄÇ

3. ÂÆâË£Ö‰æùËµñÈ°π (Install Dependencies)
Âú®ÊøÄÊ¥ªÁöÑ Conda ÁéØÂ¢É‰∏≠Ôºå‰ΩøÁî® pip Êù•ÂÆâË£ÖÊâÄÊúâÂøÖÈúÄÁöÑ Python ÂåÖ„ÄÇ

pip install numpy pynvml requests pyyaml matplotlib seaborn scipy
ÊÇ®‰πüÂèØ‰ª•ËÄÉËôëÂ∞ÜËøô‰∫õ‰æùËµñÈ°πÊï¥ÁêÜÂà∞‰∏Ä‰∏™ requirements.txt Êñá‰ª∂‰∏≠ÔºåÁÑ∂ÂêéÈÄöËøá pip install -r requirements.txt Êù•ÂÆâË£ÖÔºåËøôÊ†∑Êõ¥‰æø‰∫éÁÆ°ÁêÜ„ÄÇ

4. È™åËØÅÁéØÂ¢É‰∏éÁ°¨‰ª∂ (Verify Environment and Hardware)
ÂÆåÊàêÂÆâË£ÖÂêéÔºåÊâßË°å‰ª•‰∏ãÂëΩ‰ª§Êù•È™åËØÅÊÇ®ÁöÑ GPU ÊòØÂê¶Ë¢´Ê≠£Á°ÆËØÜÂà´‰ª•ÂèäÁõ∏ÂÖ≥ÁªÑ‰ª∂ÊòØÂê¶Â∑•‰ΩúÊ≠£Â∏∏„ÄÇ




### Basic Usage

```bash
# Run the autoscaler (recommended method)
sudo -E [your conda path] -m src.main

# Run with debug logging
sudo -E [your conda path] -m src.main --log-level DEBUG

# Run with fresh model (ignore existing models)
sudo -E [your conda path] -m src.main --reset-model

# Run with custom configuration
sudo -E [your conda path] -m src.main --config config/config.yaml

# example
sudo -E /home/ldaphome/colin/.conda/envs/vllm/bin/python -m src.main --config config/config.yaml
```

### Configuration

Edit `config/config.yaml` to customize behavior:

```yaml
# Essential settings
control:
  ignore_slo: false           # SLO-aware mode (false) vs EDP-optimal mode (true)
  ttft_limit: 2.0            # Time-to-first-token limit (seconds)
  tpot_limit: 0.25           # Time-per-output-token limit (seconds)

gpu:
  auto_step: true            # Auto-detect GPU frequency capabilities
  frequency_step: 15         # Base frequency step size (MHz)
  enable_memory_frequency_control: false  # Enable memory freq optimization

linucb:
  initial_alpha: 10.0        # Exploration parameter
  enable_action_pruning: true # Enable smart frequency pruning
  enable_extreme_pruning: true # Enable extreme frequency instant pruning
```

## üìà Performance & Results

### Energy Efficiency Gains
- **15-30% EDP reduction** compared to fixed frequency operation
- **Automatic adaptation** to varying workload patterns
- **SLO compliance** maintained during optimization

### Adaptive Learning
- **Fast convergence** typically within 100-200 decision rounds
- **Intelligent exploration** with declining alpha decay
- **Robust performance** across different GPU models and workloads

## üîß Advanced Features

### Dual-Mode Adaptive Sampling

**SLO-Aware Mode** (`ignore_slo: false`):
- High-to-low frequency search with safety prioritization
- Automatic SLO boundary detection and violation recovery
- Mixed refinement strategies based on model maturity

**EDP-Optimal Mode** (`ignore_slo: true`):
- Pure energy-delay product optimization
- Full frequency domain exploration with reward-driven refinement
- Ideal for research environments and maximum efficiency

### Smart Action Pruning

- **Historical Performance Pruning**: Removes consistently poor frequencies
- **Adaptive Cascade Pruning**: Uses `gpu_max_freq // 2` threshold instead of fixed values
- **Extreme Frequency Instant Pruning**: Immediately removes very poor frequencies in first 50 rounds
- **Exploration Protection**: Ensures minimum exploration before pruning eligibility

### Memory Frequency Optimization

When supported by hardware:
- **Combined optimization** of core and memory frequencies
- **Automatic detection** of memory frequency control capabilities
- **Graceful fallback** to core-only mode when unavailable

## üìä Monitoring & Analysis

### Real-Time Monitoring

```bash
# Monitor GPU frequency changes
watch -n 1 'nvidia-smi --query-gpu=clocks.gr --format=csv,noheader,nounits'

# View live logs
tail -f logs/*/vllm_gpu_autoscaler_*.log

# Check model convergence status
python -c "
import json
with open('data/models/model_metadata.json') as f:
    meta = json.load(f)
    print(f'Phase: {meta.get(\"phase\", \"unknown\")}')
    print(f'Converged: {meta.get(\"converged\", \"unknown\")}')
"
```


## üõ†Ô∏è Development & Testing

### Component Testing

```bash
# Test individual components
python -m src.gpu_controller          # GPU control and adaptive sampling
python -m src.metrics_collector       # vLLM metrics collection
python -m src.feature_extractor       # Contextual feature extraction

# Test LinUCB algorithm
python -c "from src.contextual_bandit import ContextualLinUCB; m=ContextualLinUCB(7); print('‚úÖ Contextual LinUCB OK')"

# Test memory frequency support
python -c "from src.gpu_controller import GPUController; g=GPUController(enable_memory_frequency_control=True); print('Memory support:', g.memory_frequency_supported)"
```

### Configuration Validation

```bash
# Validate configuration syntax
python -c "import yaml; yaml.safe_load(open('config/config.yaml')); print('‚úÖ Config valid')"

# Test GPU capabilities
nvidia-smi --query-gpu=name,driver_version,power.management --format=csv
nvidia-smi -q -d SUPPORTED_CLOCKS
```

## üìã System Requirements

### Hardware
- **NVIDIA GPU** with power management support
- **Frequency control capabilities** via nvidia-smi
- **NVML API access** for energy measurement

### Software
- **Python 3.8+**
- **NVIDIA drivers** (R470+ recommended)
- **vLLM server** with Prometheus metrics enabled
- **CUDA toolkit** (for optimal performance)

### Python Dependencies
```
numpy>=1.21.0
pynvml>=11.0.0
requests>=2.25.0
pyyaml>=5.4.0
matplotlib>=3.3.0
seaborn>=0.11.0
scipy>=1.7.0
```

## üîç Troubleshooting

### Common Issues

**GPU Permission Errors**:
```bash
# Add user to video group
sudo usermod -a -G video $USER

# Test frequency control
nvidia-smi -i 0 -lgc 1000
```

**vLLM Connection Issues**:
```bash
# Verify vLLM is accessible
curl http://localhost:8001/metrics | grep "vllm"
```

**Model Loading Issues**:
```bash
# Check model files
ls -la data/models/contextual_linucb_model_*.pkl

# Verify model integrity
python -c "import pickle; pickle.load(open('data/models/latest_model.pkl', 'rb')); print('‚úÖ Model OK')"
```

For detailed troubleshooting, see [CLAUDE.md](CLAUDE.md#troubleshooting).

## üìñ Documentation

- **[CLAUDE.md](CLAUDE.md)** - Comprehensive technical documentation
- **[Configuration Guide](CLAUDE.md#critical-configuration-parameters)** - Detailed parameter explanations
- **[Development Guide](CLAUDE.md#development-commands)** - Development workflows and testing
- **[Performance Tuning](CLAUDE.md#performance-optimization)** - GPU-specific and workload-specific optimization

## ü§ù Contributing

We welcome contributions! Please see our contribution guidelines:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Development Setup

```bash
# Clone your fork
git clone https://github.com/your-username/vllm_mab.git
cd vllm_mab

# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
python -m pytest tests/

# Run linting
flake8 src/
black src/
```


## üèÜ Key Innovations

1. **Pure Contextual Bandit Design**: Frequencies as actions, workload features as context
2. **Adaptive Cascade Pruning**: Hardware-aware frequency pruning using `gpu_max_freq // 2`
3. **Mixed Maturity-Based Refinement**: Different strategies for immature vs mature models
4. **Load-Aware Frequency Recommendation**: Percentile-based load classification
5. **Emergency SLO Recovery**: Immediate frequency adjustment for SLO violations
6. **Online Feature Normalization**: Welford's algorithm for stable feature standardization

## üìú License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **vLLM Team** for the excellent inference framework
- **NVIDIA** for NVML API and GPU management tools
- **Multi-Armed Bandit Research Community** for theoretical foundations
- **Open Source Contributors** for various dependencies and tools

## üìû Support

- **Issues**: [GitHub Issues](https://github.com/your-username/vllm_mab/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-username/vllm_mab/discussions)
- **Documentation**: [CLAUDE.md](CLAUDE.md)

---

**‚≠ê Star this repo if you find it useful!**

*Built with ‚ù§Ô∏è for the energy-efficient AI community*
